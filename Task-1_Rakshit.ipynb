{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshit-Khatri/WARP-26-INSPECT/blob/main/MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_9l9N3acFIid"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Eud9OTh3FgoC"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p-TeICpcF7gF"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhJLcb0gGVgh",
        "outputId": "577a0e9d-0a73-4087-9a02-85feb3555a18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n",
            "100.0%\n",
            "100.0%\n",
            "100.0%\n"
          ]
        }
      ],
      "source": [
        "training_dataset = torchvision.datasets.MNIST(root = \"Data\", download = True, train = True, transform = transform)\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size = batch_size, shuffle = True, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H0v5ZAZvG5Rp"
      },
      "outputs": [],
      "source": [
        "test_dataset = torchvision.datasets.MNIST(root = \"Data\", download = True, train = False, transform = transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrrFwpz_JJ66",
        "outputId": "97d7a4da-60a3-4207-ce8d-68467ddc327e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: Data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSNntZaCJU7P",
        "outputId": "67c5bebf-e6f3-495f-b43b-0d8ca944dcf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: Data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MXFHjcHKJXDS"
      },
      "outputs": [],
      "source": [
        "img, label = training_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs0YPqWgJ402",
        "outputId": "2b0d722d-01f1-4b1c-87fb-6375cccf51c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLI8xDi4J6KE",
        "outputId": "feccdc54-3118-472d-cf09-9090f719837d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPXRijQ-KFRh",
        "outputId": "bda089f1-f552-4048-b268-959489bc9899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "F67VOKTgKSzd",
        "outputId": "2ca60179-3ff3-4ada-e7d8-1747fe74965b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x23d7924f4d0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(img.reshape(28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuts5N5XKiCP",
        "outputId": "f01ff8ca-df6f-4c53-f62b-16c2f561ef13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_flatten = nn.Flatten()\n",
        "test_flatten(img).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GmtVRpi5MC8I"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "class NN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(in_features = 784, out_features = 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = 128, out_features = 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = 64, out_features = 10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logint = self.network(x)\n",
        "    return logint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "69fz8i7iNjwl",
        "outputId": "16ca25a7-45bb-4719-9d1d-94d14a854227"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XFZ1c-JuPCrC"
      },
      "outputs": [],
      "source": [
        "model = NN().to(device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5-_D5wdPWW_",
        "outputId": "1ae4663b-4152-4913-91da-dc06a9f3f0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100352\n",
            "128\n",
            "8192\n",
            "64\n",
            "640\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "for parms in model.parameters():\n",
        "  print(parms.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0hF0EQsQjMb",
        "outputId": "873fe2ab-e864-45dd-a14e-f21e063d40ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "network.0.weight\n",
            "network.0.bias\n",
            "network.2.weight\n",
            "network.2.bias\n",
            "network.4.weight\n",
            "network.4.bias\n"
          ]
        }
      ],
      "source": [
        "for name, parms in model.named_parameters():\n",
        "  print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "I5ASmgq4Q2IW"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n-qcVDnOR45Q"
      },
      "outputs": [],
      "source": [
        "EPOCH = 4\n",
        "best_vloss = 1_00_000.\n",
        "epoch_number = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4L3MJBRSUma",
        "outputId": "328212a0-2c63-4a9a-a8dd-c31a1c9ea066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 1 loss: 0.004628114700317383\n",
            "batch: 2 loss: 0.006905637741088867\n",
            "batch: 3 loss: 0.009169244766235351\n",
            "batch: 4 loss: 0.011426057577133178\n",
            "batch: 5 loss: 0.013668979406356812\n",
            "batch: 6 loss: 0.01589193844795227\n",
            "batch: 7 loss: 0.018079373598098754\n",
            "batch: 8 loss: 0.020280476093292237\n",
            "batch: 9 loss: 0.022400877952575685\n",
            "batch: 10 loss: 0.024524452686309813\n",
            "batch: 11 loss: 0.026572381496429442\n",
            "batch: 12 loss: 0.028656482458114623\n",
            "batch: 13 loss: 0.03074187636375427\n",
            "batch: 14 loss: 0.03280144476890564\n",
            "batch: 15 loss: 0.034851676464080814\n",
            "batch: 16 loss: 0.03683547830581665\n",
            "batch: 17 loss: 0.03877061939239502\n",
            "batch: 18 loss: 0.04071057724952698\n",
            "batch: 19 loss: 0.04253822016716004\n",
            "batch: 20 loss: 0.04438752007484436\n",
            "batch: 21 loss: 0.046151841878890994\n",
            "batch: 22 loss: 0.04786119318008423\n",
            "batch: 23 loss: 0.04957275247573852\n",
            "batch: 24 loss: 0.0513325343132019\n",
            "batch: 25 loss: 0.053075470685958866\n",
            "batch: 26 loss: 0.054689034938812255\n",
            "batch: 27 loss: 0.05627324438095093\n",
            "batch: 28 loss: 0.05780165112018585\n",
            "batch: 29 loss: 0.059227150321006776\n",
            "batch: 30 loss: 0.06071962249279022\n",
            "batch: 31 loss: 0.06216528034210205\n",
            "batch: 32 loss: 0.06363888132572174\n",
            "batch: 33 loss: 0.06503105270862579\n",
            "batch: 34 loss: 0.06623026049137115\n",
            "batch: 35 loss: 0.06745205700397491\n",
            "batch: 36 loss: 0.06862535297870637\n",
            "batch: 37 loss: 0.06967914474010467\n",
            "batch: 38 loss: 0.07066570347547531\n",
            "batch: 39 loss: 0.07174351567029953\n",
            "batch: 40 loss: 0.07290833884477615\n",
            "batch: 41 loss: 0.07383900374174118\n",
            "batch: 42 loss: 0.07475444561243057\n",
            "batch: 43 loss: 0.0759133922457695\n",
            "batch: 44 loss: 0.07688116043806076\n",
            "batch: 45 loss: 0.07816248208284378\n",
            "batch: 46 loss: 0.07909288209676743\n",
            "batch: 47 loss: 0.08018734973669052\n",
            "batch: 48 loss: 0.08130218702554702\n",
            "batch: 49 loss: 0.08200576758384705\n",
            "batch: 50 loss: 0.08286175096035003\n",
            "batch: 51 loss: 0.08396427118778228\n",
            "batch: 52 loss: 0.08489970284700393\n",
            "batch: 53 loss: 0.0856582116484642\n",
            "batch: 54 loss: 0.08649043065309525\n",
            "batch: 55 loss: 0.08734353774785995\n",
            "batch: 56 loss: 0.0882664406299591\n",
            "batch: 57 loss: 0.08902118253707886\n",
            "batch: 58 loss: 0.08975298142433166\n",
            "batch: 59 loss: 0.09062079912424087\n",
            "batch: 60 loss: 0.09163375383615494\n",
            "batch: 61 loss: 0.09227369827032089\n",
            "batch: 62 loss: 0.0930087929368019\n",
            "batch: 63 loss: 0.09371684151887893\n",
            "batch: 64 loss: 0.09443459814786911\n",
            "batch: 65 loss: 0.09534175676107406\n",
            "batch: 66 loss: 0.09593129456043244\n",
            "batch: 67 loss: 0.09635021203756332\n",
            "batch: 68 loss: 0.09697612833976746\n",
            "batch: 69 loss: 0.0978595517873764\n",
            "batch: 70 loss: 0.09845339822769165\n",
            "batch: 71 loss: 0.09914655470848084\n",
            "batch: 72 loss: 0.09985494089126587\n",
            "batch: 73 loss: 0.1005286528468132\n",
            "batch: 74 loss: 0.10132267010211944\n",
            "batch: 75 loss: 0.10187895607948304\n",
            "batch: 76 loss: 0.10241037404537201\n",
            "batch: 77 loss: 0.10315364801883697\n",
            "batch: 78 loss: 0.10392373132705689\n",
            "batch: 79 loss: 0.10435786348581313\n",
            "batch: 80 loss: 0.10500581938028336\n",
            "batch: 81 loss: 0.10574393945932388\n",
            "batch: 82 loss: 0.10621308812499046\n",
            "batch: 83 loss: 0.10670175924897193\n",
            "batch: 84 loss: 0.10715643671154976\n",
            "batch: 85 loss: 0.10747546803951263\n",
            "batch: 86 loss: 0.10791365504264831\n",
            "batch: 87 loss: 0.10846970438957214\n",
            "batch: 88 loss: 0.10909834599494934\n",
            "batch: 89 loss: 0.10964365136623383\n",
            "batch: 90 loss: 0.11026516419649124\n",
            "batch: 91 loss: 0.11126598304510117\n",
            "batch: 92 loss: 0.11158879208564758\n",
            "batch: 93 loss: 0.11227353024482727\n",
            "batch: 94 loss: 0.1127209643125534\n",
            "batch: 95 loss: 0.11318523627519607\n",
            "batch: 96 loss: 0.11377327275276185\n",
            "batch: 97 loss: 0.11421364429593087\n",
            "batch: 98 loss: 0.11482833006978035\n",
            "batch: 99 loss: 0.11524753472208976\n",
            "batch: 100 loss: 0.1155342945754528\n",
            "batch: 101 loss: 0.11615859839320183\n",
            "batch: 102 loss: 0.11651532626152039\n",
            "batch: 103 loss: 0.11696728658676148\n",
            "batch: 104 loss: 0.11730523943901063\n",
            "batch: 105 loss: 0.117986673951149\n",
            "batch: 106 loss: 0.1184735112786293\n",
            "batch: 107 loss: 0.11884827756881713\n",
            "batch: 108 loss: 0.11940447831153869\n",
            "batch: 109 loss: 0.12004368960857391\n",
            "batch: 110 loss: 0.12040517020225525\n",
            "batch: 111 loss: 0.12087991511821747\n",
            "batch: 112 loss: 0.12127840924263\n",
            "batch: 113 loss: 0.12210448276996612\n",
            "batch: 114 loss: 0.1223710033595562\n",
            "batch: 115 loss: 0.12280643832683563\n",
            "batch: 116 loss: 0.1231648987531662\n",
            "batch: 117 loss: 0.12357202756404877\n",
            "batch: 118 loss: 0.12403541585803032\n",
            "batch: 119 loss: 0.12452597013115883\n",
            "batch: 120 loss: 0.1251169766485691\n",
            "batch: 121 loss: 0.12552534499764442\n",
            "batch: 122 loss: 0.12617341294884682\n",
            "batch: 123 loss: 0.12654144194722175\n",
            "batch: 124 loss: 0.1271632594168186\n",
            "batch: 125 loss: 0.12746095135807992\n",
            "batch: 126 loss: 0.12787693732976912\n",
            "batch: 127 loss: 0.12828880923986435\n",
            "batch: 128 loss: 0.12851759365200996\n",
            "batch: 129 loss: 0.1288076995611191\n",
            "batch: 130 loss: 0.12913659033179284\n",
            "batch: 131 loss: 0.12941941305994986\n",
            "batch: 132 loss: 0.12984830245375634\n",
            "batch: 133 loss: 0.1303913486301899\n",
            "batch: 134 loss: 0.13086013182997702\n",
            "batch: 135 loss: 0.13133053180575371\n",
            "batch: 136 loss: 0.13172576597332955\n",
            "batch: 137 loss: 0.13206686344742774\n",
            "batch: 138 loss: 0.13237132135033608\n",
            "batch: 139 loss: 0.13284403571486472\n",
            "batch: 140 loss: 0.1332770479619503\n",
            "batch: 141 loss: 0.1337612746655941\n",
            "batch: 142 loss: 0.13429949840903282\n",
            "batch: 143 loss: 0.1347757076919079\n",
            "batch: 144 loss: 0.13512441384792329\n",
            "batch: 145 loss: 0.13530419421195983\n",
            "batch: 146 loss: 0.13576081290841102\n",
            "batch: 147 loss: 0.13626275780797004\n",
            "batch: 148 loss: 0.1366938000023365\n",
            "batch: 149 loss: 0.1373496644794941\n",
            "batch: 150 loss: 0.137717281550169\n",
            "batch: 151 loss: 0.13814980679750444\n",
            "batch: 152 loss: 0.13851102122664452\n",
            "batch: 153 loss: 0.13938839706778527\n",
            "batch: 154 loss: 0.1397847907245159\n",
            "batch: 155 loss: 0.14007013151049613\n",
            "batch: 156 loss: 0.1405785178244114\n",
            "batch: 157 loss: 0.1408540191948414\n",
            "batch: 158 loss: 0.14102300314605237\n",
            "batch: 159 loss: 0.1414949664324522\n",
            "batch: 160 loss: 0.1419115999788046\n",
            "batch: 161 loss: 0.14248874454200267\n",
            "batch: 162 loss: 0.14301683323085307\n",
            "batch: 163 loss: 0.14342678640782833\n",
            "batch: 164 loss: 0.14426349173486233\n",
            "batch: 165 loss: 0.14478333567082882\n",
            "batch: 166 loss: 0.14518555848300457\n",
            "batch: 167 loss: 0.14589938573539257\n",
            "batch: 168 loss: 0.14646583430469037\n",
            "batch: 169 loss: 0.14692673508822918\n",
            "batch: 170 loss: 0.14719384597241877\n",
            "batch: 171 loss: 0.14773399345576763\n",
            "batch: 172 loss: 0.14807520495355128\n",
            "batch: 173 loss: 0.14874365125596523\n",
            "batch: 174 loss: 0.14903874577581883\n",
            "batch: 175 loss: 0.1495467571169138\n",
            "batch: 176 loss: 0.14976372754573822\n",
            "batch: 177 loss: 0.15019695714116096\n",
            "batch: 178 loss: 0.15054270806908607\n",
            "batch: 179 loss: 0.15097590094804764\n",
            "batch: 180 loss: 0.1515246403813362\n",
            "batch: 181 loss: 0.1518200506567955\n",
            "batch: 182 loss: 0.1520060618519783\n",
            "batch: 183 loss: 0.15222537991404533\n",
            "batch: 184 loss: 0.15245413565635682\n",
            "batch: 185 loss: 0.15265854060649872\n",
            "batch: 186 loss: 0.15315092036128045\n",
            "batch: 187 loss: 0.15339098486304284\n",
            "batch: 188 loss: 0.15368464854359626\n",
            "batch: 189 loss: 0.15399520763754845\n",
            "batch: 190 loss: 0.1543905180990696\n",
            "batch: 191 loss: 0.15502143266797067\n",
            "batch: 192 loss: 0.15519041299819947\n",
            "batch: 193 loss: 0.15552955728769302\n",
            "batch: 194 loss: 0.15598335561156274\n",
            "batch: 195 loss: 0.15660222551226616\n",
            "batch: 196 loss: 0.15716802725195886\n",
            "batch: 197 loss: 0.157799517840147\n",
            "batch: 198 loss: 0.1580845209956169\n",
            "batch: 199 loss: 0.15863004064559935\n",
            "batch: 200 loss: 0.1588439192175865\n",
            "batch: 201 loss: 0.15937222641706467\n",
            "batch: 202 loss: 0.15959609657526017\n",
            "batch: 203 loss: 0.15994237872958184\n",
            "batch: 204 loss: 0.1605178512632847\n",
            "batch: 205 loss: 0.16090906500816346\n",
            "batch: 206 loss: 0.1612977375984192\n",
            "batch: 207 loss: 0.16186395275592805\n",
            "batch: 208 loss: 0.16224396964907647\n",
            "batch: 209 loss: 0.1625236269235611\n",
            "batch: 210 loss: 0.16292533260583877\n",
            "batch: 211 loss: 0.16327216410636902\n",
            "batch: 212 loss: 0.16385670852661133\n",
            "batch: 213 loss: 0.16409116262197496\n",
            "batch: 214 loss: 0.16457906293869018\n",
            "batch: 215 loss: 0.1649719557762146\n",
            "batch: 216 loss: 0.16531067514419556\n",
            "batch: 217 loss: 0.16557242184877397\n",
            "batch: 218 loss: 0.16617426234483718\n",
            "batch: 219 loss: 0.16640490117669104\n",
            "batch: 220 loss: 0.1668157559931278\n",
            "batch: 221 loss: 0.1670748591721058\n",
            "batch: 222 loss: 0.1675212888121605\n",
            "batch: 223 loss: 0.1679977006316185\n",
            "batch: 224 loss: 0.1682428952008486\n",
            "batch: 225 loss: 0.16850695015490055\n",
            "batch: 226 loss: 0.1689584741741419\n",
            "batch: 227 loss: 0.1692448617964983\n",
            "batch: 228 loss: 0.16985878624022008\n",
            "batch: 229 loss: 0.17022833134233953\n",
            "batch: 230 loss: 0.1706052116304636\n",
            "batch: 231 loss: 0.17099647743999957\n",
            "batch: 232 loss: 0.17139246709644795\n",
            "batch: 233 loss: 0.17198191066086294\n",
            "batch: 234 loss: 0.17220095153152942\n",
            "batch: 235 loss: 0.1729901923686266\n",
            "batch: 236 loss: 0.17346379552781582\n",
            "batch: 237 loss: 0.17381675834953786\n",
            "batch: 238 loss: 0.17407775197923184\n",
            "batch: 239 loss: 0.1742156216353178\n",
            "batch: 240 loss: 0.1744527868926525\n",
            "batch: 241 loss: 0.17473156735301018\n",
            "batch: 242 loss: 0.17501262333989143\n",
            "batch: 243 loss: 0.17545223215222358\n",
            "batch: 244 loss: 0.17592516937851907\n",
            "batch: 245 loss: 0.17623536708950996\n",
            "batch: 246 loss: 0.17678390863537788\n",
            "batch: 247 loss: 0.17692107366025447\n",
            "batch: 248 loss: 0.17741674952208997\n",
            "batch: 249 loss: 0.17790198223292827\n",
            "batch: 250 loss: 0.17845773933827877\n",
            "batch: 251 loss: 0.1789527667313814\n",
            "batch: 252 loss: 0.17956817086040974\n",
            "batch: 253 loss: 0.18001318611204625\n",
            "batch: 254 loss: 0.1804909408837557\n",
            "batch: 255 loss: 0.18082833842933177\n",
            "batch: 256 loss: 0.18130324397981168\n",
            "batch: 257 loss: 0.18161012192070483\n",
            "batch: 258 loss: 0.18176811923086644\n",
            "batch: 259 loss: 0.1819085558205843\n",
            "batch: 260 loss: 0.18220192317664624\n",
            "batch: 261 loss: 0.1827585705369711\n",
            "batch: 262 loss: 0.1830540322214365\n",
            "batch: 263 loss: 0.18334416334331036\n",
            "batch: 264 loss: 0.18362121252715588\n",
            "batch: 265 loss: 0.18411733578145503\n",
            "batch: 266 loss: 0.18429125106334687\n",
            "batch: 267 loss: 0.18463073191046714\n",
            "batch: 268 loss: 0.18505725774168968\n",
            "batch: 269 loss: 0.18538254004716873\n",
            "batch: 270 loss: 0.18566687139868737\n",
            "batch: 271 loss: 0.1859773252904415\n",
            "batch: 272 loss: 0.18630350425839423\n",
            "batch: 273 loss: 0.1867408554852009\n",
            "batch: 274 loss: 0.1869035677462816\n",
            "batch: 275 loss: 0.18712242038547994\n",
            "batch: 276 loss: 0.18735163415968417\n",
            "batch: 277 loss: 0.1877701812237501\n",
            "batch: 278 loss: 0.18821277140080928\n",
            "batch: 279 loss: 0.18853150568902494\n",
            "batch: 280 loss: 0.18885972513258456\n",
            "batch: 281 loss: 0.18913952665030956\n",
            "batch: 282 loss: 0.18946300791203977\n",
            "batch: 283 loss: 0.1898986043781042\n",
            "batch: 284 loss: 0.1904935368746519\n",
            "batch: 285 loss: 0.19094574634730815\n",
            "batch: 286 loss: 0.19136431558430195\n",
            "batch: 287 loss: 0.1918408862501383\n",
            "batch: 288 loss: 0.19247146959602832\n",
            "batch: 289 loss: 0.19297612173855305\n",
            "batch: 290 loss: 0.19344539572298527\n",
            "batch: 291 loss: 0.19384100769460202\n",
            "batch: 292 loss: 0.1943343534320593\n",
            "batch: 293 loss: 0.1949621239155531\n",
            "batch: 294 loss: 0.19532271836698056\n",
            "batch: 295 loss: 0.19566229014098643\n",
            "batch: 296 loss: 0.19601063232123853\n",
            "batch: 297 loss: 0.19635280393064022\n",
            "batch: 298 loss: 0.19668443517386913\n",
            "batch: 299 loss: 0.1974908445328474\n",
            "batch: 300 loss: 0.19774276961386203\n",
            "batch: 301 loss: 0.1980587363988161\n",
            "batch: 302 loss: 0.19832118304073812\n",
            "batch: 303 loss: 0.19862504883110524\n",
            "batch: 304 loss: 0.19889541412889958\n",
            "batch: 305 loss: 0.19944439317286014\n",
            "batch: 306 loss: 0.19982779978215695\n",
            "batch: 307 loss: 0.20008424608409406\n",
            "batch: 308 loss: 0.20043405513465404\n",
            "batch: 309 loss: 0.20086210896074772\n",
            "batch: 310 loss: 0.20106310117244722\n",
            "batch: 311 loss: 0.20136079648137092\n",
            "batch: 312 loss: 0.20202595636248588\n",
            "batch: 313 loss: 0.20240914154052733\n",
            "batch: 314 loss: 0.20286319413781165\n",
            "batch: 315 loss: 0.20317755115032196\n",
            "batch: 316 loss: 0.20346365869045258\n",
            "batch: 317 loss: 0.20424700319766997\n",
            "batch: 318 loss: 0.20465341782569885\n",
            "batch: 319 loss: 0.2051790817975998\n",
            "batch: 320 loss: 0.20540284684300422\n",
            "batch: 321 loss: 0.2057805474102497\n",
            "batch: 322 loss: 0.2062644810974598\n",
            "batch: 323 loss: 0.20650285339355468\n",
            "batch: 324 loss: 0.20697121086716652\n",
            "batch: 325 loss: 0.2072866124212742\n",
            "batch: 326 loss: 0.20757017481327056\n",
            "batch: 327 loss: 0.20788019198179244\n",
            "batch: 328 loss: 0.20815451815724373\n",
            "batch: 329 loss: 0.2083461634218693\n",
            "batch: 330 loss: 0.2088261202275753\n",
            "batch: 331 loss: 0.20925856482982635\n",
            "batch: 332 loss: 0.20943171685934067\n",
            "batch: 333 loss: 0.20975555714964866\n",
            "batch: 334 loss: 0.21010106837749482\n",
            "batch: 335 loss: 0.21026154023408888\n",
            "batch: 336 loss: 0.21058114996552468\n",
            "batch: 337 loss: 0.21086607739329338\n",
            "batch: 338 loss: 0.2111783849298954\n",
            "batch: 339 loss: 0.21143725392222404\n",
            "batch: 340 loss: 0.21167905317246913\n",
            "batch: 341 loss: 0.21193520332872867\n",
            "batch: 342 loss: 0.21208679969608785\n",
            "batch: 343 loss: 0.21239039154350758\n",
            "batch: 344 loss: 0.21262485404312612\n",
            "batch: 345 loss: 0.21279783974587918\n",
            "batch: 346 loss: 0.21345988915860653\n",
            "batch: 347 loss: 0.21376287637650968\n",
            "batch: 348 loss: 0.2139778926372528\n",
            "batch: 349 loss: 0.21432455658912658\n",
            "batch: 350 loss: 0.21442649483680726\n",
            "batch: 351 loss: 0.21473967331647872\n",
            "batch: 352 loss: 0.2151960160136223\n",
            "batch: 353 loss: 0.21564643317461013\n",
            "batch: 354 loss: 0.21604730227589608\n",
            "batch: 355 loss: 0.21635234248638152\n",
            "batch: 356 loss: 0.216725202023983\n",
            "batch: 357 loss: 0.21693402019143104\n",
            "batch: 358 loss: 0.21710804460942745\n",
            "batch: 359 loss: 0.21729623301327228\n",
            "batch: 360 loss: 0.21762988339364528\n",
            "batch: 361 loss: 0.217959904178977\n",
            "batch: 362 loss: 0.21826197884976864\n",
            "batch: 363 loss: 0.21881868682801722\n",
            "batch: 364 loss: 0.21932622717320918\n",
            "batch: 365 loss: 0.21967775206267834\n",
            "batch: 366 loss: 0.21975503608584404\n",
            "batch: 367 loss: 0.22003654724359512\n",
            "batch: 368 loss: 0.2202077711224556\n",
            "batch: 369 loss: 0.2203628927767277\n",
            "batch: 370 loss: 0.22064851021766663\n",
            "batch: 371 loss: 0.2209892239868641\n",
            "batch: 372 loss: 0.22142020204663276\n",
            "batch: 373 loss: 0.22183053866028785\n",
            "batch: 374 loss: 0.22213580337166786\n",
            "batch: 375 loss: 0.22235906672477723\n",
            "batch: 376 loss: 0.22245421113073827\n",
            "batch: 377 loss: 0.22260117204487323\n",
            "batch: 378 loss: 0.22301041914522649\n",
            "batch: 379 loss: 0.22330787818133832\n",
            "batch: 380 loss: 0.22350830167531968\n",
            "batch: 381 loss: 0.2239677553474903\n",
            "batch: 382 loss: 0.2246202782690525\n",
            "batch: 383 loss: 0.22482212805747986\n",
            "batch: 384 loss: 0.2251867855489254\n",
            "batch: 385 loss: 0.22528161192685367\n",
            "batch: 386 loss: 0.22569735575467348\n",
            "batch: 387 loss: 0.22585215432196856\n",
            "batch: 388 loss: 0.2261706583276391\n",
            "batch: 389 loss: 0.2264419166520238\n",
            "batch: 390 loss: 0.22659197867661715\n",
            "batch: 391 loss: 0.22677925289422274\n",
            "batch: 392 loss: 0.22706311685591937\n",
            "batch: 393 loss: 0.22757302720099687\n",
            "batch: 394 loss: 0.2278985485509038\n",
            "batch: 395 loss: 0.2280780855640769\n",
            "batch: 396 loss: 0.22853636886924505\n",
            "batch: 397 loss: 0.2289372956380248\n",
            "batch: 398 loss: 0.2291248203292489\n",
            "batch: 399 loss: 0.22950590196996928\n",
            "batch: 400 loss: 0.22972957997769117\n",
            "batch: 401 loss: 0.2299044879004359\n",
            "batch: 402 loss: 0.23036557563394308\n",
            "batch: 403 loss: 0.23061396794766187\n",
            "batch: 404 loss: 0.2309088719114661\n",
            "batch: 405 loss: 0.23112803291529416\n",
            "batch: 406 loss: 0.2312855884358287\n",
            "batch: 407 loss: 0.23153449930995704\n",
            "batch: 408 loss: 0.23176816212385892\n",
            "batch: 409 loss: 0.23210576938837765\n",
            "batch: 410 loss: 0.2322782427892089\n",
            "batch: 411 loss: 0.23238805332034826\n",
            "batch: 412 loss: 0.23276634391397238\n",
            "batch: 413 loss: 0.23302096935361624\n",
            "batch: 414 loss: 0.2331231374889612\n",
            "batch: 415 loss: 0.23340271101891993\n",
            "batch: 416 loss: 0.23364154897630215\n",
            "batch: 417 loss: 0.23423228298127652\n",
            "batch: 418 loss: 0.23441283425688744\n",
            "batch: 419 loss: 0.23478565123677253\n",
            "batch: 420 loss: 0.2349924899786711\n",
            "batch: 421 loss: 0.2351636020988226\n",
            "batch: 422 loss: 0.23534117750823497\n",
            "batch: 423 loss: 0.23563401897251607\n",
            "batch: 424 loss: 0.23613629032671452\n",
            "batch: 425 loss: 0.23652591188251973\n",
            "batch: 426 loss: 0.23694323675334453\n",
            "batch: 427 loss: 0.23713992263376713\n",
            "batch: 428 loss: 0.2375810915082693\n",
            "batch: 429 loss: 0.23829128389060497\n",
            "batch: 430 loss: 0.23848181952536107\n",
            "batch: 431 loss: 0.23917794634401798\n",
            "batch: 432 loss: 0.2394516986757517\n",
            "batch: 433 loss: 0.239721380636096\n",
            "batch: 434 loss: 0.24033534787595273\n",
            "batch: 435 loss: 0.24061817567050456\n",
            "batch: 436 loss: 0.2407771667689085\n",
            "batch: 437 loss: 0.24107334373891354\n",
            "batch: 438 loss: 0.24125695492327212\n",
            "batch: 439 loss: 0.24154967711865902\n",
            "batch: 440 loss: 0.24179421798884868\n",
            "batch: 441 loss: 0.24186667686700822\n",
            "batch: 442 loss: 0.2421095041781664\n",
            "batch: 443 loss: 0.24241084764897824\n",
            "batch: 444 loss: 0.24269330559670926\n",
            "batch: 445 loss: 0.2431350511163473\n",
            "batch: 446 loss: 0.24331614251434802\n",
            "batch: 447 loss: 0.24367015679180623\n",
            "batch: 448 loss: 0.24393744833767414\n",
            "batch: 449 loss: 0.24437533311545848\n",
            "batch: 450 loss: 0.2447360159009695\n",
            "batch: 451 loss: 0.2452194800823927\n",
            "batch: 452 loss: 0.24561525569856166\n",
            "batch: 453 loss: 0.24617664383351803\n",
            "batch: 454 loss: 0.24661869280040263\n",
            "batch: 455 loss: 0.2468767662793398\n",
            "batch: 456 loss: 0.2470926477909088\n",
            "batch: 457 loss: 0.2475176540017128\n",
            "batch: 458 loss: 0.2479334280192852\n",
            "batch: 459 loss: 0.24841156899929046\n",
            "batch: 460 loss: 0.2487052144408226\n",
            "batch: 461 loss: 0.2488703968524933\n",
            "batch: 462 loss: 0.2491697136759758\n",
            "batch: 463 loss: 0.24939660465717314\n",
            "batch: 464 loss: 0.24984012874960898\n",
            "batch: 465 loss: 0.2502573881149292\n",
            "batch: 466 loss: 0.25040670388937\n",
            "batch: 467 loss: 0.250743832051754\n",
            "batch: 468 loss: 0.25113731482625007\n",
            "batch: 469 loss: 0.2515463828444481\n",
            "batch: 470 loss: 0.25166363941133024\n",
            "batch: 471 loss: 0.25184840853512286\n",
            "batch: 472 loss: 0.2519842713624239\n",
            "batch: 473 loss: 0.2523556531816721\n",
            "batch: 474 loss: 0.25253182762861254\n",
            "batch: 475 loss: 0.2527859555482864\n",
            "batch: 476 loss: 0.253214204788208\n",
            "batch: 477 loss: 0.25348917722702025\n",
            "batch: 478 loss: 0.25393310755491255\n",
            "batch: 479 loss: 0.25446094328165053\n",
            "batch: 480 loss: 0.2546423691213131\n",
            "batch: 481 loss: 0.2551407426893711\n",
            "batch: 482 loss: 0.2555704691112041\n",
            "batch: 483 loss: 0.25586770725250246\n",
            "batch: 484 loss: 0.25598551769554617\n",
            "batch: 485 loss: 0.2563118913322687\n",
            "batch: 486 loss: 0.25720365573465825\n",
            "batch: 487 loss: 0.25745819820463656\n",
            "batch: 488 loss: 0.2576137066632509\n",
            "batch: 489 loss: 0.257840142890811\n",
            "batch: 490 loss: 0.25798113022744656\n",
            "batch: 491 loss: 0.25816301350295545\n",
            "batch: 492 loss: 0.25866362081468103\n",
            "batch: 493 loss: 0.2590827388316393\n",
            "batch: 494 loss: 0.25930118714272976\n",
            "batch: 495 loss: 0.2594402031600475\n",
            "batch: 496 loss: 0.26012205907702446\n",
            "batch: 497 loss: 0.26066712734103203\n",
            "batch: 498 loss: 0.2609773364365101\n",
            "batch: 499 loss: 0.26168097922205924\n",
            "batch: 500 loss: 0.2621362398266792\n",
            "batch: 501 loss: 0.26226011136174204\n",
            "batch: 502 loss: 0.26248505225777624\n",
            "batch: 503 loss: 0.2628483093082905\n",
            "batch: 504 loss: 0.2631138863265514\n",
            "batch: 505 loss: 0.2636102637052536\n",
            "batch: 506 loss: 0.2638246728330851\n",
            "batch: 507 loss: 0.2639911428838968\n",
            "batch: 508 loss: 0.2642364191561937\n",
            "batch: 509 loss: 0.2647287724763155\n",
            "batch: 510 loss: 0.26530947639048097\n",
            "batch: 511 loss: 0.265497995570302\n",
            "batch: 512 loss: 0.26585037480294704\n",
            "batch: 513 loss: 0.26633283199369906\n",
            "batch: 514 loss: 0.2665666568130255\n",
            "batch: 515 loss: 0.267060826048255\n",
            "batch: 516 loss: 0.26743666039407255\n",
            "batch: 517 loss: 0.2677321179062128\n",
            "batch: 518 loss: 0.2682584933191538\n",
            "batch: 519 loss: 0.26851825197041035\n",
            "batch: 520 loss: 0.2690825856477022\n",
            "batch: 521 loss: 0.26922012643516063\n",
            "batch: 522 loss: 0.2694723267108202\n",
            "batch: 523 loss: 0.2696722644716501\n",
            "batch: 524 loss: 0.26982410088181497\n",
            "batch: 525 loss: 0.26996625627577303\n",
            "batch: 526 loss: 0.27013433277606963\n",
            "batch: 527 loss: 0.2704824302792549\n",
            "batch: 528 loss: 0.270713980704546\n",
            "batch: 529 loss: 0.27104986679553983\n",
            "batch: 530 loss: 0.27134484696388245\n",
            "batch: 531 loss: 0.2720592364668846\n",
            "batch: 532 loss: 0.2724552238881588\n",
            "batch: 533 loss: 0.2726086765676737\n",
            "batch: 534 loss: 0.27292730470001697\n",
            "batch: 535 loss: 0.2731407950520515\n",
            "batch: 536 loss: 0.2735953957438469\n",
            "batch: 537 loss: 0.2738312964141369\n",
            "batch: 538 loss: 0.27422570297122\n",
            "batch: 539 loss: 0.27450992342829705\n",
            "batch: 540 loss: 0.27471697215735913\n",
            "batch: 541 loss: 0.27490323488414287\n",
            "batch: 542 loss: 0.2750199658125639\n",
            "batch: 543 loss: 0.27534190033376216\n",
            "batch: 544 loss: 0.275693499609828\n",
            "batch: 545 loss: 0.2758779663294554\n",
            "batch: 546 loss: 0.2761747179180384\n",
            "batch: 547 loss: 0.2768262835294008\n",
            "batch: 548 loss: 0.2771991273313761\n",
            "batch: 549 loss: 0.2774894758909941\n",
            "batch: 550 loss: 0.2780564091652632\n",
            "batch: 551 loss: 0.2789256712645292\n",
            "batch: 552 loss: 0.2793286356180906\n",
            "batch: 553 loss: 0.2794720527082682\n",
            "batch: 554 loss: 0.2796260839253664\n",
            "batch: 555 loss: 0.27980036571621897\n",
            "batch: 556 loss: 0.2800904299616814\n",
            "batch: 557 loss: 0.2804077420830727\n",
            "batch: 558 loss: 0.2806811303496361\n",
            "batch: 559 loss: 0.2810471904873848\n",
            "batch: 560 loss: 0.2812343312948942\n",
            "batch: 561 loss: 0.28187108258903026\n",
            "batch: 562 loss: 0.2820678188800812\n",
            "batch: 563 loss: 0.2823326766192913\n",
            "batch: 564 loss: 0.282630957454443\n",
            "batch: 565 loss: 0.2829039711952209\n",
            "batch: 566 loss: 0.28332898211479185\n",
            "batch: 567 loss: 0.28371410638093947\n",
            "batch: 568 loss: 0.28396712404489516\n",
            "batch: 569 loss: 0.28436304542422297\n",
            "batch: 570 loss: 0.28476786547899247\n",
            "batch: 571 loss: 0.2849814837872982\n",
            "batch: 572 loss: 0.2852411861121654\n",
            "batch: 573 loss: 0.285481669023633\n",
            "batch: 574 loss: 0.2858404868096113\n",
            "batch: 575 loss: 0.2862631784826517\n",
            "batch: 576 loss: 0.2865239522904158\n",
            "batch: 577 loss: 0.2869153175204992\n",
            "batch: 578 loss: 0.2870651575475931\n",
            "batch: 579 loss: 0.2872071733921766\n",
            "batch: 580 loss: 0.28756783543527126\n",
            "batch: 581 loss: 0.2878987045735121\n",
            "batch: 582 loss: 0.28839775182306765\n",
            "batch: 583 loss: 0.28872953955829145\n",
            "batch: 584 loss: 0.28910348181426526\n",
            "batch: 585 loss: 0.28956970082223416\n",
            "batch: 586 loss: 0.29056639967858794\n",
            "batch: 587 loss: 0.2909564128965139\n",
            "batch: 588 loss: 0.29107179436832664\n",
            "batch: 589 loss: 0.2911555585488677\n",
            "batch: 590 loss: 0.29170890387147663\n",
            "batch: 591 loss: 0.2918902396187186\n",
            "batch: 592 loss: 0.2922355358824134\n",
            "batch: 593 loss: 0.2924412660077214\n",
            "batch: 594 loss: 0.29267598073929546\n",
            "batch: 595 loss: 0.2928148538991809\n",
            "batch: 596 loss: 0.29302349587529897\n",
            "batch: 597 loss: 0.2931934074833989\n",
            "batch: 598 loss: 0.2933198867365718\n",
            "batch: 599 loss: 0.29348012841492893\n",
            "batch: 600 loss: 0.2936697440817952\n",
            "batch: 601 loss: 0.29404383022338154\n",
            "batch: 602 loss: 0.29439479172974825\n",
            "batch: 603 loss: 0.2944997087791562\n",
            "batch: 604 loss: 0.2947762737348676\n",
            "batch: 605 loss: 0.29498140899091957\n",
            "batch: 606 loss: 0.2952163237556815\n",
            "batch: 607 loss: 0.2956739787682891\n",
            "batch: 608 loss: 0.2962019561752677\n",
            "batch: 609 loss: 0.29644196750968693\n",
            "batch: 610 loss: 0.2968844089135528\n",
            "batch: 611 loss: 0.2969572981372476\n",
            "batch: 612 loss: 0.29757781050354243\n",
            "batch: 613 loss: 0.29803294683247805\n",
            "batch: 614 loss: 0.2982072528973222\n",
            "batch: 615 loss: 0.298621585406363\n",
            "batch: 616 loss: 0.2992420864477754\n",
            "batch: 617 loss: 0.2993278360888362\n",
            "batch: 618 loss: 0.2995827198550105\n",
            "batch: 619 loss: 0.2997998005822301\n",
            "batch: 620 loss: 0.30033365697413683\n",
            "batch: 621 loss: 0.3008420853689313\n",
            "batch: 622 loss: 0.30105674550682304\n",
            "batch: 623 loss: 0.3014286921992898\n",
            "batch: 624 loss: 0.3017827205434442\n",
            "batch: 625 loss: 0.3018952346518636\n",
            "batch: 626 loss: 0.30202960059791806\n",
            "batch: 627 loss: 0.30239677081257105\n",
            "batch: 628 loss: 0.3027045921459794\n",
            "batch: 629 loss: 0.3028126600459218\n",
            "batch: 630 loss: 0.3030160091295838\n",
            "batch: 631 loss: 0.30317846085876227\n",
            "batch: 632 loss: 0.30337260534614324\n",
            "batch: 633 loss: 0.30360879047960043\n",
            "batch: 634 loss: 0.3038064846768975\n",
            "batch: 635 loss: 0.3040160050168633\n",
            "batch: 636 loss: 0.3043697708621621\n",
            "batch: 637 loss: 0.3045000132098794\n",
            "batch: 638 loss: 0.30463444168120624\n",
            "batch: 639 loss: 0.30512969506531956\n",
            "batch: 640 loss: 0.3054003065302968\n",
            "batch: 641 loss: 0.305664957202971\n",
            "batch: 642 loss: 0.3060594615116715\n",
            "batch: 643 loss: 0.30612903807312253\n",
            "batch: 644 loss: 0.3063143849298358\n",
            "batch: 645 loss: 0.3064367328956723\n",
            "batch: 646 loss: 0.3071517916992307\n",
            "batch: 647 loss: 0.30744604981690643\n",
            "batch: 648 loss: 0.3075568862557411\n",
            "batch: 649 loss: 0.3079587540328503\n",
            "batch: 650 loss: 0.3083681246936321\n",
            "batch: 651 loss: 0.3086039615869522\n",
            "batch: 652 loss: 0.30903834146261216\n",
            "batch: 653 loss: 0.3094779706299305\n",
            "batch: 654 loss: 0.3099150011241436\n",
            "batch: 655 loss: 0.31038395431637766\n",
            "batch: 656 loss: 0.3108876488506794\n",
            "batch: 657 loss: 0.3112154206931591\n",
            "batch: 658 loss: 0.31149341675639153\n",
            "batch: 659 loss: 0.31177518877387045\n",
            "batch: 660 loss: 0.31193631000816824\n",
            "batch: 661 loss: 0.31206118850409986\n",
            "batch: 662 loss: 0.3124630283564329\n",
            "batch: 663 loss: 0.31295457915961744\n",
            "batch: 664 loss: 0.3131368712037802\n",
            "batch: 665 loss: 0.31336408656835557\n",
            "batch: 666 loss: 0.31361980810761453\n",
            "batch: 667 loss: 0.31420105800032616\n",
            "batch: 668 loss: 0.3145040394961834\n",
            "batch: 669 loss: 0.31462481638789175\n",
            "batch: 670 loss: 0.31505312952399256\n",
            "batch: 671 loss: 0.31552196383476255\n",
            "batch: 672 loss: 0.3158546634316444\n",
            "batch: 673 loss: 0.31599301770329474\n",
            "batch: 674 loss: 0.3161489742547274\n",
            "batch: 675 loss: 0.31628545989096163\n",
            "batch: 676 loss: 0.31647158466279507\n",
            "batch: 677 loss: 0.3167794528156519\n",
            "batch: 678 loss: 0.3170028403699398\n",
            "batch: 679 loss: 0.3173626228570938\n",
            "batch: 680 loss: 0.3177330968081951\n",
            "batch: 681 loss: 0.317947167724371\n",
            "batch: 682 loss: 0.31830688685178754\n",
            "batch: 683 loss: 0.3186338077187538\n",
            "batch: 684 loss: 0.31872624734789134\n",
            "batch: 685 loss: 0.3188672850653529\n",
            "batch: 686 loss: 0.31906042268127205\n",
            "batch: 687 loss: 0.3191771327033639\n",
            "batch: 688 loss: 0.3195610834136605\n",
            "batch: 689 loss: 0.31991451016813516\n",
            "batch: 690 loss: 0.32028543526679276\n",
            "batch: 691 loss: 0.3205140832290053\n",
            "batch: 692 loss: 0.3208534700796008\n",
            "batch: 693 loss: 0.3210167788043618\n",
            "batch: 694 loss: 0.32133649531751873\n",
            "batch: 695 loss: 0.3215857197418809\n",
            "batch: 696 loss: 0.3217943115755916\n",
            "batch: 697 loss: 0.3219887079969049\n",
            "batch: 698 loss: 0.3221706051304936\n",
            "batch: 699 loss: 0.32242702452093364\n",
            "batch: 700 loss: 0.32263222671300174\n",
            "batch: 701 loss: 0.3228880379572511\n",
            "batch: 702 loss: 0.32313238877803085\n",
            "batch: 703 loss: 0.3233431062474847\n",
            "batch: 704 loss: 0.32364421103149654\n",
            "batch: 705 loss: 0.32388202924281356\n",
            "batch: 706 loss: 0.3241551756039262\n",
            "batch: 707 loss: 0.32435353542119266\n",
            "batch: 708 loss: 0.32463141579180954\n",
            "batch: 709 loss: 0.3248623412773013\n",
            "batch: 710 loss: 0.32536346768587826\n",
            "batch: 711 loss: 0.3257003516480327\n",
            "batch: 712 loss: 0.32583783284574747\n",
            "batch: 713 loss: 0.3258969490081072\n",
            "batch: 714 loss: 0.32601143372803926\n",
            "batch: 715 loss: 0.3262916302159429\n",
            "batch: 716 loss: 0.326545300193131\n",
            "batch: 717 loss: 0.3267103601023555\n",
            "batch: 718 loss: 0.3268735751733184\n",
            "batch: 719 loss: 0.32696068635582926\n",
            "batch: 720 loss: 0.327282641261816\n",
            "batch: 721 loss: 0.32749195832014083\n",
            "batch: 722 loss: 0.3276087101325393\n",
            "batch: 723 loss: 0.32768770872801545\n",
            "batch: 724 loss: 0.32783644189685585\n",
            "batch: 725 loss: 0.3280700101926923\n",
            "batch: 726 loss: 0.32833023560792207\n",
            "batch: 727 loss: 0.3284494225308299\n",
            "batch: 728 loss: 0.32859944882243874\n",
            "batch: 729 loss: 0.3289781158789992\n",
            "batch: 730 loss: 0.3294064270183444\n",
            "batch: 731 loss: 0.3297203014716506\n",
            "batch: 732 loss: 0.3298718880340457\n",
            "batch: 733 loss: 0.3300162919089198\n",
            "batch: 734 loss: 0.3302300041392446\n",
            "batch: 735 loss: 0.33039093283563853\n",
            "batch: 736 loss: 0.3310055091753602\n",
            "batch: 737 loss: 0.3313832734301686\n",
            "batch: 738 loss: 0.33150500640273095\n",
            "batch: 739 loss: 0.3317533686608076\n",
            "batch: 740 loss: 0.3320919927805662\n",
            "batch: 741 loss: 0.33222558775544164\n",
            "batch: 742 loss: 0.33230819660425187\n",
            "batch: 743 loss: 0.33291173273324964\n",
            "batch: 744 loss: 0.3330374571830034\n",
            "batch: 745 loss: 0.3331100616455078\n",
            "batch: 746 loss: 0.3332726359516382\n",
            "batch: 747 loss: 0.333565912976861\n",
            "batch: 748 loss: 0.3339554277211428\n",
            "batch: 749 loss: 0.3342574356943369\n",
            "batch: 750 loss: 0.33455935163795947\n",
            "batch: 751 loss: 0.33482651706039906\n",
            "batch: 752 loss: 0.33497768227756025\n",
            "batch: 753 loss: 0.3352450731545687\n",
            "batch: 754 loss: 0.33551772962510584\n",
            "batch: 755 loss: 0.3359902295321226\n",
            "batch: 756 loss: 0.33611256776750087\n",
            "batch: 757 loss: 0.33620977733284235\n",
            "batch: 758 loss: 0.3363903089389205\n",
            "batch: 759 loss: 0.3365024500563741\n",
            "batch: 760 loss: 0.3368508423045278\n",
            "batch: 761 loss: 0.3370768347606063\n",
            "batch: 762 loss: 0.33723841498047114\n",
            "batch: 763 loss: 0.33746379376202823\n",
            "batch: 764 loss: 0.3377973569110036\n",
            "batch: 765 loss: 0.33799548404663804\n",
            "batch: 766 loss: 0.3380705647394061\n",
            "batch: 767 loss: 0.33826605703681706\n",
            "batch: 768 loss: 0.33874518992751834\n",
            "batch: 769 loss: 0.33890494134277105\n",
            "batch: 770 loss: 0.3390698188170791\n",
            "batch: 771 loss: 0.3393093380704522\n",
            "batch: 772 loss: 0.33941917269676924\n",
            "batch: 773 loss: 0.33948286678642037\n",
            "batch: 774 loss: 0.3396743129119277\n",
            "batch: 775 loss: 0.3399699557945132\n",
            "batch: 776 loss: 0.3402214210256934\n",
            "batch: 777 loss: 0.3403663049265742\n",
            "batch: 778 loss: 0.3405826699063182\n",
            "batch: 779 loss: 0.34071249871701004\n",
            "batch: 780 loss: 0.3411266275271773\n",
            "batch: 781 loss: 0.34159991224855185\n",
            "batch: 782 loss: 0.3418871025070548\n",
            "batch: 783 loss: 0.34207670887559655\n",
            "batch: 784 loss: 0.3423095037564635\n",
            "batch: 785 loss: 0.3424281913116574\n",
            "batch: 786 loss: 0.342709494329989\n",
            "batch: 787 loss: 0.34278549601882696\n",
            "batch: 788 loss: 0.3430071802958846\n",
            "batch: 789 loss: 0.3432725686952472\n",
            "batch: 790 loss: 0.343423432148993\n",
            "batch: 791 loss: 0.34352620083093643\n",
            "batch: 792 loss: 0.3437313198596239\n",
            "batch: 793 loss: 0.3439565664678812\n",
            "batch: 794 loss: 0.34425696690380575\n",
            "batch: 795 loss: 0.3450349049717188\n",
            "batch: 796 loss: 0.34533896489441396\n",
            "batch: 797 loss: 0.34563036273419856\n",
            "batch: 798 loss: 0.3458689667135477\n",
            "batch: 799 loss: 0.3461650040894747\n",
            "batch: 800 loss: 0.3464111479669809\n",
            "batch: 801 loss: 0.34649266704916953\n",
            "batch: 802 loss: 0.3467163055241108\n",
            "batch: 803 loss: 0.34694430156052114\n",
            "batch: 804 loss: 0.3471827260553837\n",
            "batch: 805 loss: 0.3473484474122524\n",
            "batch: 806 loss: 0.34784911689162257\n",
            "batch: 807 loss: 0.3480783286988735\n",
            "batch: 808 loss: 0.3482715360969305\n",
            "batch: 809 loss: 0.34854179076850417\n",
            "batch: 810 loss: 0.34880683885514735\n",
            "batch: 811 loss: 0.34931124083697795\n",
            "batch: 812 loss: 0.34944117718935014\n",
            "batch: 813 loss: 0.34972849547863005\n",
            "batch: 814 loss: 0.3498390310406685\n",
            "batch: 815 loss: 0.3500286628603935\n",
            "batch: 816 loss: 0.35029487684369087\n",
            "batch: 817 loss: 0.35065225929021837\n",
            "batch: 818 loss: 0.35084016820788383\n",
            "batch: 819 loss: 0.35111310419440267\n",
            "batch: 820 loss: 0.3516206359565258\n",
            "batch: 821 loss: 0.3519572802782059\n",
            "batch: 822 loss: 0.3521289310157299\n",
            "batch: 823 loss: 0.3524450755417347\n",
            "batch: 824 loss: 0.3530730848610401\n",
            "batch: 825 loss: 0.35331340235471725\n",
            "batch: 826 loss: 0.35339553314447403\n",
            "batch: 827 loss: 0.35375817292928696\n",
            "batch: 828 loss: 0.3538925812244415\n",
            "batch: 829 loss: 0.3540772938877344\n",
            "batch: 830 loss: 0.3541186184249818\n",
            "batch: 831 loss: 0.354202471088618\n",
            "batch: 832 loss: 0.35456443346664307\n",
            "batch: 833 loss: 0.3550190411023796\n",
            "batch: 834 loss: 0.3551432078517973\n",
            "batch: 835 loss: 0.35538150895014403\n",
            "batch: 836 loss: 0.35549079863354566\n",
            "batch: 837 loss: 0.3555703200958669\n",
            "batch: 838 loss: 0.3558119404576719\n",
            "batch: 839 loss: 0.355948493655771\n",
            "batch: 840 loss: 0.3560810690782964\n",
            "batch: 841 loss: 0.35628831678256395\n",
            "batch: 842 loss: 0.35647114972397687\n",
            "batch: 843 loss: 0.3567618716470897\n",
            "batch: 844 loss: 0.3572101678065956\n",
            "batch: 845 loss: 0.35737419382855296\n",
            "batch: 846 loss: 0.35796196464821695\n",
            "batch: 847 loss: 0.35823271713778376\n",
            "batch: 848 loss: 0.3584292124025524\n",
            "batch: 849 loss: 0.35880488831922414\n",
            "batch: 850 loss: 0.35902084965631365\n",
            "batch: 851 loss: 0.3593368900232017\n",
            "batch: 852 loss: 0.35955271480605006\n",
            "batch: 853 loss: 0.3596612434498966\n",
            "batch: 854 loss: 0.36000149528309705\n",
            "batch: 855 loss: 0.36024094007536767\n",
            "batch: 856 loss: 0.36052617214247584\n",
            "batch: 857 loss: 0.36065646464750173\n",
            "batch: 858 loss: 0.3610113601796329\n",
            "batch: 859 loss: 0.36131112433597445\n",
            "batch: 860 loss: 0.36153828118368986\n",
            "batch: 861 loss: 0.36189504150673746\n",
            "batch: 862 loss: 0.3622477586679161\n",
            "batch: 863 loss: 0.36233519576117396\n",
            "batch: 864 loss: 0.36254810954257843\n",
            "batch: 865 loss: 0.36280595494434237\n",
            "batch: 866 loss: 0.3629900164119899\n",
            "batch: 867 loss: 0.3633265451602638\n",
            "batch: 868 loss: 0.3634792090766132\n",
            "batch: 869 loss: 0.363634414087981\n",
            "batch: 870 loss: 0.3639097968451679\n",
            "batch: 871 loss: 0.364044777225703\n",
            "batch: 872 loss: 0.36413084803149104\n",
            "batch: 873 loss: 0.36431623677536845\n",
            "batch: 874 loss: 0.3645305996052921\n",
            "batch: 875 loss: 0.3646799230091274\n",
            "batch: 876 loss: 0.3649191370420158\n",
            "batch: 877 loss: 0.365243400644511\n",
            "batch: 878 loss: 0.3654611443988979\n",
            "batch: 879 loss: 0.36582839931175115\n",
            "batch: 880 loss: 0.3659779855273664\n",
            "batch: 881 loss: 0.3661629115007818\n",
            "batch: 882 loss: 0.3664138793610036\n",
            "batch: 883 loss: 0.3671057241819799\n",
            "batch: 884 loss: 0.3672141406200826\n",
            "batch: 885 loss: 0.36735019319877027\n",
            "batch: 886 loss: 0.36740758595243095\n",
            "batch: 887 loss: 0.36755665770545604\n",
            "batch: 888 loss: 0.36782192495837807\n",
            "batch: 889 loss: 0.3678955575339496\n",
            "batch: 890 loss: 0.3680256385914981\n",
            "batch: 891 loss: 0.3681650696657598\n",
            "batch: 892 loss: 0.3684719906114042\n",
            "batch: 893 loss: 0.3687788346670568\n",
            "batch: 894 loss: 0.3691841896735132\n",
            "batch: 895 loss: 0.3695459639392793\n",
            "batch: 896 loss: 0.3697894372306764\n",
            "batch: 897 loss: 0.3700630586110055\n",
            "batch: 898 loss: 0.3703366724513471\n",
            "batch: 899 loss: 0.3709926771186292\n",
            "batch: 900 loss: 0.3711051308773458\n",
            "batch: 901 loss: 0.371265408616513\n",
            "batch: 902 loss: 0.37146919713541865\n",
            "batch: 903 loss: 0.3718828655295074\n",
            "batch: 904 loss: 0.37231161136552693\n",
            "batch: 905 loss: 0.3726473864428699\n",
            "batch: 906 loss: 0.37287964911386373\n",
            "batch: 907 loss: 0.37292499880492685\n",
            "batch: 908 loss: 0.3729931171387434\n",
            "batch: 909 loss: 0.37312579026818277\n",
            "batch: 910 loss: 0.3734283918440342\n",
            "batch: 911 loss: 0.3735116834938526\n",
            "batch: 912 loss: 0.3739753613471985\n",
            "batch: 913 loss: 0.37418298533558847\n",
            "batch: 914 loss: 0.37429369059205053\n",
            "batch: 915 loss: 0.374494776904583\n",
            "batch: 916 loss: 0.374949028134346\n",
            "batch: 917 loss: 0.37502313682436944\n",
            "batch: 918 loss: 0.3753782286942005\n",
            "batch: 919 loss: 0.37554457554221155\n",
            "batch: 920 loss: 0.37585583317279814\n",
            "batch: 921 loss: 0.3762264415919781\n",
            "batch: 922 loss: 0.37653561744093894\n",
            "batch: 923 loss: 0.37687664407491683\n",
            "batch: 924 loss: 0.37715103435516356\n",
            "batch: 925 loss: 0.37751577481627463\n",
            "batch: 926 loss: 0.37758499167114495\n",
            "batch: 927 loss: 0.37779344571381807\n",
            "batch: 928 loss: 0.37810022104531527\n",
            "batch: 929 loss: 0.3782116686180234\n",
            "batch: 930 loss: 0.3783889369741082\n",
            "batch: 931 loss: 0.37866738138347866\n",
            "batch: 932 loss: 0.37874473736435177\n",
            "batch: 933 loss: 0.37886484264582393\n",
            "batch: 934 loss: 0.3793012321814895\n",
            "batch: 935 loss: 0.37961457689851524\n",
            "batch: 936 loss: 0.37974014269560574\n",
            "batch: 937 loss: 0.38000374858826397\n",
            "batch: 938 loss: 0.3801924341544509\n",
            "batch: 939 loss: 0.3802700115814805\n",
            "batch: 940 loss: 0.3806606390252709\n",
            "batch: 941 loss: 0.38081416704505683\n",
            "batch: 942 loss: 0.38086456679925323\n",
            "batch: 943 loss: 0.38100662153586745\n",
            "batch: 944 loss: 0.3812413840852678\n",
            "batch: 945 loss: 0.3814443100951612\n",
            "batch: 946 loss: 0.3817431838773191\n",
            "batch: 947 loss: 0.3818395462445915\n",
            "batch: 948 loss: 0.3819144778214395\n",
            "batch: 949 loss: 0.38231435972079636\n",
            "batch: 950 loss: 0.38274473663792014\n",
            "batch: 951 loss: 0.3831333468221128\n",
            "batch: 952 loss: 0.3832795479856431\n",
            "batch: 953 loss: 0.38368246650323273\n",
            "batch: 954 loss: 0.38386025535687807\n",
            "batch: 955 loss: 0.38413810485228894\n",
            "batch: 956 loss: 0.38422349816933277\n",
            "batch: 957 loss: 0.38459804982319473\n",
            "batch: 958 loss: 0.38488229501619936\n",
            "batch: 959 loss: 0.3850204944051802\n",
            "batch: 960 loss: 0.3851140615828335\n",
            "batch: 961 loss: 0.385462099481374\n",
            "batch: 962 loss: 0.3856130046285689\n",
            "batch: 963 loss: 0.3857270092628896\n",
            "batch: 964 loss: 0.3861271287463605\n",
            "batch: 965 loss: 0.38636708694323896\n",
            "batch: 966 loss: 0.3865504231713712\n",
            "batch: 967 loss: 0.38672937056049705\n",
            "batch: 968 loss: 0.38692741575464606\n",
            "batch: 969 loss: 0.3871027650050819\n",
            "batch: 970 loss: 0.38725434881076215\n",
            "batch: 971 loss: 0.3874824214540422\n",
            "batch: 972 loss: 0.3876223540864885\n",
            "batch: 973 loss: 0.38781869190558793\n",
            "batch: 974 loss: 0.38854228978976607\n",
            "batch: 975 loss: 0.38872251960262655\n",
            "batch: 976 loss: 0.38893111316487194\n",
            "batch: 977 loss: 0.3890617293380201\n",
            "batch: 978 loss: 0.3892044429592788\n",
            "batch: 979 loss: 0.38938403980061415\n",
            "batch: 980 loss: 0.3894566232524812\n",
            "batch: 981 loss: 0.38963204964622855\n",
            "batch: 982 loss: 0.38979073583707213\n",
            "batch: 983 loss: 0.38987100711092354\n",
            "batch: 984 loss: 0.3900664722137153\n",
            "batch: 985 loss: 0.39024804561957716\n",
            "batch: 986 loss: 0.3903914938084781\n",
            "batch: 987 loss: 0.3905703035853803\n",
            "batch: 988 loss: 0.39101775642856956\n",
            "batch: 989 loss: 0.3911647089980543\n",
            "batch: 990 loss: 0.39130099112913014\n",
            "batch: 991 loss: 0.39138989397510887\n",
            "batch: 992 loss: 0.3919420402906835\n",
            "batch: 993 loss: 0.39214585241302846\n",
            "batch: 994 loss: 0.39222880978509783\n",
            "batch: 995 loss: 0.3924045992009342\n",
            "batch: 996 loss: 0.392502128187567\n",
            "batch: 997 loss: 0.3926642971225083\n",
            "batch: 998 loss: 0.3927710955925286\n",
            "batch: 1000 loss: 0.3928805594146252\n",
            "batch: 1001 loss: 0.3930480619817972\n",
            "batch: 1002 loss: 0.3931474997997284\n",
            "batch: 1003 loss: 0.3933037049472332\n",
            "batch: 1004 loss: 0.39368866908550265\n",
            "batch: 1005 loss: 0.3939158346056938\n",
            "batch: 1006 loss: 0.39415539866685867\n",
            "batch: 1007 loss: 0.3944630397260189\n",
            "batch: 1008 loss: 0.3945600560158491\n",
            "batch: 1009 loss: 0.3946758206784725\n",
            "batch: 1010 loss: 0.3947783585712314\n",
            "batch: 1011 loss: 0.39522935336083176\n",
            "batch: 1012 loss: 0.39536422496289014\n",
            "batch: 1013 loss: 0.3954325593784451\n",
            "batch: 1014 loss: 0.3956219181492925\n",
            "batch: 1015 loss: 0.39581263229995967\n",
            "batch: 1016 loss: 0.39603426919132473\n",
            "batch: 1017 loss: 0.39635608602315187\n",
            "batch: 1018 loss: 0.3965800186917186\n",
            "batch: 1019 loss: 0.39684198313206437\n",
            "batch: 1020 loss: 0.3971985448226333\n",
            "batch: 1021 loss: 0.3973317370042205\n",
            "batch: 1022 loss: 0.3976652358993888\n",
            "batch: 1023 loss: 0.3978749875947833\n",
            "batch: 1024 loss: 0.39803692034631966\n",
            "batch: 1025 loss: 0.3981765138581395\n",
            "batch: 1026 loss: 0.39857632107287644\n",
            "batch: 1027 loss: 0.39890586153417823\n",
            "batch: 1028 loss: 0.39911520304530856\n",
            "batch: 1029 loss: 0.39934166430681944\n",
            "batch: 1030 loss: 0.39959036149829624\n",
            "batch: 1031 loss: 0.3996993710026145\n",
            "batch: 1032 loss: 0.40036644830554724\n",
            "batch: 1033 loss: 0.40041148321703074\n",
            "batch: 1034 loss: 0.4006820138581097\n",
            "batch: 1035 loss: 0.40084515504911544\n",
            "batch: 1036 loss: 0.4011036056168377\n",
            "batch: 1037 loss: 0.4012550865896046\n",
            "batch: 1038 loss: 0.4014963578470051\n",
            "batch: 1039 loss: 0.40158394277468323\n",
            "batch: 1040 loss: 0.4018856688775122\n",
            "batch: 1041 loss: 0.4020568188019097\n",
            "batch: 1042 loss: 0.40216541844978926\n",
            "batch: 1043 loss: 0.4022132322750986\n",
            "batch: 1044 loss: 0.40227888939902184\n",
            "batch: 1045 loss: 0.40244219129905107\n",
            "batch: 1046 loss: 0.40268499587103723\n",
            "batch: 1047 loss: 0.40318409852311016\n",
            "batch: 1048 loss: 0.4033641677610576\n",
            "batch: 1049 loss: 0.4037431442849338\n",
            "batch: 1050 loss: 0.40384954572841525\n",
            "batch: 1051 loss: 0.40455358565971256\n",
            "batch: 1052 loss: 0.40462164325639605\n",
            "batch: 1053 loss: 0.40497079188749197\n",
            "batch: 1054 loss: 0.40513503282889723\n",
            "batch: 1055 loss: 0.4054738663993776\n",
            "batch: 1056 loss: 0.4055821914635599\n",
            "batch: 1057 loss: 0.40574928709492086\n",
            "batch: 1058 loss: 0.405941641073674\n",
            "batch: 1059 loss: 0.4060542114265263\n",
            "batch: 1060 loss: 0.4062162438519299\n",
            "batch: 1061 loss: 0.4064752324707806\n",
            "batch: 1062 loss: 0.4067467205412686\n",
            "batch: 1063 loss: 0.40690106973424556\n",
            "batch: 1064 loss: 0.40709346360340715\n",
            "batch: 1065 loss: 0.4072611405141652\n",
            "batch: 1066 loss: 0.4076055874712765\n",
            "batch: 1067 loss: 0.4077838930375874\n",
            "batch: 1068 loss: 0.40827936174347995\n",
            "batch: 1069 loss: 0.40866248090937735\n",
            "batch: 1070 loss: 0.4088257905580103\n",
            "batch: 1071 loss: 0.40898202908411624\n",
            "batch: 1072 loss: 0.4091477261371911\n",
            "batch: 1073 loss: 0.4095641525872052\n",
            "batch: 1074 loss: 0.40973156638816\n",
            "batch: 1075 loss: 0.41017901350930336\n",
            "batch: 1076 loss: 0.4102559789456427\n",
            "batch: 1077 loss: 0.4105899723507464\n",
            "batch: 1078 loss: 0.41066172294691206\n",
            "batch: 1079 loss: 0.410785936165601\n",
            "batch: 1080 loss: 0.41095633650198576\n",
            "batch: 1081 loss: 0.41115591848269106\n",
            "batch: 1082 loss: 0.41145659017935393\n",
            "batch: 1083 loss: 0.4116231414861977\n",
            "batch: 1084 loss: 0.41180442221835256\n",
            "batch: 1085 loss: 0.4118653727211058\n",
            "batch: 1086 loss: 0.41190422113612296\n",
            "batch: 1087 loss: 0.4120922136195004\n",
            "batch: 1088 loss: 0.41254986955597994\n",
            "batch: 1089 loss: 0.41265563951805234\n",
            "batch: 1090 loss: 0.4127366577424109\n",
            "batch: 1091 loss: 0.41309824061766265\n",
            "batch: 1092 loss: 0.4132315136231482\n",
            "batch: 1093 loss: 0.41326813389360906\n",
            "batch: 1094 loss: 0.413352762080729\n",
            "batch: 1095 loss: 0.4134018510207534\n",
            "batch: 1096 loss: 0.41346650492399933\n",
            "batch: 1097 loss: 0.41353942395746707\n",
            "batch: 1098 loss: 0.4136938420385122\n",
            "batch: 1099 loss: 0.41390283262729644\n",
            "batch: 1100 loss: 0.4141102831661701\n",
            "batch: 1101 loss: 0.41425421652197836\n",
            "batch: 1102 loss: 0.4145681197345257\n",
            "batch: 1103 loss: 0.41472144301235675\n",
            "batch: 1104 loss: 0.41492031747102737\n",
            "batch: 1105 loss: 0.4149797511175275\n",
            "batch: 1106 loss: 0.4150844085738063\n",
            "batch: 1107 loss: 0.41524366875737906\n",
            "batch: 1108 loss: 0.41535975036025047\n",
            "batch: 1109 loss: 0.41573760530352594\n",
            "batch: 1110 loss: 0.41581853304058314\n",
            "batch: 1111 loss: 0.4162259173765779\n",
            "batch: 1112 loss: 0.41669391945749523\n",
            "batch: 1113 loss: 0.4168900345787406\n",
            "batch: 1114 loss: 0.4172451744899154\n",
            "batch: 1115 loss: 0.4175533373877406\n",
            "batch: 1116 loss: 0.4176016973555088\n",
            "batch: 1117 loss: 0.4177608852982521\n",
            "batch: 1118 loss: 0.41789180907607076\n",
            "batch: 1119 loss: 0.4182427547574043\n",
            "batch: 1120 loss: 0.4184109514057636\n",
            "batch: 1121 loss: 0.41862308463454245\n",
            "batch: 1122 loss: 0.4187738881409168\n",
            "batch: 1123 loss: 0.41889059364795683\n",
            "batch: 1124 loss: 0.41919479009509086\n",
            "batch: 1125 loss: 0.41943202224373816\n",
            "batch: 1126 loss: 0.41961090318858624\n",
            "batch: 1127 loss: 0.41984248654544354\n",
            "batch: 1128 loss: 0.42015317086875437\n",
            "batch: 1129 loss: 0.4203397179543972\n",
            "batch: 1130 loss: 0.42060564824938773\n",
            "batch: 1131 loss: 0.42081954860687254\n",
            "batch: 1132 loss: 0.42108127585053445\n",
            "batch: 1133 loss: 0.42117124661058186\n",
            "batch: 1134 loss: 0.421264283336699\n",
            "batch: 1135 loss: 0.42142430313676593\n",
            "batch: 1136 loss: 0.4215864911600947\n",
            "batch: 1137 loss: 0.42186032988876104\n",
            "batch: 1138 loss: 0.4221010555252433\n",
            "batch: 1139 loss: 0.4221793569624424\n",
            "batch: 1140 loss: 0.422354468151927\n",
            "batch: 1141 loss: 0.4224953213185072\n",
            "batch: 1142 loss: 0.42260168083012106\n",
            "batch: 1143 loss: 0.42273814816772937\n",
            "batch: 1144 loss: 0.42287649144232275\n",
            "batch: 1145 loss: 0.4229506529271603\n",
            "batch: 1146 loss: 0.42317787402868273\n",
            "batch: 1147 loss: 0.42323192626982925\n",
            "batch: 1148 loss: 0.42330767430365085\n",
            "batch: 1149 loss: 0.4233937276005745\n",
            "batch: 1150 loss: 0.42378718927502634\n",
            "batch: 1151 loss: 0.42439943012595177\n",
            "batch: 1152 loss: 0.4245386305749416\n",
            "batch: 1153 loss: 0.4247954796552658\n",
            "batch: 1154 loss: 0.4254003722667694\n",
            "batch: 1155 loss: 0.42570009937882425\n",
            "batch: 1156 loss: 0.42584031499922276\n",
            "batch: 1157 loss: 0.426087185382843\n",
            "batch: 1158 loss: 0.4263856829702854\n",
            "batch: 1159 loss: 0.4267119647562504\n",
            "batch: 1160 loss: 0.42679318740963934\n",
            "batch: 1161 loss: 0.42700999650359156\n",
            "batch: 1162 loss: 0.4272378113716841\n",
            "batch: 1163 loss: 0.4273362177759409\n",
            "batch: 1164 loss: 0.4275629336386919\n",
            "batch: 1165 loss: 0.42763717260956763\n",
            "batch: 1166 loss: 0.4277297679334879\n",
            "batch: 1167 loss: 0.42805048947036267\n",
            "batch: 1168 loss: 0.4281675530523062\n",
            "batch: 1169 loss: 0.42830987681448457\n",
            "batch: 1170 loss: 0.4284356940090656\n",
            "batch: 1171 loss: 0.4284897545799613\n",
            "batch: 1172 loss: 0.4285918367654085\n",
            "batch: 1173 loss: 0.42870284473150966\n",
            "batch: 1174 loss: 0.4288265994787216\n",
            "batch: 1175 loss: 0.42908385035395624\n",
            "batch: 1176 loss: 0.42915061936527493\n",
            "batch: 1177 loss: 0.4293264135196805\n",
            "batch: 1178 loss: 0.42963466057926414\n",
            "batch: 1179 loss: 0.4298521131947637\n",
            "batch: 1180 loss: 0.4300347220376134\n",
            "batch: 1181 loss: 0.4301257778927684\n",
            "batch: 1182 loss: 0.430348632954061\n",
            "batch: 1183 loss: 0.4307076902613044\n",
            "batch: 1184 loss: 0.4310599332675338\n",
            "batch: 1185 loss: 0.4311271506622434\n",
            "batch: 1186 loss: 0.4316176270917058\n",
            "batch: 1187 loss: 0.43164494168572126\n",
            "batch: 1188 loss: 0.43198446100763976\n",
            "batch: 1189 loss: 0.4321795567255467\n",
            "batch: 1190 loss: 0.43222931163199246\n",
            "batch: 1191 loss: 0.43256505064852535\n",
            "batch: 1192 loss: 0.43261577030457554\n",
            "batch: 1193 loss: 0.4329504213873297\n",
            "batch: 1194 loss: 0.43354849904216824\n",
            "batch: 1195 loss: 0.433723214501515\n",
            "batch: 1196 loss: 0.4338778591696173\n",
            "batch: 1197 loss: 0.43412977665103974\n",
            "batch: 1198 loss: 0.434267614627257\n",
            "batch: 1199 loss: 0.4343559576291591\n",
            "batch: 1200 loss: 0.4346120422501117\n",
            "batch: 1201 loss: 0.43505852949805557\n",
            "batch: 1202 loss: 0.43524391974695026\n",
            "batch: 1203 loss: 0.4355388058591634\n",
            "batch: 1204 loss: 0.4360198059845716\n",
            "batch: 1205 loss: 0.43655492200143636\n",
            "batch: 1206 loss: 0.4367276317495853\n",
            "batch: 1207 loss: 0.43687381178326906\n",
            "batch: 1208 loss: 0.4369914262462407\n",
            "batch: 1209 loss: 0.43723812031932174\n",
            "batch: 1210 loss: 0.43761502003856\n",
            "batch: 1211 loss: 0.43770165207423267\n",
            "batch: 1212 loss: 0.43795110932923853\n",
            "batch: 1213 loss: 0.43809250559844076\n",
            "batch: 1214 loss: 0.4382941895965487\n",
            "batch: 1215 loss: 0.4386974331382662\n",
            "batch: 1216 loss: 0.43911424049176273\n",
            "batch: 1217 loss: 0.4392220926228911\n",
            "batch: 1218 loss: 0.4395172696057707\n",
            "batch: 1219 loss: 0.43989621081389485\n",
            "batch: 1220 loss: 0.44020680424012243\n",
            "batch: 1221 loss: 0.4403845680896193\n",
            "batch: 1222 loss: 0.440673930818215\n",
            "batch: 1223 loss: 0.44096322085894646\n",
            "batch: 1224 loss: 0.4411097552422434\n",
            "batch: 1225 loss: 0.44126495228149\n",
            "batch: 1226 loss: 0.44133187175728383\n",
            "batch: 1227 loss: 0.44163999552465977\n",
            "batch: 1228 loss: 0.441781364062801\n",
            "batch: 1229 loss: 0.4420248215589672\n",
            "batch: 1230 loss: 0.4423048528227955\n",
            "batch: 1231 loss: 0.44243152981437744\n",
            "batch: 1232 loss: 0.4427300485018641\n",
            "batch: 1233 loss: 0.4429318363312632\n",
            "batch: 1234 loss: 0.4430768899265677\n",
            "batch: 1235 loss: 0.44362171828188\n",
            "batch: 1236 loss: 0.4436677551884204\n",
            "batch: 1237 loss: 0.44416427838988604\n",
            "batch: 1238 loss: 0.4445009086150676\n",
            "batch: 1239 loss: 0.44471318373270335\n",
            "batch: 1240 loss: 0.44478694202192126\n",
            "batch: 1241 loss: 0.44484482164122163\n",
            "batch: 1242 loss: 0.44495438612438737\n",
            "batch: 1243 loss: 0.44507458052970467\n",
            "batch: 1244 loss: 0.44533278835751117\n",
            "batch: 1245 loss: 0.4454464465174824\n",
            "batch: 1246 loss: 0.4457073530945927\n",
            "batch: 1247 loss: 0.44581327604688703\n",
            "batch: 1248 loss: 0.4461783955935389\n",
            "batch: 1249 loss: 0.4463483117762953\n",
            "batch: 1250 loss: 0.4465826749894768\n",
            "batch: 1251 loss: 0.4466973865944892\n",
            "batch: 1252 loss: 0.4469609667677432\n",
            "batch: 1253 loss: 0.4472325713951141\n",
            "batch: 1254 loss: 0.44756855991669\n",
            "batch: 1255 loss: 0.4476875385660678\n",
            "batch: 1256 loss: 0.4477944586593658\n",
            "batch: 1257 loss: 0.4481339624840766\n",
            "batch: 1258 loss: 0.448316238405183\n",
            "batch: 1259 loss: 0.4484642579574138\n",
            "batch: 1260 loss: 0.44855034239031377\n",
            "batch: 1261 loss: 0.4488104714844376\n",
            "batch: 1262 loss: 0.44899110933579506\n",
            "batch: 1263 loss: 0.44908665876276793\n",
            "batch: 1264 loss: 0.44919477568753063\n",
            "batch: 1265 loss: 0.44936067165620625\n",
            "batch: 1266 loss: 0.44946868284232916\n",
            "batch: 1267 loss: 0.4496851027328521\n",
            "batch: 1268 loss: 0.44991164793260396\n",
            "batch: 1269 loss: 0.45008859132416545\n",
            "batch: 1270 loss: 0.4503006223458797\n",
            "batch: 1271 loss: 0.45039024550653994\n",
            "batch: 1272 loss: 0.4505926417801529\n",
            "batch: 1273 loss: 0.4509000053498894\n",
            "batch: 1274 loss: 0.45108106994070113\n",
            "batch: 1275 loss: 0.451199126014486\n",
            "batch: 1276 loss: 0.45148425907827916\n",
            "batch: 1277 loss: 0.4515599788594991\n",
            "batch: 1278 loss: 0.4517659492511302\n",
            "batch: 1279 loss: 0.45202451032586394\n",
            "batch: 1280 loss: 0.45212910618819296\n",
            "batch: 1281 loss: 0.4525341584030539\n",
            "batch: 1282 loss: 0.45274510022439063\n",
            "batch: 1283 loss: 0.45320755984820427\n",
            "batch: 1284 loss: 0.45334233426488935\n",
            "batch: 1285 loss: 0.4533753415439278\n",
            "batch: 1286 loss: 0.4535977813694626\n",
            "batch: 1287 loss: 0.45368866148777304\n",
            "batch: 1288 loss: 0.45397628426738085\n",
            "batch: 1289 loss: 0.45410874468274415\n",
            "batch: 1290 loss: 0.4543948072809726\n",
            "batch: 1291 loss: 0.4545720352996141\n",
            "batch: 1292 loss: 0.45516876004822554\n",
            "batch: 1293 loss: 0.4552815241906792\n",
            "batch: 1294 loss: 0.455443014184013\n",
            "batch: 1295 loss: 0.455731009343639\n",
            "batch: 1296 loss: 0.45585216931439937\n",
            "batch: 1297 loss: 0.45600079927779735\n",
            "batch: 1298 loss: 0.45614912412501873\n",
            "batch: 1299 loss: 0.4564045400414616\n",
            "batch: 1300 loss: 0.45644656802155076\n",
            "batch: 1301 loss: 0.45665208233334126\n",
            "batch: 1302 loss: 0.45679228244163095\n",
            "batch: 1303 loss: 0.45702765584923327\n",
            "batch: 1304 loss: 0.4571705955360085\n",
            "batch: 1305 loss: 0.4572461207453161\n",
            "batch: 1306 loss: 0.4573304740730673\n",
            "batch: 1307 loss: 0.4576078953091055\n",
            "batch: 1308 loss: 0.4577618762794882\n",
            "batch: 1309 loss: 0.45796772416867315\n",
            "batch: 1310 loss: 0.45806316595710816\n",
            "batch: 1311 loss: 0.45811793470196427\n",
            "batch: 1312 loss: 0.45823657687567176\n",
            "batch: 1313 loss: 0.458470309978351\n",
            "batch: 1314 loss: 0.45877630574069916\n",
            "batch: 1315 loss: 0.4596202963050455\n",
            "batch: 1316 loss: 0.4598052306678146\n",
            "batch: 1317 loss: 0.4599894940610975\n",
            "batch: 1318 loss: 0.4603290337081999\n",
            "batch: 1319 loss: 0.4604588871952146\n",
            "batch: 1320 loss: 0.4607575003560632\n",
            "batch: 1321 loss: 0.4608799536731094\n",
            "batch: 1322 loss: 0.4610965805854648\n",
            "batch: 1323 loss: 0.46114136967621744\n",
            "batch: 1324 loss: 0.46145332241617143\n",
            "batch: 1325 loss: 0.4616614714320749\n",
            "batch: 1326 loss: 0.4618265416380018\n",
            "batch: 1327 loss: 0.46197705519758164\n",
            "batch: 1328 loss: 0.46215908380411563\n",
            "batch: 1329 loss: 0.4623714999165386\n",
            "batch: 1330 loss: 0.46244494163058697\n",
            "batch: 1331 loss: 0.46254870609007775\n",
            "batch: 1332 loss: 0.4626238430198282\n",
            "batch: 1333 loss: 0.4629779300745577\n",
            "batch: 1334 loss: 0.4632770195957273\n",
            "batch: 1335 loss: 0.4635413260217756\n",
            "batch: 1336 loss: 0.4637251179423183\n",
            "batch: 1337 loss: 0.46391208772920073\n",
            "batch: 1338 loss: 0.4639955372121185\n",
            "batch: 1339 loss: 0.46413564311526717\n",
            "batch: 1340 loss: 0.4645733624603599\n",
            "batch: 1341 loss: 0.46469166552089153\n",
            "batch: 1342 loss: 0.46478103186003866\n",
            "batch: 1343 loss: 0.4648894106280059\n",
            "batch: 1344 loss: 0.4649861576091498\n",
            "batch: 1345 loss: 0.4652409983705729\n",
            "batch: 1346 loss: 0.4653587400969118\n",
            "batch: 1347 loss: 0.4654699979480356\n",
            "batch: 1348 loss: 0.46555550681613384\n",
            "batch: 1349 loss: 0.4658099793996662\n",
            "batch: 1350 loss: 0.46616130184195936\n",
            "batch: 1351 loss: 0.4661790826972574\n",
            "batch: 1352 loss: 0.4663073861952871\n",
            "batch: 1353 loss: 0.46659488389454784\n",
            "batch: 1354 loss: 0.4667910005506128\n",
            "batch: 1355 loss: 0.46684393896721305\n",
            "batch: 1356 loss: 0.4670613347794861\n",
            "batch: 1357 loss: 0.46710126313753425\n",
            "batch: 1358 loss: 0.46725304165668785\n",
            "batch: 1359 loss: 0.46763757762499153\n",
            "batch: 1360 loss: 0.46787950171716514\n",
            "batch: 1361 loss: 0.46805593927390876\n",
            "batch: 1362 loss: 0.4682346139270812\n",
            "batch: 1363 loss: 0.4683661226946861\n",
            "batch: 1364 loss: 0.4687368035633117\n",
            "batch: 1365 loss: 0.46885228433646264\n",
            "batch: 1366 loss: 0.46919190197624266\n",
            "batch: 1367 loss: 0.46924405903182925\n",
            "batch: 1368 loss: 0.46944575778208675\n",
            "batch: 1369 loss: 0.4698161827083677\n",
            "batch: 1370 loss: 0.46999565914832053\n",
            "batch: 1371 loss: 0.4701424040403217\n",
            "batch: 1372 loss: 0.4702919617202133\n",
            "batch: 1373 loss: 0.4705222036149353\n",
            "batch: 1374 loss: 0.47072517160139976\n",
            "batch: 1375 loss: 0.4709092038180679\n",
            "batch: 1376 loss: 0.4710940000768751\n",
            "batch: 1377 loss: 0.47113703419454395\n",
            "batch: 1378 loss: 0.4712746474761516\n",
            "batch: 1379 loss: 0.4715652895886451\n",
            "batch: 1380 loss: 0.4717477426547557\n",
            "batch: 1381 loss: 0.471967792885378\n",
            "batch: 1382 loss: 0.472173133360222\n",
            "batch: 1383 loss: 0.472315051721409\n",
            "batch: 1384 loss: 0.47234765871427953\n",
            "batch: 1385 loss: 0.47244385433755814\n",
            "batch: 1386 loss: 0.4726622621174902\n",
            "batch: 1387 loss: 0.47298776361905037\n",
            "batch: 1388 loss: 0.4731994763817638\n",
            "batch: 1389 loss: 0.4734001360591501\n",
            "batch: 1390 loss: 0.47363185756467285\n",
            "batch: 1391 loss: 0.47374397253058853\n",
            "batch: 1392 loss: 0.474238628199324\n",
            "batch: 1393 loss: 0.47426362392492594\n",
            "batch: 1394 loss: 0.474356623435393\n",
            "batch: 1395 loss: 0.47454478130675853\n",
            "batch: 1396 loss: 0.4746178511921316\n",
            "batch: 1397 loss: 0.4748414390925318\n",
            "batch: 1398 loss: 0.47501183644868433\n",
            "batch: 1399 loss: 0.4750585722941905\n",
            "batch: 1400 loss: 0.47509705292247234\n",
            "batch: 1401 loss: 0.4752963874395937\n",
            "batch: 1402 loss: 0.4755623586829752\n",
            "batch: 1403 loss: 0.47584919804893433\n",
            "batch: 1404 loss: 0.47592027761600914\n",
            "batch: 1405 loss: 0.4762282079961151\n",
            "batch: 1406 loss: 0.47633164159767327\n",
            "batch: 1407 loss: 0.4766249017547816\n",
            "batch: 1408 loss: 0.47672792450897394\n",
            "batch: 1409 loss: 0.47681920531205835\n",
            "batch: 1410 loss: 0.47715955158881845\n",
            "batch: 1411 loss: 0.4773089601378888\n",
            "batch: 1412 loss: 0.47752861268632113\n",
            "batch: 1413 loss: 0.47766985609941187\n",
            "batch: 1414 loss: 0.47787705132178965\n",
            "batch: 1415 loss: 0.47807525527291\n",
            "batch: 1416 loss: 0.4782061038892716\n",
            "batch: 1417 loss: 0.47830101766996086\n",
            "batch: 1418 loss: 0.47849554766528307\n",
            "batch: 1419 loss: 0.4785529994983226\n",
            "batch: 1420 loss: 0.47884241774864494\n",
            "batch: 1421 loss: 0.47906884822435675\n",
            "batch: 1422 loss: 0.4792492514718324\n",
            "batch: 1423 loss: 0.47936670689471067\n",
            "batch: 1424 loss: 0.47940962369553747\n",
            "batch: 1425 loss: 0.4795750500988215\n",
            "batch: 1426 loss: 0.47976458477787676\n",
            "batch: 1427 loss: 0.47979411795176563\n",
            "batch: 1428 loss: 0.48041695638932286\n",
            "batch: 1429 loss: 0.48049217464961114\n",
            "batch: 1430 loss: 0.48081373670138416\n",
            "batch: 1431 loss: 0.48093785204924644\n",
            "batch: 1432 loss: 0.4810529251936823\n",
            "batch: 1433 loss: 0.48130418082512916\n",
            "batch: 1434 loss: 0.4814835271332413\n",
            "batch: 1435 loss: 0.4815363416429609\n",
            "batch: 1436 loss: 0.4816265708412975\n",
            "batch: 1437 loss: 0.4817714294251055\n",
            "batch: 1438 loss: 0.48191611746512353\n",
            "batch: 1439 loss: 0.4819377810433507\n",
            "batch: 1440 loss: 0.4824423003271222\n",
            "batch: 1441 loss: 0.48268558648973703\n",
            "batch: 1442 loss: 0.4829495486691594\n",
            "batch: 1443 loss: 0.4830438943132758\n",
            "batch: 1444 loss: 0.48321863120049235\n",
            "batch: 1445 loss: 0.4832445232756436\n",
            "batch: 1446 loss: 0.4833743656016886\n",
            "batch: 1447 loss: 0.48351330821588634\n",
            "batch: 1448 loss: 0.48376689122989774\n",
            "batch: 1449 loss: 0.4838369315452874\n",
            "batch: 1450 loss: 0.48408706482127306\n",
            "batch: 1451 loss: 0.48417240802571176\n",
            "batch: 1452 loss: 0.48438609997555615\n",
            "batch: 1453 loss: 0.484592612426728\n",
            "batch: 1454 loss: 0.48490711871907116\n",
            "batch: 1455 loss: 0.4850062171779573\n",
            "batch: 1456 loss: 0.48518961236998437\n",
            "batch: 1457 loss: 0.48533130511268974\n",
            "batch: 1458 loss: 0.48553211469575763\n",
            "batch: 1459 loss: 0.48564980398491026\n",
            "batch: 1460 loss: 0.4858284190185368\n",
            "batch: 1461 loss: 0.486031505394727\n",
            "batch: 1462 loss: 0.48610535870864985\n",
            "batch: 1463 loss: 0.48618112090602517\n",
            "batch: 1464 loss: 0.4862777280323207\n",
            "batch: 1465 loss: 0.4865175889842212\n",
            "batch: 1466 loss: 0.4865950779132545\n",
            "batch: 1467 loss: 0.4870216586701572\n",
            "batch: 1468 loss: 0.48708983478322626\n",
            "batch: 1469 loss: 0.4872752040065825\n",
            "batch: 1470 loss: 0.4874219696111977\n",
            "batch: 1471 loss: 0.48783810453489423\n",
            "batch: 1472 loss: 0.4879080083705485\n",
            "batch: 1473 loss: 0.4879947771690786\n",
            "batch: 1474 loss: 0.48809021860733626\n",
            "batch: 1475 loss: 0.4884217137731612\n",
            "batch: 1476 loss: 0.48858590533211826\n",
            "batch: 1477 loss: 0.4888341832049191\n",
            "batch: 1478 loss: 0.4888975263275206\n",
            "batch: 1479 loss: 0.48921316761150957\n",
            "batch: 1480 loss: 0.4893415164984763\n",
            "batch: 1481 loss: 0.48965884364023804\n",
            "batch: 1482 loss: 0.4896849359497428\n",
            "batch: 1483 loss: 0.4898121095970273\n",
            "batch: 1484 loss: 0.4900691494718194\n",
            "batch: 1485 loss: 0.4901349879279733\n",
            "batch: 1486 loss: 0.49021310210973024\n",
            "batch: 1487 loss: 0.49051510138064625\n",
            "batch: 1488 loss: 0.4908361916914582\n",
            "batch: 1489 loss: 0.4911183808222413\n",
            "batch: 1490 loss: 0.4914983944669366\n",
            "batch: 1491 loss: 0.4916451313868165\n",
            "batch: 1492 loss: 0.4917508862093091\n",
            "batch: 1493 loss: 0.49180406338721516\n",
            "batch: 1494 loss: 0.4920251887068152\n",
            "batch: 1495 loss: 0.4921074389517307\n",
            "batch: 1496 loss: 0.4922441477030516\n",
            "batch: 1497 loss: 0.4923807131946087\n",
            "batch: 1498 loss: 0.4925931801199913\n",
            "batch: 1499 loss: 0.4928581277728081\n",
            "batch: 1500 loss: 0.49290182649344205\n",
            "batch: 1501 loss: 0.49325061943382026\n",
            "batch: 1502 loss: 0.49334387823194265\n",
            "batch: 1503 loss: 0.4936474796757102\n",
            "batch: 1504 loss: 0.4937313291728497\n",
            "batch: 1505 loss: 0.4939102945625782\n",
            "batch: 1506 loss: 0.49404817037284376\n",
            "batch: 1507 loss: 0.49420116570591927\n",
            "batch: 1508 loss: 0.49463335168361666\n",
            "batch: 1509 loss: 0.49475108098238707\n",
            "batch: 1510 loss: 0.49485158129781487\n",
            "batch: 1511 loss: 0.4952014931961894\n",
            "batch: 1512 loss: 0.49525402662158013\n",
            "batch: 1513 loss: 0.495289448030293\n",
            "batch: 1514 loss: 0.49568473757058384\n",
            "batch: 1515 loss: 0.4957608616352081\n",
            "batch: 1516 loss: 0.4959779302179813\n",
            "batch: 1517 loss: 0.496356429040432\n",
            "batch: 1518 loss: 0.4966333031654358\n",
            "batch: 1519 loss: 0.4967589734196663\n",
            "batch: 1520 loss: 0.4968546066880226\n",
            "batch: 1521 loss: 0.4970675197094679\n",
            "batch: 1522 loss: 0.49724292229115963\n",
            "batch: 1523 loss: 0.49731444169580935\n",
            "batch: 1524 loss: 0.49736057038605214\n",
            "batch: 1525 loss: 0.49755967390537265\n",
            "batch: 1526 loss: 0.4977161086201668\n",
            "batch: 1527 loss: 0.49794158938527106\n",
            "batch: 1528 loss: 0.49816679932177066\n",
            "batch: 1529 loss: 0.4982396613508463\n",
            "batch: 1530 loss: 0.49841143722832204\n",
            "batch: 1531 loss: 0.49886364986002446\n",
            "batch: 1532 loss: 0.499214306846261\n",
            "batch: 1533 loss: 0.4993006914481521\n",
            "batch: 1534 loss: 0.49934612404555084\n",
            "batch: 1535 loss: 0.49965366514772175\n",
            "batch: 1536 loss: 0.499772670827806\n",
            "batch: 1537 loss: 0.4999057423695922\n",
            "batch: 1538 loss: 0.4999312402177602\n",
            "batch: 1539 loss: 0.5000008544046431\n",
            "batch: 1540 loss: 0.5001614688206464\n",
            "batch: 1541 loss: 0.5005330582428723\n",
            "batch: 1542 loss: 0.5008110042382031\n",
            "batch: 1543 loss: 0.5010213888455183\n",
            "batch: 1544 loss: 0.5010858603287488\n",
            "batch: 1545 loss: 0.5012992977071553\n",
            "batch: 1546 loss: 0.5015385172981769\n",
            "batch: 1547 loss: 0.5019496898073703\n",
            "batch: 1548 loss: 0.5020731671247631\n",
            "batch: 1549 loss: 0.5024913041386754\n",
            "batch: 1550 loss: 0.5027142981830984\n",
            "batch: 1551 loss: 0.5029403603021055\n",
            "batch: 1552 loss: 0.5031521614734084\n",
            "batch: 1553 loss: 0.5034423543754966\n",
            "batch: 1554 loss: 0.5036846652124077\n",
            "batch: 1555 loss: 0.5039639793131501\n",
            "batch: 1556 loss: 0.5043995837066323\n",
            "batch: 1557 loss: 0.5046127256546169\n",
            "batch: 1558 loss: 0.5047271065358072\n",
            "batch: 1559 loss: 0.5048921163324267\n",
            "batch: 1560 loss: 0.5054549937490374\n",
            "batch: 1561 loss: 0.5055998108331115\n",
            "batch: 1562 loss: 0.5056741483006626\n",
            "batch: 1563 loss: 0.5059520176444202\n",
            "batch: 1564 loss: 0.5060303442720324\n",
            "batch: 1565 loss: 0.5061013673860579\n",
            "batch: 1566 loss: 0.5063479219097644\n",
            "batch: 1567 loss: 0.5065889645237476\n",
            "batch: 1568 loss: 0.5067634907085449\n",
            "batch: 1569 loss: 0.5068145328778774\n",
            "batch: 1570 loss: 0.506998620154336\n",
            "batch: 1571 loss: 0.5072898144740612\n",
            "batch: 1572 loss: 0.50752548504062\n",
            "batch: 1573 loss: 0.5076281059402973\n",
            "batch: 1574 loss: 0.507786230744794\n",
            "batch: 1575 loss: 0.5078574273083359\n",
            "batch: 1576 loss: 0.5080220234487206\n",
            "batch: 1577 loss: 0.5081071555409581\n",
            "batch: 1578 loss: 0.5081537933219225\n",
            "batch: 1579 loss: 0.5082146396879107\n",
            "batch: 1580 loss: 0.5083315587881952\n",
            "batch: 1581 loss: 0.508370712922886\n",
            "batch: 1582 loss: 0.5084506866652518\n",
            "batch: 1583 loss: 0.5086964275408536\n",
            "batch: 1584 loss: 0.509021104471758\n",
            "batch: 1585 loss: 0.5092167264092714\n",
            "batch: 1586 loss: 0.5093255687300116\n",
            "batch: 1587 loss: 0.5095855500046164\n",
            "batch: 1588 loss: 0.5098303603623062\n",
            "batch: 1589 loss: 0.5099950961563736\n",
            "batch: 1590 loss: 0.5101689741257578\n",
            "batch: 1591 loss: 0.5103151350710541\n",
            "batch: 1592 loss: 0.5104050686154514\n",
            "batch: 1593 loss: 0.5105405073557049\n",
            "batch: 1594 loss: 0.5106223875824362\n",
            "batch: 1595 loss: 0.5107692120168358\n",
            "batch: 1596 loss: 0.5110124973449856\n",
            "batch: 1597 loss: 0.5114556430969387\n",
            "batch: 1598 loss: 0.511592373052612\n",
            "batch: 1599 loss: 0.511783595988527\n",
            "batch: 1600 loss: 0.5118165487963706\n",
            "batch: 1601 loss: 0.5120241308677942\n",
            "batch: 1602 loss: 0.5121331853438169\n",
            "batch: 1603 loss: 0.5121834050584585\n",
            "batch: 1604 loss: 0.5122586029339582\n",
            "batch: 1605 loss: 0.5125393339563161\n",
            "batch: 1606 loss: 0.5128571406174451\n",
            "batch: 1607 loss: 0.5130558160115033\n",
            "batch: 1608 loss: 0.5131528822798281\n",
            "batch: 1609 loss: 0.5133904541004449\n",
            "batch: 1610 loss: 0.5134256360251457\n",
            "batch: 1611 loss: 0.5135184977669269\n",
            "batch: 1612 loss: 0.5138956471104175\n",
            "batch: 1613 loss: 0.5140636811275036\n",
            "batch: 1614 loss: 0.51421667608805\n",
            "batch: 1615 loss: 0.514405070187524\n",
            "batch: 1616 loss: 0.5145226014126092\n",
            "batch: 1617 loss: 0.514782126115635\n",
            "batch: 1618 loss: 0.514865291127935\n",
            "batch: 1619 loss: 0.5151333312187344\n",
            "batch: 1620 loss: 0.5153466537389905\n",
            "batch: 1621 loss: 0.5155319994781167\n",
            "batch: 1622 loss: 0.5156488970909268\n",
            "batch: 1623 loss: 0.5158907600734383\n",
            "batch: 1624 loss: 0.516100506329909\n",
            "batch: 1625 loss: 0.5161567007619887\n",
            "batch: 1626 loss: 0.5162558875251562\n",
            "batch: 1627 loss: 0.5163747756872327\n",
            "batch: 1628 loss: 0.5164338986556977\n",
            "batch: 1629 loss: 0.5168515782337636\n",
            "batch: 1630 loss: 0.5170059044342488\n",
            "batch: 1631 loss: 0.5170784538369626\n",
            "batch: 1632 loss: 0.5172502884548158\n",
            "batch: 1633 loss: 0.5174027073662728\n",
            "batch: 1634 loss: 0.5174808385428041\n",
            "batch: 1635 loss: 0.5178312752302736\n",
            "batch: 1636 loss: 0.5179628817494959\n",
            "batch: 1637 loss: 0.5180795175191015\n",
            "batch: 1638 loss: 0.5181237029563636\n",
            "batch: 1639 loss: 0.5183423818331212\n",
            "batch: 1640 loss: 0.5185394257288426\n",
            "batch: 1641 loss: 0.5185842820163816\n",
            "batch: 1642 loss: 0.5186928210239857\n",
            "batch: 1643 loss: 0.5188032592814416\n",
            "batch: 1644 loss: 0.518988117320463\n",
            "batch: 1645 loss: 0.5190628250669688\n",
            "batch: 1646 loss: 0.5191092950087041\n",
            "batch: 1647 loss: 0.5193292153459043\n",
            "batch: 1648 loss: 0.5195115905087441\n",
            "batch: 1649 loss: 0.5197495601158589\n",
            "batch: 1650 loss: 0.5200054377000779\n",
            "batch: 1651 loss: 0.5202804187815636\n",
            "batch: 1652 loss: 0.5204265810828655\n",
            "batch: 1653 loss: 0.5204672325011342\n",
            "batch: 1654 loss: 0.5205895943399519\n",
            "batch: 1655 loss: 0.5207975485082715\n",
            "batch: 1656 loss: 0.5208313136380166\n",
            "batch: 1657 loss: 0.5210358364712447\n",
            "batch: 1658 loss: 0.5211079315971583\n",
            "batch: 1659 loss: 0.5212038793992251\n",
            "batch: 1660 loss: 0.5212857229765505\n",
            "batch: 1661 loss: 0.521481559311971\n",
            "batch: 1662 loss: 0.5217443241234869\n",
            "batch: 1663 loss: 0.5218265683259815\n",
            "batch: 1664 loss: 0.521942680766806\n",
            "batch: 1665 loss: 0.5220441118832677\n",
            "batch: 1666 loss: 0.5221197924669831\n",
            "batch: 1667 loss: 0.5222023883592337\n",
            "batch: 1668 loss: 0.5222524040248245\n",
            "batch: 1669 loss: 0.5225281504001469\n",
            "batch: 1670 loss: 0.5226020368468016\n",
            "batch: 1671 loss: 0.5227103463243693\n",
            "batch: 1672 loss: 0.5230977581571787\n",
            "batch: 1673 loss: 0.5235206471513957\n",
            "batch: 1674 loss: 0.5236536693703383\n",
            "batch: 1675 loss: 0.5236963477078825\n",
            "batch: 1676 loss: 0.5240246863011271\n",
            "batch: 1677 loss: 0.5241078030113131\n",
            "batch: 1678 loss: 0.524351239958778\n",
            "batch: 1679 loss: 0.5245099135134369\n",
            "batch: 1680 loss: 0.5246692723874002\n",
            "batch: 1681 loss: 0.5247457461375743\n",
            "batch: 1682 loss: 0.5248914930839091\n",
            "batch: 1683 loss: 0.5249896578807384\n",
            "batch: 1684 loss: 0.5252849367875606\n",
            "batch: 1685 loss: 0.5253838133532553\n",
            "batch: 1686 loss: 0.5254355589468032\n",
            "batch: 1687 loss: 0.5254645041748881\n",
            "batch: 1688 loss: 0.5255011927559972\n",
            "batch: 1689 loss: 0.5255879167094827\n",
            "batch: 1690 loss: 0.5256992583498359\n",
            "batch: 1691 loss: 0.5257426377385854\n",
            "batch: 1692 loss: 0.5257824386358261\n",
            "batch: 1693 loss: 0.5259880699366332\n",
            "batch: 1694 loss: 0.5262030139565468\n",
            "batch: 1695 loss: 0.526348702982068\n",
            "batch: 1696 loss: 0.5264140623137354\n",
            "batch: 1697 loss: 0.5265903499647975\n",
            "batch: 1698 loss: 0.5270377559587359\n",
            "batch: 1699 loss: 0.5272532155141234\n",
            "batch: 1700 loss: 0.5274808384850621\n",
            "batch: 1701 loss: 0.5275978534147143\n",
            "batch: 1702 loss: 0.5276650394126773\n",
            "batch: 1703 loss: 0.5279199819490313\n",
            "batch: 1704 loss: 0.5281068957224488\n",
            "batch: 1705 loss: 0.5281838119700552\n",
            "batch: 1706 loss: 0.5283358757868409\n",
            "batch: 1707 loss: 0.5285476957038044\n",
            "batch: 1708 loss: 0.5289135699942707\n",
            "batch: 1709 loss: 0.5293360170796514\n",
            "batch: 1710 loss: 0.5295137762799859\n",
            "batch: 1711 loss: 0.5297416451796889\n",
            "batch: 1712 loss: 0.5297571393493563\n",
            "batch: 1713 loss: 0.5301886604074388\n",
            "batch: 1714 loss: 0.5302474892679602\n",
            "batch: 1715 loss: 0.5303123132530599\n",
            "batch: 1716 loss: 0.5303744732905179\n",
            "batch: 1717 loss: 0.5305142194647342\n",
            "batch: 1718 loss: 0.5308572417516262\n",
            "batch: 1719 loss: 0.5309014885965735\n",
            "batch: 1720 loss: 0.5309561317954212\n",
            "batch: 1721 loss: 0.5310831094328314\n",
            "batch: 1722 loss: 0.5311962563041598\n",
            "batch: 1723 loss: 0.5313421490136534\n",
            "batch: 1724 loss: 0.5317541922573\n",
            "batch: 1725 loss: 0.5317891531530767\n",
            "batch: 1726 loss: 0.5320907878223806\n",
            "batch: 1727 loss: 0.5323516976777464\n",
            "batch: 1728 loss: 0.5324400716591626\n",
            "batch: 1729 loss: 0.5328226033020764\n",
            "batch: 1730 loss: 0.5330022513139993\n",
            "batch: 1731 loss: 0.5330856807921082\n",
            "batch: 1732 loss: 0.5333331123981625\n",
            "batch: 1733 loss: 0.5334312622342259\n",
            "batch: 1734 loss: 0.5335631053838878\n",
            "batch: 1735 loss: 0.5336210131142288\n",
            "batch: 1736 loss: 0.5337020367328078\n",
            "batch: 1737 loss: 0.5340685203317552\n",
            "batch: 1738 loss: 0.534252189392224\n",
            "batch: 1739 loss: 0.5343967371825129\n",
            "batch: 1740 loss: 0.5344393341820687\n",
            "batch: 1741 loss: 0.534498848920688\n",
            "batch: 1742 loss: 0.5346339540537447\n",
            "batch: 1743 loss: 0.5347354577388614\n",
            "batch: 1744 loss: 0.5347937487121671\n",
            "batch: 1745 loss: 0.534818399457261\n",
            "batch: 1746 loss: 0.5350394392441958\n",
            "batch: 1747 loss: 0.5351516605746001\n",
            "batch: 1748 loss: 0.5352092993166297\n",
            "batch: 1749 loss: 0.5354437788333744\n",
            "batch: 1750 loss: 0.5355575266610831\n",
            "batch: 1751 loss: 0.5357374341320247\n",
            "batch: 1752 loss: 0.5358906381558627\n",
            "batch: 1753 loss: 0.5362845457028598\n",
            "batch: 1754 loss: 0.5363162826355546\n",
            "batch: 1755 loss: 0.5363910252656787\n",
            "batch: 1756 loss: 0.5365139689352363\n",
            "batch: 1757 loss: 0.536599898179993\n",
            "batch: 1758 loss: 0.536688926903531\n",
            "batch: 1759 loss: 0.5368575589638204\n",
            "batch: 1760 loss: 0.5369470875840634\n",
            "batch: 1761 loss: 0.5371321095805616\n",
            "batch: 1762 loss: 0.5372182807903737\n",
            "batch: 1763 loss: 0.5372591987866908\n",
            "batch: 1764 loss: 0.5374468343425542\n",
            "batch: 1765 loss: 0.5376024928260594\n",
            "batch: 1766 loss: 0.5376821909938008\n",
            "batch: 1767 loss: 0.5377720367480069\n",
            "batch: 1768 loss: 0.5378769195694476\n",
            "batch: 1769 loss: 0.5380746472496539\n",
            "batch: 1770 loss: 0.5383517751116306\n",
            "batch: 1771 loss: 0.5385074536371977\n",
            "batch: 1772 loss: 0.5385193959213793\n",
            "batch: 1773 loss: 0.5386639831848442\n",
            "batch: 1774 loss: 0.53872298739478\n",
            "batch: 1775 loss: 0.5387889623679221\n",
            "batch: 1776 loss: 0.5389594817496837\n",
            "batch: 1777 loss: 0.539255008045584\n",
            "batch: 1778 loss: 0.5392983288727701\n",
            "batch: 1779 loss: 0.539667780276388\n",
            "batch: 1780 loss: 0.5397436696104705\n",
            "batch: 1781 loss: 0.5400329576544464\n",
            "batch: 1782 loss: 0.5402110158614815\n",
            "batch: 1783 loss: 0.5403456679694355\n",
            "batch: 1784 loss: 0.540449827145785\n",
            "batch: 1785 loss: 0.5409323209635913\n",
            "batch: 1786 loss: 0.5409402321996167\n",
            "batch: 1787 loss: 0.5411131229968742\n",
            "batch: 1788 loss: 0.5411742467107251\n",
            "batch: 1789 loss: 0.5412463356526569\n",
            "batch: 1790 loss: 0.541707496133633\n",
            "batch: 1791 loss: 0.5417597045199946\n",
            "batch: 1792 loss: 0.5419361265050248\n",
            "batch: 1793 loss: 0.5422005785750226\n",
            "batch: 1794 loss: 0.5425564951347187\n",
            "batch: 1795 loss: 0.5426486976044252\n",
            "batch: 1796 loss: 0.5426803247677162\n",
            "batch: 1797 loss: 0.5427388051683083\n",
            "batch: 1798 loss: 0.5429920200342312\n",
            "batch: 1799 loss: 0.5431575096035376\n",
            "batch: 1800 loss: 0.5432647381136194\n",
            "batch: 1801 loss: 0.54332372711692\n",
            "batch: 1802 loss: 0.54349047497008\n",
            "batch: 1803 loss: 0.5435401505948976\n",
            "batch: 1804 loss: 0.5436871600570157\n",
            "batch: 1805 loss: 0.5438210744680837\n",
            "batch: 1806 loss: 0.543948014867492\n",
            "batch: 1807 loss: 0.5440953549565747\n",
            "batch: 1808 loss: 0.5441633340464905\n",
            "batch: 1809 loss: 0.5442276414083317\n",
            "batch: 1810 loss: 0.5444215999888257\n",
            "batch: 1811 loss: 0.5446878326581791\n",
            "batch: 1812 loss: 0.5447694204645231\n",
            "batch: 1813 loss: 0.5449342610286548\n",
            "batch: 1814 loss: 0.5450439703511074\n",
            "batch: 1815 loss: 0.5453755828784779\n",
            "batch: 1816 loss: 0.5455927460687235\n",
            "batch: 1817 loss: 0.5457269233660772\n",
            "batch: 1818 loss: 0.5459130585985258\n",
            "batch: 1819 loss: 0.5459768378930167\n",
            "batch: 1820 loss: 0.5460627550231293\n",
            "batch: 1821 loss: 0.546292847414501\n",
            "batch: 1822 loss: 0.5464039349080995\n",
            "batch: 1823 loss: 0.5465733620049432\n",
            "batch: 1824 loss: 0.5467174185039475\n",
            "batch: 1825 loss: 0.5468813529433683\n",
            "batch: 1826 loss: 0.5472303461255505\n",
            "batch: 1827 loss: 0.5472758151525632\n",
            "batch: 1828 loss: 0.5476702577108518\n",
            "batch: 1829 loss: 0.5478007427835837\n",
            "batch: 1830 loss: 0.5479285869086161\n",
            "batch: 1831 loss: 0.5479741322332993\n",
            "batch: 1832 loss: 0.5480447561675683\n",
            "batch: 1833 loss: 0.5480646870741621\n",
            "batch: 1834 loss: 0.5481763741159812\n",
            "batch: 1835 loss: 0.548310807862319\n",
            "batch: 1836 loss: 0.5483341171080247\n",
            "batch: 1837 loss: 0.5484505012566224\n",
            "batch: 1838 loss: 0.5485427736723796\n",
            "batch: 1839 loss: 0.5488632849538699\n",
            "batch: 1840 loss: 0.5489626122796908\n",
            "batch: 1841 loss: 0.5492456623995676\n",
            "batch: 1842 loss: 0.5495109544778243\n",
            "batch: 1843 loss: 0.5497780412221327\n",
            "batch: 1844 loss: 0.5498622370446101\n",
            "batch: 1845 loss: 0.5502046360755339\n",
            "batch: 1846 loss: 0.5503063950473442\n",
            "batch: 1847 loss: 0.5504005182990804\n",
            "batch: 1848 loss: 0.5508642436871305\n",
            "batch: 1849 loss: 0.551064167813398\n",
            "batch: 1850 loss: 0.5512265581348911\n",
            "batch: 1851 loss: 0.5512686691330746\n",
            "batch: 1852 loss: 0.5515213158773258\n",
            "batch: 1853 loss: 0.5516448435308412\n",
            "batch: 1854 loss: 0.5517498086886481\n",
            "batch: 1855 loss: 0.551785899844952\n",
            "batch: 1856 loss: 0.5520896071167662\n",
            "batch: 1857 loss: 0.5521974405618384\n",
            "batch: 1858 loss: 0.5524153867634013\n",
            "batch: 1859 loss: 0.5528774482877925\n",
            "batch: 1860 loss: 0.5531144399764016\n",
            "batch: 1861 loss: 0.5532429841430858\n",
            "batch: 1862 loss: 0.55338504118938\n",
            "batch: 1863 loss: 0.5536038217367605\n",
            "batch: 1864 loss: 0.5537884063692764\n",
            "batch: 1865 loss: 0.5539230908723548\n",
            "batch: 1866 loss: 0.5540919603230432\n",
            "batch: 1867 loss: 0.5541302838781849\n",
            "batch: 1868 loss: 0.5542075756127015\n",
            "batch: 1869 loss: 0.5542661447012797\n",
            "batch: 1870 loss: 0.5544539107615128\n",
            "batch: 1871 loss: 0.5547248329455033\n",
            "batch: 1872 loss: 0.554956651055254\n",
            "batch: 1873 loss: 0.5549883785406128\n",
            "batch: 1874 loss: 0.5553422698238865\n",
            "batch: 1 loss: 0.00038860587775707247\n",
            "batch: 2 loss: 0.0005267796814441681\n",
            "batch: 3 loss: 0.0006441220790147781\n",
            "batch: 4 loss: 0.0007286914885044098\n",
            "batch: 5 loss: 0.0008719236552715301\n",
            "batch: 6 loss: 0.0008895366415381432\n",
            "batch: 7 loss: 0.0010861891135573387\n",
            "batch: 8 loss: 0.0012566729709506035\n",
            "batch: 9 loss: 0.0013540864735841751\n",
            "batch: 10 loss: 0.0015376439094543456\n",
            "batch: 11 loss: 0.0016213921681046486\n",
            "batch: 12 loss: 0.0018015112206339835\n",
            "batch: 13 loss: 0.0019288525804877282\n",
            "batch: 14 loss: 0.002026310496032238\n",
            "batch: 15 loss: 0.002117616765201092\n",
            "batch: 16 loss: 0.002614098034799099\n",
            "batch: 17 loss: 0.0026494677513837816\n",
            "batch: 18 loss: 0.0026745421271771193\n",
            "batch: 19 loss: 0.0027896843235939743\n",
            "batch: 20 loss: 0.002895811213180423\n",
            "batch: 21 loss: 0.003116263134405017\n",
            "batch: 22 loss: 0.003291006101295352\n",
            "batch: 23 loss: 0.003431211752817035\n",
            "batch: 24 loss: 0.004048903090879321\n",
            "batch: 25 loss: 0.00417725564353168\n",
            "batch: 26 loss: 0.0042598336171358825\n",
            "batch: 27 loss: 0.004502022875472903\n",
            "batch: 28 loss: 0.004608723541721702\n",
            "batch: 29 loss: 0.005344815632328391\n",
            "batch: 30 loss: 0.00538031448982656\n",
            "batch: 31 loss: 0.005518661698326468\n",
            "batch: 32 loss: 0.005642551986500621\n",
            "batch: 33 loss: 0.005840170053765178\n",
            "batch: 34 loss: 0.0059054008852690455\n",
            "batch: 35 loss: 0.005939483797177673\n",
            "batch: 36 loss: 0.006036994701251387\n",
            "batch: 37 loss: 0.006346348321065307\n",
            "batch: 38 loss: 0.006431217527016997\n",
            "batch: 39 loss: 0.006502600697800517\n",
            "batch: 40 loss: 0.006568054689094424\n",
            "batch: 41 loss: 0.006620261808857322\n",
            "batch: 42 loss: 0.006668487777933479\n",
            "batch: 43 loss: 0.006924529841169715\n",
            "batch: 44 loss: 0.0069689525384455915\n",
            "batch: 45 loss: 0.007026003057137132\n",
            "batch: 46 loss: 0.0070818016473203895\n",
            "batch: 47 loss: 0.007196986803784966\n",
            "batch: 48 loss: 0.007293531874194742\n",
            "batch: 49 loss: 0.0073815706763416524\n",
            "batch: 50 loss: 0.00746323418058455\n",
            "batch: 51 loss: 0.007905651861801744\n",
            "batch: 52 loss: 0.007995528744533659\n",
            "batch: 53 loss: 0.008064558843150734\n",
            "batch: 54 loss: 0.008184230634942651\n",
            "batch: 55 loss: 0.008264670634642243\n",
            "batch: 56 loss: 0.008339180143550038\n",
            "batch: 57 loss: 0.008367744455114007\n",
            "batch: 58 loss: 0.008380697110667825\n",
            "batch: 59 loss: 0.008409168737009167\n",
            "batch: 60 loss: 0.008604343609884381\n",
            "batch: 61 loss: 0.008647163366898894\n",
            "batch: 62 loss: 0.008684919407591224\n",
            "batch: 63 loss: 0.008700543873012065\n",
            "batch: 64 loss: 0.00886748953908682\n",
            "batch: 65 loss: 0.009042386032640935\n",
            "batch: 66 loss: 0.009066539650782943\n",
            "batch: 67 loss: 0.009294561123475433\n",
            "batch: 68 loss: 0.00939710925333202\n",
            "batch: 69 loss: 0.009459620064124465\n",
            "batch: 70 loss: 0.009487778512760997\n",
            "batch: 71 loss: 0.009680920166894794\n",
            "batch: 72 loss: 0.00993059386126697\n",
            "batch: 73 loss: 0.010040636984631418\n",
            "batch: 74 loss: 0.010124024158343672\n",
            "batch: 75 loss: 0.010223886584863067\n",
            "batch: 76 loss: 0.01025746282748878\n",
            "batch: 77 loss: 0.010352824596688152\n",
            "batch: 78 loss: 0.01045668357424438\n",
            "batch: 79 loss: 0.010648088527843356\n",
            "batch: 80 loss: 0.010785767672583461\n",
            "batch: 81 loss: 0.010931340126320719\n",
            "batch: 82 loss: 0.011054967759177088\n",
            "batch: 83 loss: 0.011148391311988234\n",
            "batch: 84 loss: 0.01156215644441545\n",
            "batch: 85 loss: 0.011703085770830512\n",
            "batch: 86 loss: 0.011816114878281951\n",
            "batch: 87 loss: 0.01195134404860437\n",
            "batch: 88 loss: 0.011981609795242548\n",
            "batch: 89 loss: 0.012047336142510176\n",
            "batch: 90 loss: 0.012138851445168257\n",
            "batch: 91 loss: 0.012474276226013898\n",
            "batch: 92 loss: 0.01273137391731143\n",
            "batch: 93 loss: 0.012996608775109053\n",
            "batch: 94 loss: 0.013267061661928892\n",
            "batch: 95 loss: 0.01334946247562766\n",
            "batch: 96 loss: 0.01350413566455245\n",
            "batch: 97 loss: 0.013562888015061617\n",
            "batch: 98 loss: 0.01390570392087102\n",
            "batch: 99 loss: 0.014095797453075647\n",
            "batch: 100 loss: 0.01422478086128831\n",
            "batch: 101 loss: 0.014401852522045374\n",
            "batch: 102 loss: 0.01449211621657014\n",
            "batch: 103 loss: 0.014508276538923382\n",
            "batch: 104 loss: 0.014625107111409307\n",
            "batch: 105 loss: 0.014707927035167814\n",
            "batch: 106 loss: 0.015277745353057981\n",
            "batch: 107 loss: 0.015394186722114683\n",
            "batch: 108 loss: 0.015509940670803189\n",
            "batch: 109 loss: 0.015585897194221616\n",
            "batch: 110 loss: 0.015619999857619405\n",
            "batch: 111 loss: 0.01577598430402577\n",
            "batch: 112 loss: 0.015889010535553097\n",
            "batch: 113 loss: 0.01595046236179769\n",
            "batch: 114 loss: 0.01596619308553636\n",
            "batch: 115 loss: 0.01603528225235641\n",
            "batch: 116 loss: 0.01616438071243465\n",
            "batch: 117 loss: 0.016669012708589434\n",
            "batch: 118 loss: 0.0168146201800555\n",
            "batch: 119 loss: 0.01702098282985389\n",
            "batch: 120 loss: 0.017177889896556733\n",
            "batch: 121 loss: 0.017334383053705098\n",
            "batch: 122 loss: 0.017447909286245705\n",
            "batch: 123 loss: 0.017618514021858572\n",
            "batch: 124 loss: 0.01772886491380632\n",
            "batch: 125 loss: 0.01783130002580583\n",
            "batch: 126 loss: 0.017904726853594184\n",
            "batch: 127 loss: 0.017956154240295293\n",
            "batch: 128 loss: 0.017989962363615632\n",
            "batch: 129 loss: 0.01805239431373775\n",
            "batch: 130 loss: 0.018155556363984943\n",
            "batch: 131 loss: 0.018297562969848514\n",
            "batch: 132 loss: 0.018387134177610277\n",
            "batch: 133 loss: 0.018440317986533047\n",
            "batch: 134 loss: 0.01882518228702247\n",
            "batch: 135 loss: 0.01901303022913635\n",
            "batch: 136 loss: 0.019080480193719267\n",
            "batch: 137 loss: 0.019105060167610644\n",
            "batch: 138 loss: 0.01925455089658499\n",
            "batch: 139 loss: 0.019749055556952954\n",
            "batch: 140 loss: 0.01988820270448923\n",
            "batch: 141 loss: 0.020031300120055676\n",
            "batch: 142 loss: 0.02010390132665634\n",
            "batch: 143 loss: 0.02027951294183731\n",
            "batch: 144 loss: 0.020330820351839064\n",
            "batch: 145 loss: 0.020573514133691788\n",
            "batch: 146 loss: 0.020770570009946823\n",
            "batch: 147 loss: 0.02098368000984192\n",
            "batch: 148 loss: 0.021173721879720688\n",
            "batch: 149 loss: 0.02140633727610111\n",
            "batch: 150 loss: 0.02147287717461586\n",
            "batch: 151 loss: 0.021600480556488038\n",
            "batch: 152 loss: 0.02162619047611952\n",
            "batch: 153 loss: 0.021655718095600605\n",
            "batch: 154 loss: 0.021878458239138126\n",
            "batch: 155 loss: 0.02198014535009861\n",
            "batch: 156 loss: 0.02219377624988556\n",
            "batch: 157 loss: 0.022301326274871826\n",
            "batch: 158 loss: 0.02249913316965103\n",
            "batch: 159 loss: 0.022724405154585837\n",
            "batch: 160 loss: 0.022792923122644426\n",
            "batch: 161 loss: 0.02288391876220703\n",
            "batch: 162 loss: 0.02291482507251203\n",
            "batch: 163 loss: 0.022990291779860852\n",
            "batch: 164 loss: 0.023096883019432426\n",
            "batch: 165 loss: 0.023407363554462792\n",
            "batch: 166 loss: 0.02357490943931043\n",
            "batch: 167 loss: 0.02368751016817987\n",
            "batch: 168 loss: 0.023972819244489074\n",
            "batch: 169 loss: 0.02422897050343454\n",
            "batch: 170 loss: 0.024429860716685653\n",
            "batch: 171 loss: 0.02457587209902704\n",
            "batch: 172 loss: 0.024907839929684997\n",
            "batch: 173 loss: 0.025290687089785935\n",
            "batch: 174 loss: 0.025472954576835037\n",
            "batch: 175 loss: 0.025631388550624253\n",
            "batch: 176 loss: 0.025666904477402566\n",
            "batch: 177 loss: 0.025752213960513474\n",
            "batch: 178 loss: 0.025969068801030518\n",
            "batch: 179 loss: 0.026184290474280714\n",
            "batch: 180 loss: 0.026259183606132865\n",
            "batch: 181 loss: 0.02642238732241094\n",
            "batch: 182 loss: 0.02658870013616979\n",
            "batch: 183 loss: 0.026629375079646706\n",
            "batch: 184 loss: 0.026654972212389112\n",
            "batch: 185 loss: 0.026727939346805216\n",
            "batch: 186 loss: 0.026821335965767502\n",
            "batch: 187 loss: 0.026969148049131034\n",
            "batch: 188 loss: 0.02698977451957762\n",
            "batch: 189 loss: 0.027243849599733947\n",
            "batch: 190 loss: 0.027394479716196657\n",
            "batch: 191 loss: 0.027473845968022943\n",
            "batch: 192 loss: 0.02778933680988848\n",
            "batch: 193 loss: 0.027805671064183114\n",
            "batch: 194 loss: 0.027997390089556574\n",
            "batch: 195 loss: 0.028297273961827157\n",
            "batch: 196 loss: 0.02857476240210235\n",
            "batch: 197 loss: 0.02874800249747932\n",
            "batch: 198 loss: 0.028953487245365978\n",
            "batch: 199 loss: 0.0291189250331372\n",
            "batch: 200 loss: 0.029151253832504154\n",
            "batch: 201 loss: 0.029260973049327732\n",
            "batch: 202 loss: 0.029354993095621465\n",
            "batch: 203 loss: 0.02951011929474771\n",
            "batch: 204 loss: 0.029594033157452942\n",
            "batch: 205 loss: 0.029753927817568183\n",
            "batch: 206 loss: 0.02986852282844484\n",
            "batch: 207 loss: 0.029964592358097435\n",
            "batch: 208 loss: 0.03005790970288217\n",
            "batch: 209 loss: 0.030183113982900977\n",
            "batch: 210 loss: 0.030238071223720908\n",
            "batch: 211 loss: 0.03028675383888185\n",
            "batch: 212 loss: 0.03029689856246114\n",
            "batch: 213 loss: 0.030400715868920087\n",
            "batch: 214 loss: 0.030474799428135156\n",
            "batch: 215 loss: 0.030573558185249566\n",
            "batch: 216 loss: 0.03059887794777751\n",
            "batch: 217 loss: 0.03090164376422763\n",
            "batch: 218 loss: 0.031113288190215825\n",
            "batch: 219 loss: 0.03144922610744834\n",
            "batch: 220 loss: 0.03159672617539763\n",
            "batch: 221 loss: 0.0321793248616159\n",
            "batch: 222 loss: 0.032231972437351944\n",
            "batch: 223 loss: 0.032393971633166076\n",
            "batch: 224 loss: 0.032560546319931744\n",
            "batch: 225 loss: 0.03263725689426065\n",
            "batch: 226 loss: 0.032876539323478934\n",
            "batch: 227 loss: 0.03299273391440511\n",
            "batch: 228 loss: 0.03301950016617775\n",
            "batch: 229 loss: 0.033259020656347275\n",
            "batch: 230 loss: 0.03348273605108261\n",
            "batch: 231 loss: 0.03364158779382706\n",
            "batch: 232 loss: 0.03372897488623858\n",
            "batch: 233 loss: 0.03388496265560389\n",
            "batch: 234 loss: 0.03393731892853975\n",
            "batch: 235 loss: 0.03414981097728014\n",
            "batch: 236 loss: 0.03417185455933213\n",
            "batch: 237 loss: 0.0343750083334744\n",
            "batch: 238 loss: 0.03448299419507384\n",
            "batch: 239 loss: 0.034598678592592476\n",
            "batch: 240 loss: 0.034710124630481\n",
            "batch: 241 loss: 0.034822140205651525\n",
            "batch: 242 loss: 0.034925309639424085\n",
            "batch: 243 loss: 0.03496397427096963\n",
            "batch: 244 loss: 0.03503435074165463\n",
            "batch: 245 loss: 0.03512457529082894\n",
            "batch: 246 loss: 0.03523698226734996\n",
            "batch: 247 loss: 0.03526865242421627\n",
            "batch: 248 loss: 0.035417607828974726\n",
            "batch: 249 loss: 0.035579624399542806\n",
            "batch: 250 loss: 0.03597980533540249\n",
            "batch: 251 loss: 0.03635820864140987\n",
            "batch: 252 loss: 0.036512795776128766\n",
            "batch: 253 loss: 0.03678198701143265\n",
            "batch: 254 loss: 0.036959481745958325\n",
            "batch: 255 loss: 0.037014103662222624\n",
            "batch: 256 loss: 0.037097794730216266\n",
            "batch: 257 loss: 0.0371272403113544\n",
            "batch: 258 loss: 0.037138214993290605\n",
            "batch: 259 loss: 0.03725816522818059\n",
            "batch: 260 loss: 0.03734388418775052\n",
            "batch: 261 loss: 0.03736810771655291\n",
            "batch: 262 loss: 0.037763448814861475\n",
            "batch: 263 loss: 0.037843936714343725\n",
            "batch: 264 loss: 0.038077021556906405\n",
            "batch: 265 loss: 0.0381679092599079\n",
            "batch: 266 loss: 0.03830294958781451\n",
            "batch: 267 loss: 0.038361568103544415\n",
            "batch: 268 loss: 0.03841821147035807\n",
            "batch: 269 loss: 0.03859264327120036\n",
            "batch: 270 loss: 0.03886410583090037\n",
            "batch: 271 loss: 0.038931235807947814\n",
            "batch: 272 loss: 0.0390106145767495\n",
            "batch: 273 loss: 0.039098062234930696\n",
            "batch: 274 loss: 0.03920352956932038\n",
            "batch: 275 loss: 0.03922201984655112\n",
            "batch: 276 loss: 0.03927410357352346\n",
            "batch: 277 loss: 0.03938375363405794\n",
            "batch: 278 loss: 0.0399345815544948\n",
            "batch: 279 loss: 0.04029202649649233\n",
            "batch: 280 loss: 0.040463382891379296\n",
            "batch: 281 loss: 0.040597258693538606\n",
            "batch: 282 loss: 0.0407949272012338\n",
            "batch: 283 loss: 0.040902172795496884\n",
            "batch: 284 loss: 0.041097960046492514\n",
            "batch: 285 loss: 0.041267340487800536\n",
            "batch: 286 loss: 0.041512300333939496\n",
            "batch: 287 loss: 0.04153230321500451\n",
            "batch: 288 loss: 0.041612386570312083\n",
            "batch: 289 loss: 0.04171629220340401\n",
            "batch: 290 loss: 0.041795787543989715\n",
            "batch: 291 loss: 0.04189760277513414\n",
            "batch: 292 loss: 0.04216989544872195\n",
            "batch: 293 loss: 0.04232404907885939\n",
            "batch: 294 loss: 0.042401543752290306\n",
            "batch: 295 loss: 0.04249787306133658\n",
            "batch: 296 loss: 0.042690542303957045\n",
            "batch: 297 loss: 0.04296981605235487\n",
            "batch: 298 loss: 0.043052274622954426\n",
            "batch: 299 loss: 0.04308862782735377\n",
            "batch: 300 loss: 0.04314447121042758\n",
            "batch: 301 loss: 0.043267555532045664\n",
            "batch: 302 loss: 0.04351498582679778\n",
            "batch: 303 loss: 0.04352803812082857\n",
            "batch: 304 loss: 0.043730742684565484\n",
            "batch: 305 loss: 0.044007985345087944\n",
            "batch: 306 loss: 0.0441820775931701\n",
            "batch: 307 loss: 0.044303943104110656\n",
            "batch: 308 loss: 0.04435561033990234\n",
            "batch: 309 loss: 0.04451211210992187\n",
            "batch: 310 loss: 0.04480121782328934\n",
            "batch: 311 loss: 0.04489192239101976\n",
            "batch: 312 loss: 0.04504144615586847\n",
            "batch: 313 loss: 0.04521109130140394\n",
            "batch: 314 loss: 0.045284988581202924\n",
            "batch: 315 loss: 0.04533317875023931\n",
            "batch: 316 loss: 0.04558670949097723\n",
            "batch: 317 loss: 0.04596148391719908\n",
            "batch: 318 loss: 0.04601062147226185\n",
            "batch: 319 loss: 0.046490326448343694\n",
            "batch: 320 loss: 0.04651781415287405\n",
            "batch: 321 loss: 0.046645023399032655\n",
            "batch: 322 loss: 0.04674234727118164\n",
            "batch: 323 loss: 0.04686160456482321\n",
            "batch: 324 loss: 0.04694254943076521\n",
            "batch: 325 loss: 0.04714396069291979\n",
            "batch: 326 loss: 0.0471686861300841\n",
            "batch: 327 loss: 0.047333059021271766\n",
            "batch: 328 loss: 0.047509400227107104\n",
            "batch: 329 loss: 0.0475572908828035\n",
            "batch: 330 loss: 0.047658232645131644\n",
            "batch: 331 loss: 0.04781731312070042\n",
            "batch: 332 loss: 0.04802355079445988\n",
            "batch: 333 loss: 0.04806081718299538\n",
            "batch: 334 loss: 0.048158511430956424\n",
            "batch: 335 loss: 0.04832484921906143\n",
            "batch: 336 loss: 0.04852051462326199\n",
            "batch: 337 loss: 0.04865324254427105\n",
            "batch: 338 loss: 0.0489450630703941\n",
            "batch: 339 loss: 0.04907858234737068\n",
            "batch: 340 loss: 0.04928612361941487\n",
            "batch: 341 loss: 0.04941700327489525\n",
            "batch: 342 loss: 0.04944352305773646\n",
            "batch: 343 loss: 0.04948600354511291\n",
            "batch: 344 loss: 0.049557555732317266\n",
            "batch: 345 loss: 0.04964804270584136\n",
            "batch: 346 loss: 0.04996433320362121\n",
            "batch: 347 loss: 0.049990899770520625\n",
            "batch: 348 loss: 0.050066218099556865\n",
            "batch: 349 loss: 0.050143753393553196\n",
            "batch: 350 loss: 0.050195119800977406\n",
            "batch: 351 loss: 0.05038433468621224\n",
            "batch: 352 loss: 0.050542590486817064\n",
            "batch: 353 loss: 0.050697933125309645\n",
            "batch: 354 loss: 0.050954054432921114\n",
            "batch: 355 loss: 0.051030090901069344\n",
            "batch: 356 loss: 0.05110705173294991\n",
            "batch: 357 loss: 0.05116626854147762\n",
            "batch: 358 loss: 0.0513457373669371\n",
            "batch: 359 loss: 0.05145796323474497\n",
            "batch: 360 loss: 0.051485813203267755\n",
            "batch: 361 loss: 0.051549402850680055\n",
            "batch: 362 loss: 0.05165165996085853\n",
            "batch: 363 loss: 0.05185410314332694\n",
            "batch: 364 loss: 0.05205599596630782\n",
            "batch: 365 loss: 0.05257620998751372\n",
            "batch: 366 loss: 0.05264840077888221\n",
            "batch: 367 loss: 0.052702441382221875\n",
            "batch: 368 loss: 0.05276151809375733\n",
            "batch: 369 loss: 0.05285568972211331\n",
            "batch: 370 loss: 0.05287236173357814\n",
            "batch: 371 loss: 0.05299565730895847\n",
            "batch: 372 loss: 0.05306619239505381\n",
            "batch: 373 loss: 0.05321306370850652\n",
            "batch: 374 loss: 0.05334019640740007\n",
            "batch: 375 loss: 0.05337778234388679\n",
            "batch: 376 loss: 0.05341184927430004\n",
            "batch: 377 loss: 0.053471062458120285\n",
            "batch: 378 loss: 0.053576995915733276\n",
            "batch: 379 loss: 0.053645117982290685\n",
            "batch: 380 loss: 0.053764948113821445\n",
            "batch: 381 loss: 0.05378674248699099\n",
            "batch: 382 loss: 0.053905905448831615\n",
            "batch: 383 loss: 0.053930634333752094\n",
            "batch: 384 loss: 0.054063284470699725\n",
            "batch: 385 loss: 0.05411628536786884\n",
            "batch: 386 loss: 0.05423333246912807\n",
            "batch: 387 loss: 0.054257161675952376\n",
            "batch: 388 loss: 0.05439108917023987\n",
            "batch: 389 loss: 0.05447851000633091\n",
            "batch: 390 loss: 0.05478409863915294\n",
            "batch: 391 loss: 0.054846185996197165\n",
            "batch: 392 loss: 0.054923029004596176\n",
            "batch: 393 loss: 0.05546425753738731\n",
            "batch: 394 loss: 0.05564119568374008\n",
            "batch: 395 loss: 0.055671577745117246\n",
            "batch: 396 loss: 0.055698369783349334\n",
            "batch: 397 loss: 0.05573045170772821\n",
            "batch: 398 loss: 0.05582392970938235\n",
            "batch: 399 loss: 0.05602484424132854\n",
            "batch: 400 loss: 0.056122444649226964\n",
            "batch: 401 loss: 0.05627333794999868\n",
            "batch: 402 loss: 0.05667352603841573\n",
            "batch: 403 loss: 0.056864723701961335\n",
            "batch: 404 loss: 0.05692794376332313\n",
            "batch: 405 loss: 0.05697454860899597\n",
            "batch: 406 loss: 0.057010997214354577\n",
            "batch: 407 loss: 0.05778276238683611\n",
            "batch: 408 loss: 0.05784796478692442\n",
            "batch: 409 loss: 0.05790198914799839\n",
            "batch: 410 loss: 0.057989328742958604\n",
            "batch: 411 loss: 0.058022431896068156\n",
            "batch: 412 loss: 0.05818469882104546\n",
            "batch: 413 loss: 0.0584982418725267\n",
            "batch: 414 loss: 0.05858859904203564\n",
            "batch: 415 loss: 0.05860545499343425\n",
            "batch: 416 loss: 0.05873736898321658\n",
            "batch: 417 loss: 0.058780759890563784\n",
            "batch: 418 loss: 0.05879927048366517\n",
            "batch: 419 loss: 0.0589625534741208\n",
            "batch: 420 loss: 0.05912206276040524\n",
            "batch: 421 loss: 0.05931962342839688\n",
            "batch: 422 loss: 0.059584259825758636\n",
            "batch: 423 loss: 0.05964469196926803\n",
            "batch: 424 loss: 0.05972242471110076\n",
            "batch: 425 loss: 0.059878134380094705\n",
            "batch: 426 loss: 0.06004124612640589\n",
            "batch: 427 loss: 0.06006080903392285\n",
            "batch: 428 loss: 0.0601723689166829\n",
            "batch: 429 loss: 0.06022362024243921\n",
            "batch: 430 loss: 0.06024274098593742\n",
            "batch: 431 loss: 0.06050601717550307\n",
            "batch: 432 loss: 0.06068628792185336\n",
            "batch: 433 loss: 0.06088201228994876\n",
            "batch: 434 loss: 0.06092522845137864\n",
            "batch: 435 loss: 0.06094444658514112\n",
            "batch: 436 loss: 0.061231292597018185\n",
            "batch: 437 loss: 0.06126372172217816\n",
            "batch: 438 loss: 0.061428109440021215\n",
            "batch: 439 loss: 0.06153683337848634\n",
            "batch: 440 loss: 0.061573139789514245\n",
            "batch: 441 loss: 0.06171358731668442\n",
            "batch: 442 loss: 0.06183519116323441\n",
            "batch: 443 loss: 0.061868876478634774\n",
            "batch: 444 loss: 0.06198716232087463\n",
            "batch: 445 loss: 0.062327756254933774\n",
            "batch: 446 loss: 0.06250073595251888\n",
            "batch: 447 loss: 0.0627372013470158\n",
            "batch: 448 loss: 0.06276626222673803\n",
            "batch: 449 loss: 0.06285907458607107\n",
            "batch: 450 loss: 0.06293877387885004\n",
            "batch: 451 loss: 0.06297669994924217\n",
            "batch: 452 loss: 0.06299266594741494\n",
            "batch: 453 loss: 0.06311978449020535\n",
            "batch: 454 loss: 0.0632839166680351\n",
            "batch: 455 loss: 0.06333198286313564\n",
            "batch: 456 loss: 0.06334454958233983\n",
            "batch: 457 loss: 0.06335832134820521\n",
            "batch: 458 loss: 0.06352101475931704\n",
            "batch: 459 loss: 0.06360896240361034\n",
            "batch: 460 loss: 0.06380907489545644\n",
            "batch: 461 loss: 0.06398928459174931\n",
            "batch: 462 loss: 0.064043971253559\n",
            "batch: 463 loss: 0.06413419633172453\n",
            "batch: 464 loss: 0.06429316363297403\n",
            "batch: 465 loss: 0.06438511281274259\n",
            "batch: 466 loss: 0.06445816939137876\n",
            "batch: 467 loss: 0.06450665829144418\n",
            "batch: 468 loss: 0.06461461836658418\n",
            "batch: 469 loss: 0.06502454758249224\n",
            "batch: 470 loss: 0.06506075400672853\n",
            "batch: 471 loss: 0.06524196181260049\n",
            "batch: 472 loss: 0.06525599269848317\n",
            "batch: 473 loss: 0.0653626132933423\n",
            "batch: 474 loss: 0.06554127994459122\n",
            "batch: 475 loss: 0.0656622169194743\n",
            "batch: 476 loss: 0.06598356177192181\n",
            "batch: 477 loss: 0.066027287828736\n",
            "batch: 478 loss: 0.06608432416897267\n",
            "batch: 479 loss: 0.06610131128784269\n",
            "batch: 480 loss: 0.06619554222282022\n",
            "batch: 481 loss: 0.06627551463898271\n",
            "batch: 482 loss: 0.06632647902425379\n",
            "batch: 483 loss: 0.06649259377177805\n",
            "batch: 484 loss: 0.06678051371034235\n",
            "batch: 485 loss: 0.06691668879147619\n",
            "batch: 486 loss: 0.06702958818431944\n",
            "batch: 487 loss: 0.06719508064445108\n",
            "batch: 488 loss: 0.06733223131950945\n",
            "batch: 489 loss: 0.06763289261516184\n",
            "batch: 490 loss: 0.06791554794367403\n",
            "batch: 491 loss: 0.0679384937165305\n",
            "batch: 492 loss: 0.06810863061528653\n",
            "batch: 493 loss: 0.06828933118563145\n",
            "batch: 494 loss: 0.06832024658750743\n",
            "batch: 495 loss: 0.06856310140620916\n",
            "batch: 496 loss: 0.06886236655246467\n",
            "batch: 497 loss: 0.06888686722051353\n",
            "batch: 498 loss: 0.06898247945588082\n",
            "batch: 499 loss: 0.06909639989864082\n",
            "batch: 500 loss: 0.06922092704009265\n",
            "batch: 501 loss: 0.06932062454055994\n",
            "batch: 502 loss: 0.06934691047575325\n",
            "batch: 503 loss: 0.0695230078091845\n",
            "batch: 504 loss: 0.06982996255066246\n",
            "batch: 505 loss: 0.06989698514994235\n",
            "batch: 506 loss: 0.07002043521311134\n",
            "batch: 507 loss: 0.07022367155458778\n",
            "batch: 508 loss: 0.07037294241692871\n",
            "batch: 509 loss: 0.0704486206015572\n",
            "batch: 510 loss: 0.07049964803364128\n",
            "batch: 511 loss: 0.07057750075962395\n",
            "batch: 512 loss: 0.07064616383519023\n",
            "batch: 513 loss: 0.07067713474389166\n",
            "batch: 514 loss: 0.07076930777635425\n",
            "batch: 515 loss: 0.07098189715947956\n",
            "batch: 516 loss: 0.071504853351973\n",
            "batch: 517 loss: 0.07194299526419491\n",
            "batch: 518 loss: 0.07209511999692768\n",
            "batch: 519 loss: 0.07229066997673363\n",
            "batch: 520 loss: 0.07237035936769098\n",
            "batch: 521 loss: 0.07251891945954413\n",
            "batch: 522 loss: 0.07256407244782895\n",
            "batch: 523 loss: 0.0726873506931588\n",
            "batch: 524 loss: 0.07290954983513802\n",
            "batch: 525 loss: 0.07329131818097084\n",
            "batch: 526 loss: 0.07330933705810458\n",
            "batch: 527 loss: 0.07338394221011549\n",
            "batch: 528 loss: 0.07350035774055869\n",
            "batch: 529 loss: 0.07372975166980177\n",
            "batch: 530 loss: 0.07376705240551382\n",
            "batch: 531 loss: 0.07386184588167817\n",
            "batch: 532 loss: 0.0740625204751268\n",
            "batch: 533 loss: 0.07409237283747644\n",
            "batch: 534 loss: 0.07415315415617078\n",
            "batch: 535 loss: 0.07421184081118554\n",
            "batch: 536 loss: 0.07438552531879396\n",
            "batch: 537 loss: 0.07447246065270155\n",
            "batch: 538 loss: 0.07452992446627468\n",
            "batch: 539 loss: 0.07461296558286995\n",
            "batch: 540 loss: 0.07476450766529888\n",
            "batch: 541 loss: 0.07483265998866409\n",
            "batch: 542 loss: 0.07488012549560517\n",
            "batch: 543 loss: 0.07496576780360192\n",
            "batch: 544 loss: 0.07502072669845074\n",
            "batch: 545 loss: 0.07521859057527036\n",
            "batch: 546 loss: 0.07532104664575309\n",
            "batch: 547 loss: 0.07553147023450583\n",
            "batch: 548 loss: 0.07581692191492766\n",
            "batch: 549 loss: 0.07582932163123042\n",
            "batch: 550 loss: 0.0759318872699514\n",
            "batch: 551 loss: 0.07594905154500156\n",
            "batch: 552 loss: 0.0760285208011046\n",
            "batch: 553 loss: 0.0760453052232042\n",
            "batch: 554 loss: 0.07609978941921144\n",
            "batch: 555 loss: 0.07649134127143771\n",
            "batch: 556 loss: 0.07654412960354239\n",
            "batch: 557 loss: 0.07658466954994947\n",
            "batch: 558 loss: 0.07664578961674123\n",
            "batch: 559 loss: 0.07675712398532777\n",
            "batch: 560 loss: 0.07694860250595957\n",
            "batch: 561 loss: 0.07712401881162077\n",
            "batch: 562 loss: 0.0772011588299647\n",
            "batch: 563 loss: 0.07728971367422491\n",
            "batch: 564 loss: 0.07734575548116118\n",
            "batch: 565 loss: 0.07750878790859134\n",
            "batch: 566 loss: 0.07754388133902103\n",
            "batch: 567 loss: 0.07760735217947513\n",
            "batch: 568 loss: 0.07771617062110454\n",
            "batch: 569 loss: 0.0777476405063644\n",
            "batch: 570 loss: 0.07789055621717125\n",
            "batch: 571 loss: 0.07811249545309693\n",
            "batch: 572 loss: 0.07820118856523187\n",
            "batch: 573 loss: 0.07826398366782815\n",
            "batch: 574 loss: 0.07833294710610061\n",
            "batch: 575 loss: 0.07845647300127893\n",
            "batch: 576 loss: 0.07851305369008332\n",
            "batch: 577 loss: 0.07866243103612214\n",
            "batch: 578 loss: 0.07897494620550424\n",
            "batch: 579 loss: 0.07924129659403116\n",
            "batch: 580 loss: 0.07933284157235175\n",
            "batch: 581 loss: 0.07937188951764255\n",
            "batch: 582 loss: 0.07943555781338364\n",
            "batch: 583 loss: 0.07948118399921805\n",
            "batch: 584 loss: 0.0795195832895115\n",
            "batch: 585 loss: 0.07960057153273374\n",
            "batch: 586 loss: 0.07966819844115526\n",
            "batch: 587 loss: 0.07985256469715386\n",
            "batch: 588 loss: 0.07998121162224561\n",
            "batch: 589 loss: 0.08006188601721079\n",
            "batch: 590 loss: 0.08014921518135816\n",
            "batch: 591 loss: 0.08039218937326223\n",
            "batch: 592 loss: 0.08041215034853667\n",
            "batch: 593 loss: 0.08054883983265608\n",
            "batch: 594 loss: 0.08066248633246868\n",
            "batch: 595 loss: 0.0806961586503312\n",
            "batch: 596 loss: 0.08072974870633334\n",
            "batch: 597 loss: 0.08075528113823384\n",
            "batch: 598 loss: 0.08109668700676412\n",
            "batch: 599 loss: 0.08117731549125165\n",
            "batch: 600 loss: 0.08122835375647992\n",
            "batch: 601 loss: 0.08139497131388634\n",
            "batch: 602 loss: 0.0815321842012927\n",
            "batch: 603 loss: 0.08162669471930713\n",
            "batch: 604 loss: 0.08163789212424308\n",
            "batch: 605 loss: 0.0817132369922474\n",
            "batch: 606 loss: 0.08175112891662865\n",
            "batch: 607 loss: 0.08192444926965982\n",
            "batch: 608 loss: 0.08196658405009657\n",
            "batch: 609 loss: 0.08199252555985004\n",
            "batch: 610 loss: 0.08211431267578155\n",
            "batch: 611 loss: 0.08213732184190303\n",
            "batch: 612 loss: 0.08229960785526783\n",
            "batch: 613 loss: 0.08258920229692011\n",
            "batch: 614 loss: 0.0826416029157117\n",
            "batch: 615 loss: 0.08266220668796449\n",
            "batch: 616 loss: 0.08269601506460458\n",
            "batch: 617 loss: 0.0827554951729253\n",
            "batch: 618 loss: 0.08283094744104892\n",
            "batch: 619 loss: 0.08287230680603534\n",
            "batch: 620 loss: 0.08303139909822493\n",
            "batch: 621 loss: 0.08318864692468196\n",
            "batch: 622 loss: 0.08343502315599471\n",
            "batch: 623 loss: 0.08359748050291091\n",
            "batch: 624 loss: 0.08384097091574222\n",
            "batch: 625 loss: 0.08401382606942207\n",
            "batch: 626 loss: 0.08403723981138318\n",
            "batch: 627 loss: 0.08406568257790059\n",
            "batch: 628 loss: 0.08417459303420037\n",
            "batch: 629 loss: 0.08420264726039023\n",
            "batch: 630 loss: 0.08432138990517705\n",
            "batch: 631 loss: 0.08450914623495191\n",
            "batch: 632 loss: 0.08479501401539892\n",
            "batch: 633 loss: 0.08486634303536265\n",
            "batch: 634 loss: 0.0850529262861237\n",
            "batch: 635 loss: 0.08511538451444357\n",
            "batch: 636 loss: 0.0852908754600212\n",
            "batch: 637 loss: 0.08541658627521247\n",
            "batch: 638 loss: 0.0854556599026546\n",
            "batch: 639 loss: 0.08557559332158417\n",
            "batch: 640 loss: 0.08564274483080954\n",
            "batch: 641 loss: 0.08597569703217596\n",
            "batch: 642 loss: 0.08612559016700834\n",
            "batch: 643 loss: 0.08628254953678698\n",
            "batch: 644 loss: 0.0863869937499985\n",
            "batch: 645 loss: 0.08644446086045354\n",
            "batch: 646 loss: 0.08651136327441782\n",
            "batch: 647 loss: 0.08662329691555351\n",
            "batch: 648 loss: 0.08683906759228557\n",
            "batch: 649 loss: 0.08690239167120307\n",
            "batch: 650 loss: 0.08695741990488022\n",
            "batch: 651 loss: 0.08704918451886624\n",
            "batch: 652 loss: 0.08709379311930389\n",
            "batch: 653 loss: 0.08717736292164772\n",
            "batch: 654 loss: 0.0872011214485392\n",
            "batch: 655 loss: 0.08740230628754944\n",
            "batch: 656 loss: 0.08754676131810993\n",
            "batch: 657 loss: 0.0876032482823357\n",
            "batch: 658 loss: 0.08773213954176753\n",
            "batch: 659 loss: 0.08777539310883731\n",
            "batch: 660 loss: 0.08793608812522143\n",
            "batch: 661 loss: 0.08801495461445302\n",
            "batch: 662 loss: 0.0880484083024785\n",
            "batch: 663 loss: 0.08824684572499246\n",
            "batch: 664 loss: 0.08839253256004304\n",
            "batch: 665 loss: 0.08864408874791116\n",
            "batch: 666 loss: 0.08876854574214667\n",
            "batch: 667 loss: 0.08903324645292014\n",
            "batch: 668 loss: 0.08914743643533439\n",
            "batch: 669 loss: 0.08923331683408468\n",
            "batch: 670 loss: 0.08930039841216057\n",
            "batch: 671 loss: 0.08940287993382663\n",
            "batch: 672 loss: 0.08950199742149562\n",
            "batch: 673 loss: 0.08952992728818208\n",
            "batch: 674 loss: 0.08964279622305185\n",
            "batch: 675 loss: 0.08980764967668801\n",
            "batch: 676 loss: 0.08989937585312874\n",
            "batch: 677 loss: 0.08996644438523799\n",
            "batch: 678 loss: 0.09000432621035726\n",
            "batch: 679 loss: 0.09018139164242893\n",
            "batch: 680 loss: 0.09042674581799656\n",
            "batch: 681 loss: 0.09047435072157532\n",
            "batch: 682 loss: 0.0906554248938337\n",
            "batch: 683 loss: 0.09067143579106778\n",
            "batch: 684 loss: 0.09085126439016313\n",
            "batch: 685 loss: 0.09086760619562119\n",
            "batch: 686 loss: 0.09109973751287907\n",
            "batch: 687 loss: 0.09138071684818715\n",
            "batch: 688 loss: 0.09151308714132755\n",
            "batch: 689 loss: 0.09166832621674985\n",
            "batch: 690 loss: 0.09177909329067915\n",
            "batch: 691 loss: 0.09184948387276382\n",
            "batch: 692 loss: 0.09192043025325984\n",
            "batch: 693 loss: 0.09202696872781962\n",
            "batch: 694 loss: 0.09206815821211785\n",
            "batch: 695 loss: 0.09223456101398915\n",
            "batch: 696 loss: 0.09225326919462531\n",
            "batch: 697 loss: 0.09227660326194018\n",
            "batch: 698 loss: 0.09243368781637401\n",
            "batch: 699 loss: 0.09252555647026747\n",
            "batch: 700 loss: 0.0925421553691849\n",
            "batch: 701 loss: 0.09264609282370656\n",
            "batch: 702 loss: 0.09278681170102208\n",
            "batch: 703 loss: 0.09290008557494729\n",
            "batch: 704 loss: 0.09293118346203119\n",
            "batch: 705 loss: 0.09295080957468599\n",
            "batch: 706 loss: 0.09312954900320619\n",
            "batch: 707 loss: 0.09322377869393676\n",
            "batch: 708 loss: 0.09330689228978008\n",
            "batch: 709 loss: 0.09343830650951714\n",
            "batch: 710 loss: 0.09348753236886113\n",
            "batch: 711 loss: 0.09372844413574785\n",
            "batch: 712 loss: 0.09391686504241079\n",
            "batch: 713 loss: 0.09405456548091023\n",
            "batch: 714 loss: 0.09440383421536536\n",
            "batch: 715 loss: 0.09461659035738558\n",
            "batch: 716 loss: 0.09471231460478156\n",
            "batch: 717 loss: 0.09477197769563644\n",
            "batch: 718 loss: 0.09482427233736962\n",
            "batch: 719 loss: 0.09483991635870188\n",
            "batch: 720 loss: 0.09488216650020331\n",
            "batch: 721 loss: 0.09491123796161265\n",
            "batch: 722 loss: 0.09530818495806306\n",
            "batch: 723 loss: 0.09539139266964049\n",
            "batch: 724 loss: 0.095455915174447\n",
            "batch: 725 loss: 0.09564243908878416\n",
            "batch: 726 loss: 0.09580868879612535\n",
            "batch: 727 loss: 0.09598214802797883\n",
            "batch: 728 loss: 0.09609336838778108\n",
            "batch: 729 loss: 0.09619291331525892\n",
            "batch: 730 loss: 0.09632588191982358\n",
            "batch: 731 loss: 0.09646153110917657\n",
            "batch: 732 loss: 0.09662706988211721\n",
            "batch: 733 loss: 0.09678454268630594\n",
            "batch: 734 loss: 0.09702809210773558\n",
            "batch: 735 loss: 0.0970895990645513\n",
            "batch: 736 loss: 0.0971467743134126\n",
            "batch: 737 loss: 0.09721405056025832\n",
            "batch: 738 loss: 0.097244162122719\n",
            "batch: 739 loss: 0.09728537560906261\n",
            "batch: 740 loss: 0.09729670418892056\n",
            "batch: 741 loss: 0.09735123323742301\n",
            "batch: 742 loss: 0.0973713969597593\n",
            "batch: 743 loss: 0.09740977488923817\n",
            "batch: 744 loss: 0.09746461178082973\n",
            "batch: 745 loss: 0.09753033679444342\n",
            "batch: 746 loss: 0.09757055194023996\n",
            "batch: 747 loss: 0.0978341993773356\n",
            "batch: 748 loss: 0.09802752447966487\n",
            "batch: 749 loss: 0.09811174370441586\n",
            "batch: 750 loss: 0.09835235849115997\n",
            "batch: 751 loss: 0.0986032702634111\n",
            "batch: 752 loss: 0.09871866122726351\n",
            "batch: 753 loss: 0.09881735336128622\n",
            "batch: 754 loss: 0.09917272400204093\n",
            "batch: 755 loss: 0.09930063321534545\n",
            "batch: 756 loss: 0.09951726596895605\n",
            "batch: 757 loss: 0.09958205883298069\n",
            "batch: 758 loss: 0.09987158490810544\n",
            "batch: 759 loss: 0.09992948905471713\n",
            "batch: 760 loss: 0.10021935493592173\n",
            "batch: 761 loss: 0.10034337043110281\n",
            "batch: 762 loss: 0.10039772250223905\n",
            "batch: 763 loss: 0.10046237566042691\n",
            "batch: 764 loss: 0.1004866199484095\n",
            "batch: 765 loss: 0.10074689042475074\n",
            "batch: 766 loss: 0.10085035510268062\n",
            "batch: 767 loss: 0.10089059391897172\n",
            "batch: 768 loss: 0.10093062209989875\n",
            "batch: 769 loss: 0.10095129948388785\n",
            "batch: 770 loss: 0.10096410768199712\n",
            "batch: 771 loss: 0.10098246156517417\n",
            "batch: 772 loss: 0.1009952541841194\n",
            "batch: 773 loss: 0.10138784259092062\n",
            "batch: 774 loss: 0.101439454424195\n",
            "batch: 775 loss: 0.10154927382897586\n",
            "batch: 776 loss: 0.10172997651528567\n",
            "batch: 777 loss: 0.10179135237168521\n",
            "batch: 778 loss: 0.10187580200564116\n",
            "batch: 779 loss: 0.10207107454072684\n",
            "batch: 780 loss: 0.10212599163781852\n",
            "batch: 781 loss: 0.1024418227924034\n",
            "batch: 782 loss: 0.10262457918655127\n",
            "batch: 783 loss: 0.10274201432149857\n",
            "batch: 784 loss: 0.10278517226036638\n",
            "batch: 785 loss: 0.10291904447134584\n",
            "batch: 786 loss: 0.10298409591522067\n",
            "batch: 787 loss: 0.1030648725843057\n",
            "batch: 788 loss: 0.10316580264922232\n",
            "batch: 789 loss: 0.10331495592650027\n",
            "batch: 790 loss: 0.10338562812563032\n",
            "batch: 791 loss: 0.10347269715275616\n",
            "batch: 792 loss: 0.10354766043182463\n",
            "batch: 793 loss: 0.10387976746913045\n",
            "batch: 794 loss: 0.10391499521490187\n",
            "batch: 795 loss: 0.1039580030767247\n",
            "batch: 796 loss: 0.10411830538790673\n",
            "batch: 797 loss: 0.10422388468217104\n",
            "batch: 798 loss: 0.10499796048831195\n",
            "batch: 799 loss: 0.10520311989914626\n",
            "batch: 800 loss: 0.10540180046390742\n",
            "batch: 801 loss: 0.10546769631188363\n",
            "batch: 802 loss: 0.10564372191112488\n",
            "batch: 803 loss: 0.10567998966481537\n",
            "batch: 804 loss: 0.10590265589859336\n",
            "batch: 805 loss: 0.10608660173323005\n",
            "batch: 806 loss: 0.10616086862143129\n",
            "batch: 807 loss: 0.10659587759431452\n",
            "batch: 808 loss: 0.10666508420463651\n",
            "batch: 809 loss: 0.10680844744201749\n",
            "batch: 810 loss: 0.10698289772029966\n",
            "batch: 811 loss: 0.10711963813658804\n",
            "batch: 812 loss: 0.10719915878679603\n",
            "batch: 813 loss: 0.10722479797061532\n",
            "batch: 814 loss: 0.10742386280652136\n",
            "batch: 815 loss: 0.10750092171784491\n",
            "batch: 816 loss: 0.10752841194998473\n",
            "batch: 817 loss: 0.10760877315979452\n",
            "batch: 818 loss: 0.10766202198620886\n",
            "batch: 819 loss: 0.10774999249633402\n",
            "batch: 820 loss: 0.10792468803282827\n",
            "batch: 821 loss: 0.10802944528218358\n",
            "batch: 822 loss: 0.1080962999900803\n",
            "batch: 823 loss: 0.1081368330558762\n",
            "batch: 824 loss: 0.1083434378048405\n",
            "batch: 825 loss: 0.10835559108667076\n",
            "batch: 826 loss: 0.1084796961825341\n",
            "batch: 827 loss: 0.10864425688795745\n",
            "batch: 828 loss: 0.10885718978755177\n",
            "batch: 829 loss: 0.10910665143840015\n",
            "batch: 830 loss: 0.109119533944875\n",
            "batch: 831 loss: 0.10931978454068303\n",
            "batch: 832 loss: 0.10934571911394596\n",
            "batch: 833 loss: 0.10957654668390751\n",
            "batch: 834 loss: 0.10977215641736984\n",
            "batch: 835 loss: 0.1098732623308897\n",
            "batch: 836 loss: 0.11001444871723652\n",
            "batch: 837 loss: 0.11026655875146389\n",
            "batch: 838 loss: 0.11036696273088455\n",
            "batch: 839 loss: 0.11044319080561399\n",
            "batch: 840 loss: 0.11053541669249535\n",
            "batch: 841 loss: 0.11056422751024365\n",
            "batch: 842 loss: 0.11060654701292515\n",
            "batch: 843 loss: 0.11067093223333359\n",
            "batch: 844 loss: 0.11080873045325279\n",
            "batch: 845 loss: 0.11090844939649105\n",
            "batch: 846 loss: 0.1109309961386025\n",
            "batch: 847 loss: 0.11097613768652081\n",
            "batch: 848 loss: 0.11105513709411025\n",
            "batch: 849 loss: 0.11111049183085561\n",
            "batch: 850 loss: 0.11125542387738824\n",
            "batch: 851 loss: 0.11135306626185774\n",
            "batch: 852 loss: 0.11139795561879873\n",
            "batch: 853 loss: 0.11146055864542723\n",
            "batch: 854 loss: 0.11154644309729338\n",
            "batch: 855 loss: 0.11169392380863429\n",
            "batch: 856 loss: 0.11171762474812567\n",
            "batch: 857 loss: 0.11189630114473402\n",
            "batch: 858 loss: 0.1119374377746135\n",
            "batch: 859 loss: 0.1120461803842336\n",
            "batch: 860 loss: 0.1122417406309396\n",
            "batch: 861 loss: 0.11235394674725831\n",
            "batch: 862 loss: 0.1125159813631326\n",
            "batch: 863 loss: 0.11266579200513661\n",
            "batch: 864 loss: 0.11282420160062612\n",
            "batch: 865 loss: 0.11291490579582751\n",
            "batch: 866 loss: 0.11321196673251689\n",
            "batch: 867 loss: 0.11329182921536267\n",
            "batch: 868 loss: 0.11350560803897679\n",
            "batch: 869 loss: 0.11351315144775435\n",
            "batch: 870 loss: 0.11392794744251296\n",
            "batch: 871 loss: 0.11395800842670724\n",
            "batch: 872 loss: 0.11397329857992008\n",
            "batch: 873 loss: 0.11419379977928475\n",
            "batch: 874 loss: 0.1142243535076268\n",
            "batch: 875 loss: 0.11424270602548495\n",
            "batch: 876 loss: 0.11433125455165281\n",
            "batch: 877 loss: 0.11433652935130521\n",
            "batch: 878 loss: 0.11447950027091429\n",
            "batch: 879 loss: 0.11450821715174243\n",
            "batch: 880 loss: 0.11455156059889122\n",
            "batch: 881 loss: 0.11476985875098035\n",
            "batch: 882 loss: 0.11484177167294547\n",
            "batch: 883 loss: 0.11487767658708617\n",
            "batch: 884 loss: 0.11492134558735416\n",
            "batch: 885 loss: 0.1151799353021197\n",
            "batch: 886 loss: 0.11524338231561705\n",
            "batch: 887 loss: 0.1153973555075936\n",
            "batch: 888 loss: 0.11550640140054748\n",
            "batch: 889 loss: 0.11556195888994261\n",
            "batch: 890 loss: 0.11558690866967664\n",
            "batch: 891 loss: 0.11571980635961518\n",
            "batch: 892 loss: 0.115754701027181\n",
            "batch: 893 loss: 0.11590395804634318\n",
            "batch: 894 loss: 0.11596881998470053\n",
            "batch: 895 loss: 0.11628823957731947\n",
            "batch: 896 loss: 0.11643251583864912\n",
            "batch: 897 loss: 0.11645658697886392\n",
            "batch: 898 loss: 0.1166850308100693\n",
            "batch: 899 loss: 0.11671239472506569\n",
            "batch: 900 loss: 0.11673753379611299\n",
            "batch: 901 loss: 0.11682443564711138\n",
            "batch: 902 loss: 0.11691296954033896\n",
            "batch: 903 loss: 0.11700504958955571\n",
            "batch: 904 loss: 0.11705009813560173\n",
            "batch: 905 loss: 0.11710963602317497\n",
            "batch: 906 loss: 0.11759544242871925\n",
            "batch: 907 loss: 0.1176144619579427\n",
            "batch: 908 loss: 0.11767226353241131\n",
            "batch: 909 loss: 0.1176920472397469\n",
            "batch: 910 loss: 0.11772710321238264\n",
            "batch: 911 loss: 0.11775506439944729\n",
            "batch: 912 loss: 0.1180994098498486\n",
            "batch: 913 loss: 0.11815224688639864\n",
            "batch: 914 loss: 0.11843209140887484\n",
            "batch: 915 loss: 0.11872811427107081\n",
            "batch: 916 loss: 0.11905553632369265\n",
            "batch: 917 loss: 0.11909012224292383\n",
            "batch: 918 loss: 0.11912841955712065\n",
            "batch: 919 loss: 0.11935450052609667\n",
            "batch: 920 loss: 0.11937333711748943\n",
            "batch: 921 loss: 0.11941618134593592\n",
            "batch: 922 loss: 0.11947977112745867\n",
            "batch: 923 loss: 0.11948583611147479\n",
            "batch: 924 loss: 0.11973152376012877\n",
            "batch: 925 loss: 0.12004162759380416\n",
            "batch: 926 loss: 0.12010735681699589\n",
            "batch: 927 loss: 0.1204210439925082\n",
            "batch: 928 loss: 0.12054962927149608\n",
            "batch: 929 loss: 0.12065888710366562\n",
            "batch: 930 loss: 0.12077244949387386\n",
            "batch: 931 loss: 0.12088243302004412\n",
            "batch: 932 loss: 0.12114551617996767\n",
            "batch: 933 loss: 0.12122006164537742\n",
            "batch: 934 loss: 0.12141975940810516\n",
            "batch: 935 loss: 0.12166823713527992\n",
            "batch: 936 loss: 0.12193857653485611\n",
            "batch: 937 loss: 0.1221461406503804\n",
            "batch: 938 loss: 0.12218163671018556\n",
            "batch: 939 loss: 0.12224666729243472\n",
            "batch: 940 loss: 0.12245406889589504\n",
            "batch: 941 loss: 0.1226792687443085\n",
            "batch: 942 loss: 0.12269724999601021\n",
            "batch: 943 loss: 0.12272813495667652\n",
            "batch: 944 loss: 0.12286303108604625\n",
            "batch: 945 loss: 0.12298414691956713\n",
            "batch: 946 loss: 0.12314741256507114\n",
            "batch: 947 loss: 0.12316723594116047\n",
            "batch: 948 loss: 0.12322918171109631\n",
            "batch: 949 loss: 0.12334459847630933\n",
            "batch: 950 loss: 0.1234214774412103\n",
            "batch: 951 loss: 0.1235494181853719\n",
            "batch: 952 loss: 0.12362199124367908\n",
            "batch: 953 loss: 0.12382787733944133\n",
            "batch: 954 loss: 0.12404061093600467\n",
            "batch: 955 loss: 0.12407523891003802\n",
            "batch: 956 loss: 0.12436038097413257\n",
            "batch: 957 loss: 0.12439535359712317\n",
            "batch: 958 loss: 0.1244230606299825\n",
            "batch: 959 loss: 0.1247624417883344\n",
            "batch: 960 loss: 0.12487963137449697\n",
            "batch: 961 loss: 0.12492402226896956\n",
            "batch: 962 loss: 0.12501741900714114\n",
            "batch: 963 loss: 0.1251523380992003\n",
            "batch: 964 loss: 0.12519839161308483\n",
            "batch: 965 loss: 0.12522299206489698\n",
            "batch: 966 loss: 0.12527875262359156\n",
            "batch: 967 loss: 0.12540505723515524\n",
            "batch: 968 loss: 0.12545322383427993\n",
            "batch: 969 loss: 0.12559483570838348\n",
            "batch: 970 loss: 0.12560976253123954\n",
            "batch: 971 loss: 0.1256761008319445\n",
            "batch: 972 loss: 0.12583543932111935\n",
            "batch: 973 loss: 0.12598544574948028\n",
            "batch: 974 loss: 0.12629504374833778\n",
            "batch: 975 loss: 0.12636812205286696\n",
            "batch: 976 loss: 0.126527111959178\n",
            "batch: 977 loss: 0.12662962551089005\n",
            "batch: 978 loss: 0.12671694279881193\n",
            "batch: 979 loss: 0.12684807648928836\n",
            "batch: 980 loss: 0.12701742744119837\n",
            "batch: 981 loss: 0.1272107261088677\n",
            "batch: 982 loss: 0.12739782249601558\n",
            "batch: 983 loss: 0.12743591537373142\n",
            "batch: 984 loss: 0.12755626505659892\n",
            "batch: 985 loss: 0.1276753237028606\n",
            "batch: 986 loss: 0.1277240248476155\n",
            "batch: 987 loss: 0.1278048400883563\n",
            "batch: 988 loss: 0.12807257580803708\n",
            "batch: 989 loss: 0.1283289138977416\n",
            "batch: 990 loss: 0.12845181748317555\n",
            "batch: 991 loss: 0.12856042470084503\n",
            "batch: 992 loss: 0.1286357224737294\n",
            "batch: 993 loss: 0.12873409032123162\n",
            "batch: 994 loss: 0.12898071613209322\n",
            "batch: 995 loss: 0.12914889601664617\n",
            "batch: 996 loss: 0.12920857993559912\n",
            "batch: 997 loss: 0.129421563454438\n",
            "batch: 998 loss: 0.1294567529526539\n",
            "batch: 1000 loss: 0.12951354694413023\n",
            "batch: 1001 loss: 0.12986368924425915\n",
            "batch: 1002 loss: 0.12995046292291954\n",
            "batch: 1003 loss: 0.13034891174780205\n",
            "batch: 1004 loss: 0.13042474019574002\n",
            "batch: 1005 loss: 0.1305099290763028\n",
            "batch: 1006 loss: 0.13070286397682504\n",
            "batch: 1007 loss: 0.13077099732356146\n",
            "batch: 1008 loss: 0.13080377721833064\n",
            "batch: 1009 loss: 0.13094113622652367\n",
            "batch: 1010 loss: 0.1310580525402911\n",
            "batch: 1011 loss: 0.13111954094888642\n",
            "batch: 1012 loss: 0.1311529375319369\n",
            "batch: 1013 loss: 0.13125840000854805\n",
            "batch: 1014 loss: 0.13136052018450572\n",
            "batch: 1015 loss: 0.13144017809676006\n",
            "batch: 1016 loss: 0.13148118379386142\n",
            "batch: 1017 loss: 0.1315912087080069\n",
            "batch: 1018 loss: 0.131757050734479\n",
            "batch: 1019 loss: 0.13189207982691004\n",
            "batch: 1020 loss: 0.13208394963713363\n",
            "batch: 1021 loss: 0.13232329833181575\n",
            "batch: 1022 loss: 0.13242489250423387\n",
            "batch: 1023 loss: 0.13249869463266806\n",
            "batch: 1024 loss: 0.13255487599642948\n",
            "batch: 1025 loss: 0.13264258983405308\n",
            "batch: 1026 loss: 0.13269719478162006\n",
            "batch: 1027 loss: 0.13311650892766191\n",
            "batch: 1028 loss: 0.13346174004347994\n",
            "batch: 1029 loss: 0.13356966205360368\n",
            "batch: 1030 loss: 0.1339002447319217\n",
            "batch: 1031 loss: 0.13399427815200762\n",
            "batch: 1032 loss: 0.1340198141974397\n",
            "batch: 1033 loss: 0.13420299123646692\n",
            "batch: 1034 loss: 0.13430032636644318\n",
            "batch: 1035 loss: 0.13439205411495642\n",
            "batch: 1036 loss: 0.13443831590237096\n",
            "batch: 1037 loss: 0.13463911308767273\n",
            "batch: 1038 loss: 0.1347352152657695\n",
            "batch: 1039 loss: 0.1347808852721937\n",
            "batch: 1040 loss: 0.13492078735725954\n",
            "batch: 1041 loss: 0.13500183327542617\n",
            "batch: 1042 loss: 0.13520608364092185\n",
            "batch: 1043 loss: 0.13521965696895494\n",
            "batch: 1044 loss: 0.13535792038822547\n",
            "batch: 1045 loss: 0.13550426534796134\n",
            "batch: 1046 loss: 0.1357449741610326\n",
            "batch: 1047 loss: 0.13592325110221282\n",
            "batch: 1048 loss: 0.13602346924925224\n",
            "batch: 1049 loss: 0.13605026319855823\n",
            "batch: 1050 loss: 0.13634518859023229\n",
            "batch: 1051 loss: 0.1363593742181547\n",
            "batch: 1052 loss: 0.1365335803856142\n",
            "batch: 1053 loss: 0.13655185194360092\n",
            "batch: 1054 loss: 0.1365855268840678\n",
            "batch: 1055 loss: 0.13679162393556907\n",
            "batch: 1056 loss: 0.13684713251935318\n",
            "batch: 1057 loss: 0.13695021405117586\n",
            "batch: 1058 loss: 0.13728547301189975\n",
            "batch: 1059 loss: 0.13741855426924304\n",
            "batch: 1060 loss: 0.13752493653493003\n",
            "batch: 1061 loss: 0.13756429616035892\n",
            "batch: 1062 loss: 0.13761180780874566\n",
            "batch: 1063 loss: 0.13772464782046154\n",
            "batch: 1064 loss: 0.13792492477642374\n",
            "batch: 1065 loss: 0.1379639853318222\n",
            "batch: 1066 loss: 0.1379811889459379\n",
            "batch: 1067 loss: 0.13828781353728845\n",
            "batch: 1068 loss: 0.13838781946944073\n",
            "batch: 1069 loss: 0.13852465276466683\n",
            "batch: 1070 loss: 0.1386436259751208\n",
            "batch: 1071 loss: 0.13865335840871557\n",
            "batch: 1072 loss: 0.13884118504216894\n",
            "batch: 1073 loss: 0.1389507974325679\n",
            "batch: 1074 loss: 0.13912218848755584\n",
            "batch: 1075 loss: 0.1392275482355617\n",
            "batch: 1076 loss: 0.13930732748797164\n",
            "batch: 1077 loss: 0.13939171397080646\n",
            "batch: 1078 loss: 0.13947272803029045\n",
            "batch: 1079 loss: 0.13953860031208024\n",
            "batch: 1080 loss: 0.13977137810131535\n",
            "batch: 1081 loss: 0.13986625647684559\n",
            "batch: 1082 loss: 0.13998491501947866\n",
            "batch: 1083 loss: 0.14013632552465424\n",
            "batch: 1084 loss: 0.14041866915067658\n",
            "batch: 1085 loss: 0.14054454603930935\n",
            "batch: 1086 loss: 0.1408010939671658\n",
            "batch: 1087 loss: 0.14107235729834064\n",
            "batch: 1088 loss: 0.14110392887284978\n",
            "batch: 1089 loss: 0.14112881267955527\n",
            "batch: 1090 loss: 0.14120524048944935\n",
            "batch: 1091 loss: 0.14140381932398305\n",
            "batch: 1092 loss: 0.14165620935102924\n",
            "batch: 1093 loss: 0.14186836847802625\n",
            "batch: 1094 loss: 0.14188667839160188\n",
            "batch: 1095 loss: 0.14217409720411525\n",
            "batch: 1096 loss: 0.14220485008647665\n",
            "batch: 1097 loss: 0.142322854348924\n",
            "batch: 1098 loss: 0.14255488593271\n",
            "batch: 1099 loss: 0.14259064702829347\n",
            "batch: 1100 loss: 0.1426419015689753\n",
            "batch: 1101 loss: 0.14280874052783474\n",
            "batch: 1102 loss: 0.14286598613252863\n",
            "batch: 1103 loss: 0.1429486160366796\n",
            "batch: 1104 loss: 0.14297137995203957\n",
            "batch: 1105 loss: 0.14314335733791814\n",
            "batch: 1106 loss: 0.14335285432776437\n",
            "batch: 1107 loss: 0.1433771826303564\n",
            "batch: 1108 loss: 0.14352741749351844\n",
            "batch: 1109 loss: 0.14355446321470663\n",
            "batch: 1110 loss: 0.14374742164416238\n",
            "batch: 1111 loss: 0.14391639143927024\n",
            "batch: 1112 loss: 0.1440684505472891\n",
            "batch: 1113 loss: 0.14419007416767998\n",
            "batch: 1114 loss: 0.1442619500081055\n",
            "batch: 1115 loss: 0.1443047617780976\n",
            "batch: 1116 loss: 0.1444831657218747\n",
            "batch: 1117 loss: 0.14468639011261986\n",
            "batch: 1118 loss: 0.14482244988856838\n",
            "batch: 1119 loss: 0.14489010873762892\n",
            "batch: 1120 loss: 0.1449338089930825\n",
            "batch: 1121 loss: 0.14499142565904186\n",
            "batch: 1122 loss: 0.1451423899489455\n",
            "batch: 1123 loss: 0.14545656355796382\n",
            "batch: 1124 loss: 0.14555397281376645\n",
            "batch: 1125 loss: 0.14566058405069635\n",
            "batch: 1126 loss: 0.14580146473972128\n",
            "batch: 1127 loss: 0.14611333719221875\n",
            "batch: 1128 loss: 0.14641448819963263\n",
            "batch: 1129 loss: 0.14646506535215303\n",
            "batch: 1130 loss: 0.14661311560077592\n",
            "batch: 1131 loss: 0.14684444554848597\n",
            "batch: 1132 loss: 0.14712500216765328\n",
            "batch: 1133 loss: 0.14742247416777537\n",
            "batch: 1134 loss: 0.14754201198322697\n",
            "batch: 1135 loss: 0.14763156161410734\n",
            "batch: 1136 loss: 0.14772597687644884\n",
            "batch: 1137 loss: 0.1477572434055619\n",
            "batch: 1138 loss: 0.14787377249775455\n",
            "batch: 1139 loss: 0.14804162224708126\n",
            "batch: 1140 loss: 0.14810583099303767\n",
            "batch: 1141 loss: 0.1482309146183543\n",
            "batch: 1142 loss: 0.14834356218157335\n",
            "batch: 1143 loss: 0.14837055110326036\n",
            "batch: 1144 loss: 0.1484112487374805\n",
            "batch: 1145 loss: 0.1486132526784204\n",
            "batch: 1146 loss: 0.14899229807546363\n",
            "batch: 1147 loss: 0.14908739904453977\n",
            "batch: 1148 loss: 0.1491442316561006\n",
            "batch: 1149 loss: 0.14935638458421455\n",
            "batch: 1150 loss: 0.1494407739280723\n",
            "batch: 1151 loss: 0.14980118315806612\n",
            "batch: 1152 loss: 0.14998702227463945\n",
            "batch: 1153 loss: 0.15006283370545134\n",
            "batch: 1154 loss: 0.1502567201196216\n",
            "batch: 1155 loss: 0.1505607011555694\n",
            "batch: 1156 loss: 0.15059938886901364\n",
            "batch: 1157 loss: 0.1509725002362393\n",
            "batch: 1158 loss: 0.15102480386709793\n",
            "batch: 1159 loss: 0.1511113988882862\n",
            "batch: 1160 loss: 0.1511363414633088\n",
            "batch: 1161 loss: 0.1511731040100567\n",
            "batch: 1162 loss: 0.1513179749767296\n",
            "batch: 1163 loss: 0.15153369935555383\n",
            "batch: 1164 loss: 0.15163874905509875\n",
            "batch: 1165 loss: 0.15170838899118827\n",
            "batch: 1166 loss: 0.1517590192477219\n",
            "batch: 1167 loss: 0.1518218579213135\n",
            "batch: 1168 loss: 0.15194743706984445\n",
            "batch: 1169 loss: 0.152010847307276\n",
            "batch: 1170 loss: 0.15207655246509239\n",
            "batch: 1171 loss: 0.1523704864825122\n",
            "batch: 1172 loss: 0.15245960961235688\n",
            "batch: 1173 loss: 0.15247307394677773\n",
            "batch: 1174 loss: 0.1526327615850605\n",
            "batch: 1175 loss: 0.15265214306348934\n",
            "batch: 1176 loss: 0.15280737059051172\n",
            "batch: 1177 loss: 0.15283740370580925\n",
            "batch: 1178 loss: 0.1528696215027012\n",
            "batch: 1179 loss: 0.1529139312156476\n",
            "batch: 1180 loss: 0.1531186031945981\n",
            "batch: 1181 loss: 0.15316498635569586\n",
            "batch: 1182 loss: 0.15346243209997193\n",
            "batch: 1183 loss: 0.1537838642434217\n",
            "batch: 1184 loss: 0.15405786643782632\n",
            "batch: 1185 loss: 0.1542241577343084\n",
            "batch: 1186 loss: 0.15428696539858355\n",
            "batch: 1187 loss: 0.1545313034192659\n",
            "batch: 1188 loss: 0.15465296575287357\n",
            "batch: 1189 loss: 0.15474078436056152\n",
            "batch: 1190 loss: 0.1547675925907679\n",
            "batch: 1191 loss: 0.1548289065924473\n",
            "batch: 1192 loss: 0.15487363183917477\n",
            "batch: 1193 loss: 0.15504731828393414\n",
            "batch: 1194 loss: 0.15538571697892622\n",
            "batch: 1195 loss: 0.15539255303610117\n",
            "batch: 1196 loss: 0.15542869674135\n",
            "batch: 1197 loss: 0.15558620653022082\n",
            "batch: 1198 loss: 0.15561541303712875\n",
            "batch: 1199 loss: 0.15567876645643264\n",
            "batch: 1200 loss: 0.1557274884553626\n",
            "batch: 1201 loss: 0.15576525924075396\n",
            "batch: 1202 loss: 0.15591693397331982\n",
            "batch: 1203 loss: 0.15598354766983538\n",
            "batch: 1204 loss: 0.15620782613474876\n",
            "batch: 1205 loss: 0.15624690323416143\n",
            "batch: 1206 loss: 0.15630015888158233\n",
            "batch: 1207 loss: 0.15635684629995375\n",
            "batch: 1208 loss: 0.15652042036969216\n",
            "batch: 1209 loss: 0.15655731866229325\n",
            "batch: 1210 loss: 0.15656966195534916\n",
            "batch: 1211 loss: 0.15657910193223507\n",
            "batch: 1212 loss: 0.1567318463595584\n",
            "batch: 1213 loss: 0.15677013197634368\n",
            "batch: 1214 loss: 0.15680533090326934\n",
            "batch: 1215 loss: 0.15683220890443772\n",
            "batch: 1216 loss: 0.1568753433628008\n",
            "batch: 1217 loss: 0.15689046103786677\n",
            "batch: 1218 loss: 0.15705662613641472\n",
            "batch: 1219 loss: 0.15743075200449674\n",
            "batch: 1220 loss: 0.15748711455892772\n",
            "batch: 1221 loss: 0.1576495451433584\n",
            "batch: 1222 loss: 0.1576980178495869\n",
            "batch: 1223 loss: 0.15774223995115608\n",
            "batch: 1224 loss: 0.15779553910251706\n",
            "batch: 1225 loss: 0.1579090329175815\n",
            "batch: 1226 loss: 0.15794814974721522\n",
            "batch: 1227 loss: 0.157985376435332\n",
            "batch: 1228 loss: 0.15812499387841672\n",
            "batch: 1229 loss: 0.15836933259945363\n",
            "batch: 1230 loss: 0.15849352626036853\n",
            "batch: 1231 loss: 0.15850223516765982\n",
            "batch: 1232 loss: 0.15863725077454\n",
            "batch: 1233 loss: 0.15877600593212993\n",
            "batch: 1234 loss: 0.15886545948777347\n",
            "batch: 1235 loss: 0.15890637882892042\n",
            "batch: 1236 loss: 0.15892593660671264\n",
            "batch: 1237 loss: 0.15902682914305477\n",
            "batch: 1238 loss: 0.15912608941365033\n",
            "batch: 1239 loss: 0.15936990182567387\n",
            "batch: 1240 loss: 0.15964070444274694\n",
            "batch: 1241 loss: 0.15968791759479792\n",
            "batch: 1242 loss: 0.15976522683817893\n",
            "batch: 1243 loss: 0.15992295434791595\n",
            "batch: 1244 loss: 0.16013627929706126\n",
            "batch: 1245 loss: 0.16016712926048784\n",
            "batch: 1246 loss: 0.16027348869014532\n",
            "batch: 1247 loss: 0.16029785137530417\n",
            "batch: 1248 loss: 0.16038261613901705\n",
            "batch: 1249 loss: 0.16051793121453375\n",
            "batch: 1250 loss: 0.16052475798595697\n",
            "batch: 1251 loss: 0.16054154884349556\n",
            "batch: 1252 loss: 0.16059825080167503\n",
            "batch: 1253 loss: 0.1608482400132343\n",
            "batch: 1254 loss: 0.16099353304039687\n",
            "batch: 1255 loss: 0.16104759729187937\n",
            "batch: 1256 loss: 0.1613065623668954\n",
            "batch: 1257 loss: 0.16140655321162195\n",
            "batch: 1258 loss: 0.1614625004818663\n",
            "batch: 1259 loss: 0.1614656665562652\n",
            "batch: 1260 loss: 0.16155242646625265\n",
            "batch: 1261 loss: 0.16169585555186494\n",
            "batch: 1262 loss: 0.16171057814965026\n",
            "batch: 1263 loss: 0.1618500358820893\n",
            "batch: 1264 loss: 0.16194362047920002\n",
            "batch: 1265 loss: 0.1619637088594027\n",
            "batch: 1266 loss: 0.1622989249941893\n",
            "batch: 1267 loss: 0.1623040555678308\n",
            "batch: 1268 loss: 0.16243517495319248\n",
            "batch: 1269 loss: 0.1624799527004361\n",
            "batch: 1270 loss: 0.16257914287596942\n",
            "batch: 1271 loss: 0.16267151058465243\n",
            "batch: 1272 loss: 0.16271205669641495\n",
            "batch: 1273 loss: 0.16317567408084868\n",
            "batch: 1274 loss: 0.16321634824573994\n",
            "batch: 1275 loss: 0.16329799012094737\n",
            "batch: 1276 loss: 0.16345555315166713\n",
            "batch: 1277 loss: 0.1636521859690547\n",
            "batch: 1278 loss: 0.16371763829141855\n",
            "batch: 1279 loss: 0.16374021359346808\n",
            "batch: 1280 loss: 0.16380629980377853\n",
            "batch: 1281 loss: 0.164113599864766\n",
            "batch: 1282 loss: 0.16429954500310123\n",
            "batch: 1283 loss: 0.1645288859140128\n",
            "batch: 1284 loss: 0.16463060989789666\n",
            "batch: 1285 loss: 0.16472208352200687\n",
            "batch: 1286 loss: 0.16473447020351886\n",
            "batch: 1287 loss: 0.1648078812509775\n",
            "batch: 1288 loss: 0.16485528092831372\n",
            "batch: 1289 loss: 0.1648944418504834\n",
            "batch: 1290 loss: 0.16518198592215777\n",
            "batch: 1291 loss: 0.16536442636698484\n",
            "batch: 1292 loss: 0.1653847574777901\n",
            "batch: 1293 loss: 0.1657018400616944\n",
            "batch: 1294 loss: 0.16589736168459057\n",
            "batch: 1295 loss: 0.16599194012954832\n",
            "batch: 1296 loss: 0.1660780118741095\n",
            "batch: 1297 loss: 0.16613992988318205\n",
            "batch: 1298 loss: 0.16623255816847085\n",
            "batch: 1299 loss: 0.16626178047433496\n",
            "batch: 1300 loss: 0.1662988793514669\n",
            "batch: 1301 loss: 0.16643557527288794\n",
            "batch: 1302 loss: 0.16656471556052566\n",
            "batch: 1303 loss: 0.16665399250015617\n",
            "batch: 1304 loss: 0.166698794092983\n",
            "batch: 1305 loss: 0.16671083312947302\n",
            "batch: 1306 loss: 0.166902232256718\n",
            "batch: 1307 loss: 0.16724960234481842\n",
            "batch: 1308 loss: 0.16767033919412644\n",
            "batch: 1309 loss: 0.16774015790689736\n",
            "batch: 1310 loss: 0.16791089375782758\n",
            "batch: 1311 loss: 0.16810048640239983\n",
            "batch: 1312 loss: 0.16814202268142253\n",
            "batch: 1313 loss: 0.1684166652681306\n",
            "batch: 1314 loss: 0.16847307087201624\n",
            "batch: 1315 loss: 0.1686292611779645\n",
            "batch: 1316 loss: 0.16875305839348584\n",
            "batch: 1317 loss: 0.16907658316660673\n",
            "batch: 1318 loss: 0.1692007650407031\n",
            "batch: 1319 loss: 0.1694023322435096\n",
            "batch: 1320 loss: 0.16944877285230905\n",
            "batch: 1321 loss: 0.16949968931172044\n",
            "batch: 1322 loss: 0.16974103367421775\n",
            "batch: 1323 loss: 0.1699979754993692\n",
            "batch: 1324 loss: 0.17020032544527203\n",
            "batch: 1325 loss: 0.17026594830397518\n",
            "batch: 1326 loss: 0.17048728194180876\n",
            "batch: 1327 loss: 0.1705739578763023\n",
            "batch: 1328 loss: 0.17062763451132923\n",
            "batch: 1329 loss: 0.1706999257588759\n",
            "batch: 1330 loss: 0.17077846721652895\n",
            "batch: 1331 loss: 0.17082350636739282\n",
            "batch: 1332 loss: 0.17084405497740954\n",
            "batch: 1333 loss: 0.17091101982723922\n",
            "batch: 1334 loss: 0.17114318011235446\n",
            "batch: 1335 loss: 0.17117999353539198\n",
            "batch: 1336 loss: 0.17120700085069984\n",
            "batch: 1337 loss: 0.1714147480269894\n",
            "batch: 1338 loss: 0.17147253285627811\n",
            "batch: 1339 loss: 0.17156194729637356\n",
            "batch: 1340 loss: 0.17169102753233165\n",
            "batch: 1341 loss: 0.17173683110903948\n",
            "batch: 1342 loss: 0.1718433105153963\n",
            "batch: 1343 loss: 0.1718891979670152\n",
            "batch: 1344 loss: 0.17230970673915\n",
            "batch: 1345 loss: 0.17239362423028798\n",
            "batch: 1346 loss: 0.1725245768567547\n",
            "batch: 1347 loss: 0.172722787453793\n",
            "batch: 1348 loss: 0.17275435874145478\n",
            "batch: 1349 loss: 0.1728506036279723\n",
            "batch: 1350 loss: 0.17287256732489914\n",
            "batch: 1351 loss: 0.17293902502860875\n",
            "batch: 1352 loss: 0.17311939726676792\n",
            "batch: 1353 loss: 0.173202438919805\n",
            "batch: 1354 loss: 0.17335383185651154\n",
            "batch: 1355 loss: 0.17337226015981286\n",
            "batch: 1356 loss: 0.1734418420260772\n",
            "batch: 1357 loss: 0.1735853415792808\n",
            "batch: 1358 loss: 0.1738445382779464\n",
            "batch: 1359 loss: 0.17404472494777293\n",
            "batch: 1360 loss: 0.17412857302185147\n",
            "batch: 1361 loss: 0.17415738887619228\n",
            "batch: 1362 loss: 0.17426872725319117\n",
            "batch: 1363 loss: 0.17440121106337755\n",
            "batch: 1364 loss: 0.174468387122266\n",
            "batch: 1365 loss: 0.17450673224311322\n",
            "batch: 1366 loss: 0.17455985061731188\n",
            "batch: 1367 loss: 0.17475275798048823\n",
            "batch: 1368 loss: 0.17490443140175194\n",
            "batch: 1369 loss: 0.17507018014695494\n",
            "batch: 1370 loss: 0.1752279536416754\n",
            "batch: 1371 loss: 0.17538582870271058\n",
            "batch: 1372 loss: 0.17565374570991843\n",
            "batch: 1373 loss: 0.17578152725007384\n",
            "batch: 1374 loss: 0.17590168084856123\n",
            "batch: 1375 loss: 0.17591212578397245\n",
            "batch: 1376 loss: 0.17599450169783085\n",
            "batch: 1377 loss: 0.1760506541384384\n",
            "batch: 1378 loss: 0.1762042845292017\n",
            "batch: 1379 loss: 0.17644040777813644\n",
            "batch: 1380 loss: 0.1764603386586532\n",
            "batch: 1381 loss: 0.17654599656071515\n",
            "batch: 1382 loss: 0.1765831272257492\n",
            "batch: 1383 loss: 0.17665454982500522\n",
            "batch: 1384 loss: 0.1767516239164397\n",
            "batch: 1385 loss: 0.17698178358655423\n",
            "batch: 1386 loss: 0.17705810458492488\n",
            "batch: 1387 loss: 0.17710184942465276\n",
            "batch: 1388 loss: 0.17711488674674183\n",
            "batch: 1389 loss: 0.17725304848048837\n",
            "batch: 1390 loss: 0.17734757000301032\n",
            "batch: 1391 loss: 0.1774701065653935\n",
            "batch: 1392 loss: 0.17752388715092093\n",
            "batch: 1393 loss: 0.177697811239399\n",
            "batch: 1394 loss: 0.17790722879115492\n",
            "batch: 1395 loss: 0.17792822067532688\n",
            "batch: 1396 loss: 0.17796816337201743\n",
            "batch: 1397 loss: 0.178152180836536\n",
            "batch: 1398 loss: 0.178227793619968\n",
            "batch: 1399 loss: 0.17837622158322483\n",
            "batch: 1400 loss: 0.17848363485280425\n",
            "batch: 1401 loss: 0.17861716099921615\n",
            "batch: 1402 loss: 0.17867509735096246\n",
            "batch: 1403 loss: 0.1788340342985466\n",
            "batch: 1404 loss: 0.17890273049939423\n",
            "batch: 1405 loss: 0.17893254131358116\n",
            "batch: 1406 loss: 0.17896809665393085\n",
            "batch: 1407 loss: 0.1794461970133707\n",
            "batch: 1408 loss: 0.17948124495428056\n",
            "batch: 1409 loss: 0.1796569612203166\n",
            "batch: 1410 loss: 0.17967610391508787\n",
            "batch: 1411 loss: 0.17999798741471024\n",
            "batch: 1412 loss: 0.1801823053760454\n",
            "batch: 1413 loss: 0.1802765810294077\n",
            "batch: 1414 loss: 0.1803179989559576\n",
            "batch: 1415 loss: 0.18049778787326068\n",
            "batch: 1416 loss: 0.18061040443461387\n",
            "batch: 1417 loss: 0.1809971744446084\n",
            "batch: 1418 loss: 0.18125013357680292\n",
            "batch: 1419 loss: 0.18130029711406678\n",
            "batch: 1420 loss: 0.18151382696907967\n",
            "batch: 1421 loss: 0.18159523955266924\n",
            "batch: 1422 loss: 0.18170271317940206\n",
            "batch: 1423 loss: 0.18177959758322687\n",
            "batch: 1424 loss: 0.18181003519054503\n",
            "batch: 1425 loss: 0.18212273263093084\n",
            "batch: 1426 loss: 0.18213999311905354\n",
            "batch: 1427 loss: 0.18221077949833125\n",
            "batch: 1428 loss: 0.18228233780246228\n",
            "batch: 1429 loss: 0.18237643552850932\n",
            "batch: 1430 loss: 0.18256199867557735\n",
            "batch: 1431 loss: 0.1826003752304241\n",
            "batch: 1432 loss: 0.1826571185430512\n",
            "batch: 1433 loss: 0.1827598315393552\n",
            "batch: 1434 loss: 0.18309205558057876\n",
            "batch: 1435 loss: 0.18318808604683728\n",
            "batch: 1436 loss: 0.18327358489390463\n",
            "batch: 1437 loss: 0.1833192002242431\n",
            "batch: 1438 loss: 0.18344056370016187\n",
            "batch: 1439 loss: 0.18348128037061542\n",
            "batch: 1440 loss: 0.18363520865049213\n",
            "batch: 1441 loss: 0.18373193712439387\n",
            "batch: 1442 loss: 0.18379957980569453\n",
            "batch: 1443 loss: 0.18385875436570495\n",
            "batch: 1444 loss: 0.18415602648165078\n",
            "batch: 1445 loss: 0.18434524956252427\n",
            "batch: 1446 loss: 0.1843834305247292\n",
            "batch: 1447 loss: 0.18444873852934687\n",
            "batch: 1448 loss: 0.18479624353256077\n",
            "batch: 1449 loss: 0.18481898586731405\n",
            "batch: 1450 loss: 0.18482868628855795\n",
            "batch: 1451 loss: 0.18493844535108656\n",
            "batch: 1452 loss: 0.18516791280265898\n",
            "batch: 1453 loss: 0.18587109240051358\n",
            "batch: 1454 loss: 0.18595112352725118\n",
            "batch: 1455 loss: 0.18609874483104796\n",
            "batch: 1456 loss: 0.186258787474595\n",
            "batch: 1457 loss: 0.18629168808739632\n",
            "batch: 1458 loss: 0.18659178543370217\n",
            "batch: 1459 loss: 0.18670634081494064\n",
            "batch: 1460 loss: 0.1867402227325365\n",
            "batch: 1461 loss: 0.1868370437277481\n",
            "batch: 1462 loss: 0.18696142757963388\n",
            "batch: 1463 loss: 0.18719658167194575\n",
            "batch: 1464 loss: 0.18731642423104494\n",
            "batch: 1465 loss: 0.18733820990007372\n",
            "batch: 1466 loss: 0.18742345547955483\n",
            "batch: 1467 loss: 0.18765229569654912\n",
            "batch: 1468 loss: 0.1876688808640465\n",
            "batch: 1469 loss: 0.18782060691621155\n",
            "batch: 1470 loss: 0.18785233105625956\n",
            "batch: 1471 loss: 0.18795094126369805\n",
            "batch: 1472 loss: 0.18805728278215975\n",
            "batch: 1473 loss: 0.18815593869891017\n",
            "batch: 1474 loss: 0.18824103876855225\n",
            "batch: 1475 loss: 0.18831317771133035\n",
            "batch: 1476 loss: 0.18851985410507768\n",
            "batch: 1477 loss: 0.18859364525135608\n",
            "batch: 1478 loss: 0.18867450425680726\n",
            "batch: 1479 loss: 0.18870054930727928\n",
            "batch: 1480 loss: 0.18882117835711687\n",
            "batch: 1481 loss: 0.18884776441659779\n",
            "batch: 1482 loss: 0.18888735550548882\n",
            "batch: 1483 loss: 0.18894249357562512\n",
            "batch: 1484 loss: 0.1890318973241374\n",
            "batch: 1485 loss: 0.18923632501345128\n",
            "batch: 1486 loss: 0.1893054772121832\n",
            "batch: 1487 loss: 0.1894514005286619\n",
            "batch: 1488 loss: 0.18952656188886613\n",
            "batch: 1489 loss: 0.18955060365516693\n",
            "batch: 1490 loss: 0.18963410526234656\n",
            "batch: 1491 loss: 0.1897318123774603\n",
            "batch: 1492 loss: 0.18983556771744042\n",
            "batch: 1493 loss: 0.18993821486551316\n",
            "batch: 1494 loss: 0.19032297977525742\n",
            "batch: 1495 loss: 0.19035370922926814\n",
            "batch: 1496 loss: 0.19040062184352427\n",
            "batch: 1497 loss: 0.19050890473742038\n",
            "batch: 1498 loss: 0.19054742642957717\n",
            "batch: 1499 loss: 0.19076005693990739\n",
            "batch: 1500 loss: 0.1909477766128257\n",
            "batch: 1501 loss: 0.19109866532403977\n",
            "batch: 1502 loss: 0.19123888054210691\n",
            "batch: 1503 loss: 0.19134689590055495\n",
            "batch: 1504 loss: 0.191392217499204\n",
            "batch: 1505 loss: 0.19144188611302526\n",
            "batch: 1506 loss: 0.1914824797185138\n",
            "batch: 1507 loss: 0.1916040436597541\n",
            "batch: 1508 loss: 0.19161450269911437\n",
            "batch: 1509 loss: 0.19168754130695015\n",
            "batch: 1510 loss: 0.19196991574857383\n",
            "batch: 1511 loss: 0.19201870270166546\n",
            "batch: 1512 loss: 0.19208891783747822\n",
            "batch: 1513 loss: 0.19212015959527343\n",
            "batch: 1514 loss: 0.19218627073522657\n",
            "batch: 1515 loss: 0.19223611728008835\n",
            "batch: 1516 loss: 0.19224888840783388\n",
            "batch: 1517 loss: 0.19231706999707968\n",
            "batch: 1518 loss: 0.19239591260720043\n",
            "batch: 1519 loss: 0.19240334960725158\n",
            "batch: 1520 loss: 0.19250855138059705\n",
            "batch: 1521 loss: 0.19266214517410846\n",
            "batch: 1522 loss: 0.19274459046777337\n",
            "batch: 1523 loss: 0.19278522246982902\n",
            "batch: 1524 loss: 0.19285019022878258\n",
            "batch: 1525 loss: 0.19289073710795493\n",
            "batch: 1526 loss: 0.1929926910093054\n",
            "batch: 1527 loss: 0.19305194858741015\n",
            "batch: 1528 loss: 0.19328976317774504\n",
            "batch: 1529 loss: 0.193318979694508\n",
            "batch: 1530 loss: 0.19355589492525904\n",
            "batch: 1531 loss: 0.19371864437963812\n",
            "batch: 1532 loss: 0.19376956811826676\n",
            "batch: 1533 loss: 0.19384192389529198\n",
            "batch: 1534 loss: 0.19396985118370502\n",
            "batch: 1535 loss: 0.19410761826019735\n",
            "batch: 1536 loss: 0.19429132347088307\n",
            "batch: 1537 loss: 0.1943745280979201\n",
            "batch: 1538 loss: 0.1944808525023982\n",
            "batch: 1539 loss: 0.1944993253191933\n",
            "batch: 1540 loss: 0.19462846989836544\n",
            "batch: 1541 loss: 0.19466550447698683\n",
            "batch: 1542 loss: 0.19473324976768344\n",
            "batch: 1543 loss: 0.19475040327291937\n",
            "batch: 1544 loss: 0.1948049611626193\n",
            "batch: 1545 loss: 0.19487132753711195\n",
            "batch: 1546 loss: 0.1950578554449603\n",
            "batch: 1547 loss: 0.19510059472452848\n",
            "batch: 1548 loss: 0.1951489279968664\n",
            "batch: 1549 loss: 0.19525116754602642\n",
            "batch: 1550 loss: 0.19536332794558256\n",
            "batch: 1551 loss: 0.19544978590589016\n",
            "batch: 1552 loss: 0.195536059464328\n",
            "batch: 1553 loss: 0.19573323314916344\n",
            "batch: 1554 loss: 0.19583993814419956\n",
            "batch: 1555 loss: 0.1960045271916315\n",
            "batch: 1556 loss: 0.19616173193883152\n",
            "batch: 1557 loss: 0.19627159335743635\n",
            "batch: 1558 loss: 0.1965037413937971\n",
            "batch: 1559 loss: 0.19653905629273505\n",
            "batch: 1560 loss: 0.19660670974012465\n",
            "batch: 1561 loss: 0.1968471942609176\n",
            "batch: 1562 loss: 0.19702769786771387\n",
            "batch: 1563 loss: 0.19711089686956257\n",
            "batch: 1564 loss: 0.19713903118949383\n",
            "batch: 1565 loss: 0.1972360378978774\n",
            "batch: 1566 loss: 0.1973379447935149\n",
            "batch: 1567 loss: 0.19735893441643565\n",
            "batch: 1568 loss: 0.1975892424127087\n",
            "batch: 1569 loss: 0.1976317547550425\n",
            "batch: 1570 loss: 0.19781643575336785\n",
            "batch: 1571 loss: 0.1978264910141006\n",
            "batch: 1572 loss: 0.19799465204868466\n",
            "batch: 1573 loss: 0.1980039432812482\n",
            "batch: 1574 loss: 0.19805180031619965\n",
            "batch: 1575 loss: 0.19810196307860314\n",
            "batch: 1576 loss: 0.19819313841871916\n",
            "batch: 1577 loss: 0.19827394141070545\n",
            "batch: 1578 loss: 0.19829100948385894\n",
            "batch: 1579 loss: 0.19852846415154635\n",
            "batch: 1580 loss: 0.19891676975600422\n",
            "batch: 1581 loss: 0.1989587449450046\n",
            "batch: 1582 loss: 0.19930553057976066\n",
            "batch: 1583 loss: 0.19943370342440903\n",
            "batch: 1584 loss: 0.19958968438394367\n",
            "batch: 1585 loss: 0.19977744597382843\n",
            "batch: 1586 loss: 0.19982414889521896\n",
            "batch: 1587 loss: 0.19989602381177246\n",
            "batch: 1588 loss: 0.20008193296380342\n",
            "batch: 1589 loss: 0.20011120670102536\n",
            "batch: 1590 loss: 0.20013815125264228\n",
            "batch: 1591 loss: 0.20018839845620096\n",
            "batch: 1592 loss: 0.20021418212912978\n",
            "batch: 1593 loss: 0.20036778349243103\n",
            "batch: 1594 loss: 0.20038677726872264\n",
            "batch: 1595 loss: 0.20061051143892109\n",
            "batch: 1596 loss: 0.20072354225255548\n",
            "batch: 1597 loss: 0.20092993910051882\n",
            "batch: 1598 loss: 0.20114044474996626\n",
            "batch: 1599 loss: 0.20132232695259153\n",
            "batch: 1600 loss: 0.20143643818236887\n",
            "batch: 1601 loss: 0.20145275529846549\n",
            "batch: 1602 loss: 0.2015194244198501\n",
            "batch: 1603 loss: 0.20153845833428205\n",
            "batch: 1604 loss: 0.20156445891968905\n",
            "batch: 1605 loss: 0.2017323542367667\n",
            "batch: 1606 loss: 0.2018520932774991\n",
            "batch: 1607 loss: 0.2019220468159765\n",
            "batch: 1608 loss: 0.202151403715834\n",
            "batch: 1609 loss: 0.20224936014227568\n",
            "batch: 1610 loss: 0.20233224578760564\n",
            "batch: 1611 loss: 0.20265332796238364\n",
            "batch: 1612 loss: 0.2028137560542673\n",
            "batch: 1613 loss: 0.2028527081441134\n",
            "batch: 1614 loss: 0.20286325938161462\n",
            "batch: 1615 loss: 0.20302846576925368\n",
            "batch: 1616 loss: 0.20321232848521323\n",
            "batch: 1617 loss: 0.2033457397883758\n",
            "batch: 1618 loss: 0.20342395714577288\n",
            "batch: 1619 loss: 0.203451639871113\n",
            "batch: 1620 loss: 0.20378785936068744\n",
            "batch: 1621 loss: 0.20382092957850545\n",
            "batch: 1622 loss: 0.20396089776512236\n",
            "batch: 1623 loss: 0.20408942120429127\n",
            "batch: 1624 loss: 0.20411209573503583\n",
            "batch: 1625 loss: 0.2041685594683513\n",
            "batch: 1626 loss: 0.20417872485797853\n",
            "batch: 1627 loss: 0.20422779888939113\n",
            "batch: 1628 loss: 0.20438517270516604\n",
            "batch: 1629 loss: 0.20464618904422968\n",
            "batch: 1630 loss: 0.20477887512277812\n",
            "batch: 1631 loss: 0.20503045506309717\n",
            "batch: 1632 loss: 0.2050769741749391\n",
            "batch: 1633 loss: 0.2051367571009323\n",
            "batch: 1634 loss: 0.20528664586972445\n",
            "batch: 1635 loss: 0.20539528303127735\n",
            "batch: 1636 loss: 0.20550985221844167\n",
            "batch: 1637 loss: 0.20557615438383073\n",
            "batch: 1638 loss: 0.20571682241838427\n",
            "batch: 1639 loss: 0.20572883106395604\n",
            "batch: 1640 loss: 0.20586080140993\n",
            "batch: 1641 loss: 0.20591883137077094\n",
            "batch: 1642 loss: 0.20601310319453478\n",
            "batch: 1643 loss: 0.20603559356555343\n",
            "batch: 1644 loss: 0.20612681962177157\n",
            "batch: 1645 loss: 0.20627873666211963\n",
            "batch: 1646 loss: 0.20632686051353813\n",
            "batch: 1647 loss: 0.20636079822853207\n",
            "batch: 1648 loss: 0.20657488303259014\n",
            "batch: 1649 loss: 0.20662320530414582\n",
            "batch: 1650 loss: 0.20666242888569833\n",
            "batch: 1651 loss: 0.20669738014787437\n",
            "batch: 1652 loss: 0.20683218146115542\n",
            "batch: 1653 loss: 0.20685541941039265\n",
            "batch: 1654 loss: 0.2069129751417786\n",
            "batch: 1655 loss: 0.20693255274929107\n",
            "batch: 1656 loss: 0.20712481752969325\n",
            "batch: 1657 loss: 0.2071728439386934\n",
            "batch: 1658 loss: 0.20729266504757107\n",
            "batch: 1659 loss: 0.2075382794868201\n",
            "batch: 1660 loss: 0.20785988767258823\n",
            "batch: 1661 loss: 0.20798199291341007\n",
            "batch: 1662 loss: 0.20798816638765857\n",
            "batch: 1663 loss: 0.20800882027624176\n",
            "batch: 1664 loss: 0.20803066297387704\n",
            "batch: 1665 loss: 0.20809247821336613\n",
            "batch: 1666 loss: 0.20811255459999667\n",
            "batch: 1667 loss: 0.20812187620578335\n",
            "batch: 1668 loss: 0.20819299589423462\n",
            "batch: 1669 loss: 0.2084124549808912\n",
            "batch: 1670 loss: 0.20844117478607221\n",
            "batch: 1671 loss: 0.20861338910041377\n",
            "batch: 1672 loss: 0.20869828421948478\n",
            "batch: 1673 loss: 0.20877476241765544\n",
            "batch: 1674 loss: 0.2088959229621105\n",
            "batch: 1675 loss: 0.20897011077729985\n",
            "batch: 1676 loss: 0.20913069528667255\n",
            "batch: 1677 loss: 0.2093328761938028\n",
            "batch: 1678 loss: 0.209463659230154\n",
            "batch: 1679 loss: 0.20951683798758314\n",
            "batch: 1680 loss: 0.2096684034052305\n",
            "batch: 1681 loss: 0.21014916412858292\n",
            "batch: 1682 loss: 0.21016161797149108\n",
            "batch: 1683 loss: 0.210191574301105\n",
            "batch: 1684 loss: 0.21023522583348678\n",
            "batch: 1685 loss: 0.21041692843241616\n",
            "batch: 1686 loss: 0.21056557042105123\n",
            "batch: 1687 loss: 0.21065557594550774\n",
            "batch: 1688 loss: 0.21074271155847238\n",
            "batch: 1689 loss: 0.21080279373703525\n",
            "batch: 1690 loss: 0.21082313403626904\n",
            "batch: 1691 loss: 0.21093924021115526\n",
            "batch: 1692 loss: 0.2111040963619016\n",
            "batch: 1693 loss: 0.21111902755266054\n",
            "batch: 1694 loss: 0.21121120604639873\n",
            "batch: 1695 loss: 0.2113790110326372\n",
            "batch: 1696 loss: 0.21145796510344372\n",
            "batch: 1697 loss: 0.2114968714877032\n",
            "batch: 1698 loss: 0.21162045330693946\n",
            "batch: 1699 loss: 0.21175941918184982\n",
            "batch: 1700 loss: 0.2119866747050546\n",
            "batch: 1701 loss: 0.21211274130037056\n",
            "batch: 1702 loss: 0.2121838691025041\n",
            "batch: 1703 loss: 0.21232723411312326\n",
            "batch: 1704 loss: 0.2124306219681166\n",
            "batch: 1705 loss: 0.21252705539902672\n",
            "batch: 1706 loss: 0.21293517084559427\n",
            "batch: 1707 loss: 0.21313203509291634\n",
            "batch: 1708 loss: 0.2132344346283935\n",
            "batch: 1709 loss: 0.21349194287648424\n",
            "batch: 1710 loss: 0.2135063024298288\n",
            "batch: 1711 loss: 0.21352565571898593\n",
            "batch: 1712 loss: 0.2135642931559123\n",
            "batch: 1713 loss: 0.2136324474834837\n",
            "batch: 1714 loss: 0.21375098004424944\n",
            "batch: 1715 loss: 0.2138640160211362\n",
            "batch: 1716 loss: 0.21389496161835267\n",
            "batch: 1717 loss: 0.21390946777304634\n",
            "batch: 1718 loss: 0.2139982313825749\n",
            "batch: 1719 loss: 0.214080962525215\n",
            "batch: 1720 loss: 0.2142539699091576\n",
            "batch: 1721 loss: 0.21427769092237578\n",
            "batch: 1722 loss: 0.21433550689509137\n",
            "batch: 1723 loss: 0.21437241788720712\n",
            "batch: 1724 loss: 0.21442544933175667\n",
            "batch: 1725 loss: 0.21484596981620416\n",
            "batch: 1726 loss: 0.21488715409254655\n",
            "batch: 1727 loss: 0.21503938517486676\n",
            "batch: 1728 loss: 0.2150961302644573\n",
            "batch: 1729 loss: 0.21515620636334643\n",
            "batch: 1730 loss: 0.2153664313494228\n",
            "batch: 1731 loss: 0.21547120206197723\n",
            "batch: 1732 loss: 0.21562083034357055\n",
            "batch: 1733 loss: 0.2160293478234671\n",
            "batch: 1734 loss: 0.21613284583529457\n",
            "batch: 1735 loss: 0.21624408791353927\n",
            "batch: 1736 loss: 0.2163189619719051\n",
            "batch: 1737 loss: 0.21642221805592998\n",
            "batch: 1738 loss: 0.21655049258610234\n",
            "batch: 1739 loss: 0.2167073892368935\n",
            "batch: 1740 loss: 0.21677160477777943\n",
            "batch: 1741 loss: 0.21692870104452594\n",
            "batch: 1742 loss: 0.2172344206585549\n",
            "batch: 1743 loss: 0.21725777369132265\n",
            "batch: 1744 loss: 0.2172996470569633\n",
            "batch: 1745 loss: 0.21737780673196538\n",
            "batch: 1746 loss: 0.21739789076661692\n",
            "batch: 1747 loss: 0.217406187471468\n",
            "batch: 1748 loss: 0.21748716899426654\n",
            "batch: 1749 loss: 0.21755197426350786\n",
            "batch: 1750 loss: 0.21756885174149648\n",
            "batch: 1751 loss: 0.2177324873828329\n",
            "batch: 1752 loss: 0.21781162319565192\n",
            "batch: 1753 loss: 0.21788299153232946\n",
            "batch: 1754 loss: 0.21801202670717612\n",
            "batch: 1755 loss: 0.21840833304310217\n",
            "batch: 1756 loss: 0.21851416862988846\n",
            "batch: 1757 loss: 0.21856943070376292\n",
            "batch: 1758 loss: 0.2186692612268962\n",
            "batch: 1759 loss: 0.21869413138041272\n",
            "batch: 1760 loss: 0.2187200092212297\n",
            "batch: 1761 loss: 0.21885626059630886\n",
            "batch: 1762 loss: 0.2189242643848993\n",
            "batch: 1763 loss: 0.21933431692281738\n",
            "batch: 1764 loss: 0.21939495934406295\n",
            "batch: 1765 loss: 0.2194396364078857\n",
            "batch: 1766 loss: 0.2194870234564878\n",
            "batch: 1767 loss: 0.2195528602213599\n",
            "batch: 1768 loss: 0.2195809845351614\n",
            "batch: 1769 loss: 0.21961183187784628\n",
            "batch: 1770 loss: 0.21971568650426343\n",
            "batch: 1771 loss: 0.21972753482172266\n",
            "batch: 1772 loss: 0.22007090633222834\n",
            "batch: 1773 loss: 0.22010016653174536\n",
            "batch: 1774 loss: 0.22013305252278223\n",
            "batch: 1775 loss: 0.22019493860239164\n",
            "batch: 1776 loss: 0.2202569588185288\n",
            "batch: 1777 loss: 0.2203258093581535\n",
            "batch: 1778 loss: 0.22054872055212035\n",
            "batch: 1779 loss: 0.22055959531711414\n",
            "batch: 1780 loss: 0.2207613853518851\n",
            "batch: 1781 loss: 0.22089707207726314\n",
            "batch: 1782 loss: 0.22094494137959556\n",
            "batch: 1783 loss: 0.22099546123715116\n",
            "batch: 1784 loss: 0.22101261559547855\n",
            "batch: 1785 loss: 0.2211093457606621\n",
            "batch: 1786 loss: 0.2211742601436563\n",
            "batch: 1787 loss: 0.22123711809935048\n",
            "batch: 1788 loss: 0.22140987746836618\n",
            "batch: 1789 loss: 0.22146968459011987\n",
            "batch: 1790 loss: 0.22147833959711716\n",
            "batch: 1791 loss: 0.22156491587264462\n",
            "batch: 1792 loss: 0.2217921914528124\n",
            "batch: 1793 loss: 0.2219877263973467\n",
            "batch: 1794 loss: 0.2221136546949856\n",
            "batch: 1795 loss: 0.2221469729389064\n",
            "batch: 1796 loss: 0.22239244091464205\n",
            "batch: 1797 loss: 0.22250694769574328\n",
            "batch: 1798 loss: 0.22255363479210064\n",
            "batch: 1799 loss: 0.22262858354253695\n",
            "batch: 1800 loss: 0.22274131026072427\n",
            "batch: 1801 loss: 0.22300861375732348\n",
            "batch: 1802 loss: 0.2230779796312563\n",
            "batch: 1803 loss: 0.2231164149637334\n",
            "batch: 1804 loss: 0.22319744029594585\n",
            "batch: 1805 loss: 0.22324609231157228\n",
            "batch: 1806 loss: 0.22349084656639023\n",
            "batch: 1807 loss: 0.22351101680798455\n",
            "batch: 1808 loss: 0.22363846277398988\n",
            "batch: 1809 loss: 0.22375266800029203\n",
            "batch: 1810 loss: 0.2237760538100265\n",
            "batch: 1811 loss: 0.22404766061296685\n",
            "batch: 1812 loss: 0.22442459752550348\n",
            "batch: 1813 loss: 0.22451930574467405\n",
            "batch: 1814 loss: 0.22459567006817088\n",
            "batch: 1815 loss: 0.22463453717296944\n",
            "batch: 1816 loss: 0.22481849366193637\n",
            "batch: 1817 loss: 0.22492250218754634\n",
            "batch: 1818 loss: 0.224953642541077\n",
            "batch: 1819 loss: 0.22501011375850066\n",
            "batch: 1820 loss: 0.22509192388271912\n",
            "batch: 1821 loss: 0.22511635860381649\n",
            "batch: 1822 loss: 0.2253721668976359\n",
            "batch: 1823 loss: 0.22538994041783736\n",
            "batch: 1824 loss: 0.22559690327150747\n",
            "batch: 1825 loss: 0.22567597757978364\n",
            "batch: 1826 loss: 0.22568858478358014\n",
            "batch: 1827 loss: 0.22573899401864037\n",
            "batch: 1828 loss: 0.22577659905841574\n",
            "batch: 1829 loss: 0.2258114963970147\n",
            "batch: 1830 loss: 0.22595493668830022\n",
            "batch: 1831 loss: 0.22620769292628393\n",
            "batch: 1832 loss: 0.2262815717062913\n",
            "batch: 1833 loss: 0.2263392334780656\n",
            "batch: 1834 loss: 0.22673582499241457\n",
            "batch: 1835 loss: 0.22676129112532362\n",
            "batch: 1836 loss: 0.2268641644655727\n",
            "batch: 1837 loss: 0.22711767857661472\n",
            "batch: 1838 loss: 0.22735317733278498\n",
            "batch: 1839 loss: 0.22744015702744946\n",
            "batch: 1840 loss: 0.22754926654091104\n",
            "batch: 1841 loss: 0.2277065391629003\n",
            "batch: 1842 loss: 0.22783840229501948\n",
            "batch: 1843 loss: 0.22795081585040317\n",
            "batch: 1844 loss: 0.22801757836481557\n",
            "batch: 1845 loss: 0.22807082250854\n",
            "batch: 1846 loss: 0.2282006994499825\n",
            "batch: 1847 loss: 0.2282142338338308\n",
            "batch: 1848 loss: 0.22830062796501444\n",
            "batch: 1849 loss: 0.228362979024183\n",
            "batch: 1850 loss: 0.22843338911188765\n",
            "batch: 1851 loss: 0.22849004714516924\n",
            "batch: 1852 loss: 0.22864381765155123\n",
            "batch: 1853 loss: 0.22869584922073408\n",
            "batch: 1854 loss: 0.2289221271830611\n",
            "batch: 1855 loss: 0.22895593979535625\n",
            "batch: 1856 loss: 0.22913248657761143\n",
            "batch: 1857 loss: 0.2292169920238666\n",
            "batch: 1858 loss: 0.2294368976089172\n",
            "batch: 1859 loss: 0.22948372479109094\n",
            "batch: 1860 loss: 0.22962412454513834\n",
            "batch: 1861 loss: 0.22979094143537804\n",
            "batch: 1862 loss: 0.2298030773620121\n",
            "batch: 1863 loss: 0.2298340824651532\n",
            "batch: 1864 loss: 0.22991862292168663\n",
            "batch: 1865 loss: 0.2301209457772784\n",
            "batch: 1866 loss: 0.2303267333167605\n",
            "batch: 1867 loss: 0.23047333843586967\n",
            "batch: 1868 loss: 0.230510740514379\n",
            "batch: 1869 loss: 0.23074776342092082\n",
            "batch: 1870 loss: 0.23077886650850996\n",
            "batch: 1871 loss: 0.23096197692444548\n",
            "batch: 1872 loss: 0.23112720636418088\n",
            "batch: 1873 loss: 0.23115659055067225\n",
            "batch: 1874 loss: 0.23133809122396634\n",
            "batch: 1 loss: 0.0002442110329866409\n",
            "batch: 2 loss: 0.0004116501212120056\n",
            "batch: 3 loss: 0.0006082607209682465\n",
            "batch: 4 loss: 0.0008233600556850434\n",
            "batch: 5 loss: 0.0010203866511583328\n",
            "batch: 6 loss: 0.0010985305905342102\n",
            "batch: 7 loss: 0.0011092831417918204\n",
            "batch: 8 loss: 0.001189394675195217\n",
            "batch: 9 loss: 0.0012639135792851448\n",
            "batch: 10 loss: 0.0013223077058792114\n",
            "batch: 11 loss: 0.0013809573948383332\n",
            "batch: 12 loss: 0.001415940947830677\n",
            "batch: 13 loss: 0.0014341102708131076\n",
            "batch: 14 loss: 0.0016327537018805743\n",
            "batch: 15 loss: 0.0017277205903083086\n",
            "batch: 16 loss: 0.0018378951270133256\n",
            "batch: 17 loss: 0.0018791550640016794\n",
            "batch: 18 loss: 0.0019204383585602045\n",
            "batch: 19 loss: 0.002070437440648675\n",
            "batch: 20 loss: 0.002149399431422353\n",
            "batch: 21 loss: 0.002282665627077222\n",
            "batch: 22 loss: 0.0023380185794085262\n",
            "batch: 23 loss: 0.0024488707464188336\n",
            "batch: 24 loss: 0.0024947328772395847\n",
            "batch: 25 loss: 0.002522834399715066\n",
            "batch: 26 loss: 0.0026296039540320633\n",
            "batch: 27 loss: 0.0026508857198059557\n",
            "batch: 28 loss: 0.0026624919399619103\n",
            "batch: 29 loss: 0.002677967536263168\n",
            "batch: 30 loss: 0.002884890812449157\n",
            "batch: 31 loss: 0.002924982785247266\n",
            "batch: 32 loss: 0.0029557899413630365\n",
            "batch: 33 loss: 0.0030490287197753787\n",
            "batch: 34 loss: 0.0032388515127822755\n",
            "batch: 35 loss: 0.0033367688758298756\n",
            "batch: 36 loss: 0.0033505258904770016\n",
            "batch: 37 loss: 0.0034493875103071333\n",
            "batch: 38 loss: 0.0035086925262585284\n",
            "batch: 39 loss: 0.003577909299172461\n",
            "batch: 40 loss: 0.0036173393623903393\n",
            "batch: 41 loss: 0.003637178980745375\n",
            "batch: 42 loss: 0.0037100051203742624\n",
            "batch: 43 loss: 0.003748367109335959\n",
            "batch: 44 loss: 0.0038905207002535463\n",
            "batch: 45 loss: 0.0039874448040500285\n",
            "batch: 46 loss: 0.004038295027799905\n",
            "batch: 47 loss: 0.004144273173995316\n",
            "batch: 48 loss: 0.004165668862871826\n",
            "batch: 49 loss: 0.004272125127725303\n",
            "batch: 50 loss: 0.004405901330523193\n",
            "batch: 51 loss: 0.004419704718515277\n",
            "batch: 52 loss: 0.004468273652717471\n",
            "batch: 53 loss: 0.004479756023734808\n",
            "batch: 54 loss: 0.004543942894786596\n",
            "batch: 55 loss: 0.0046290988363325595\n",
            "batch: 56 loss: 0.00464776998385787\n",
            "batch: 57 loss: 0.0047438210062682624\n",
            "batch: 58 loss: 0.004874173413962126\n",
            "batch: 59 loss: 0.004902583383023739\n",
            "batch: 60 loss: 0.0050781875178217886\n",
            "batch: 61 loss: 0.005204471193253994\n",
            "batch: 62 loss: 0.005400938101112842\n",
            "batch: 63 loss: 0.005457538925111294\n",
            "batch: 64 loss: 0.0054966390468180176\n",
            "batch: 65 loss: 0.005580906335264445\n",
            "batch: 66 loss: 0.005615022707730532\n",
            "batch: 67 loss: 0.00563046720251441\n",
            "batch: 68 loss: 0.0057525854520499705\n",
            "batch: 69 loss: 0.005778564689680934\n",
            "batch: 70 loss: 0.0058215761538594965\n",
            "batch: 71 loss: 0.0059341271575540306\n",
            "batch: 72 loss: 0.006033524570986629\n",
            "batch: 73 loss: 0.006174959136173129\n",
            "batch: 74 loss: 0.006332841200754047\n",
            "batch: 75 loss: 0.00637043303065002\n",
            "batch: 76 loss: 0.006494823096320033\n",
            "batch: 77 loss: 0.006632880030199885\n",
            "batch: 78 loss: 0.006677424306049943\n",
            "batch: 79 loss: 0.006817049289122224\n",
            "batch: 80 loss: 0.006837773760780692\n",
            "batch: 81 loss: 0.00700602880679071\n",
            "batch: 82 loss: 0.0070562458094209435\n",
            "batch: 83 loss: 0.0071725282426923515\n",
            "batch: 84 loss: 0.007247743478044868\n",
            "batch: 85 loss: 0.007311061440035701\n",
            "batch: 86 loss: 0.007326153704896569\n",
            "batch: 87 loss: 0.0073913938049227\n",
            "batch: 88 loss: 0.00745869598723948\n",
            "batch: 89 loss: 0.00749606522358954\n",
            "batch: 90 loss: 0.007500167210120708\n",
            "batch: 91 loss: 0.007635075007099658\n",
            "batch: 92 loss: 0.00792768329801038\n",
            "batch: 93 loss: 0.007957804944831878\n",
            "batch: 94 loss: 0.008071085732895882\n",
            "batch: 95 loss: 0.008261534613091499\n",
            "batch: 96 loss: 0.008305069484282284\n",
            "batch: 97 loss: 0.008351475675124675\n",
            "batch: 98 loss: 0.008401464723516256\n",
            "batch: 99 loss: 0.008416287056636065\n",
            "batch: 100 loss: 0.00850432202918455\n",
            "batch: 101 loss: 0.008679823375772685\n",
            "batch: 102 loss: 0.008874199755024166\n",
            "batch: 103 loss: 0.008896739445161074\n",
            "batch: 104 loss: 0.009076081461738795\n",
            "batch: 105 loss: 0.009143270723056048\n",
            "batch: 106 loss: 0.009412835083436221\n",
            "batch: 107 loss: 0.009653539083432406\n",
            "batch: 108 loss: 0.009972136191558094\n",
            "batch: 109 loss: 0.01005874691111967\n",
            "batch: 110 loss: 0.010089388118591159\n",
            "batch: 111 loss: 0.010274894775357098\n",
            "batch: 112 loss: 0.010310437755193561\n",
            "batch: 113 loss: 0.010325068064499647\n",
            "batch: 114 loss: 0.010539631791878492\n",
            "batch: 115 loss: 0.010609403081703932\n",
            "batch: 116 loss: 0.010647744939196855\n",
            "batch: 117 loss: 0.01071196210430935\n",
            "batch: 118 loss: 0.010898059502709657\n",
            "batch: 119 loss: 0.010952871174085886\n",
            "batch: 120 loss: 0.01097293857904151\n",
            "batch: 121 loss: 0.011011463448870927\n",
            "batch: 122 loss: 0.011044603161979466\n",
            "batch: 123 loss: 0.011077090904582292\n",
            "batch: 124 loss: 0.011224467888940126\n",
            "batch: 125 loss: 0.011383012697566301\n",
            "batch: 126 loss: 0.011391070330049843\n",
            "batch: 127 loss: 0.011409750401508063\n",
            "batch: 128 loss: 0.011648460551630706\n",
            "batch: 129 loss: 0.011735345191787929\n",
            "batch: 130 loss: 0.011783783625345677\n",
            "batch: 131 loss: 0.011957505713682622\n",
            "batch: 132 loss: 0.01199762652395293\n",
            "batch: 133 loss: 0.012342324923258275\n",
            "batch: 134 loss: 0.012418198566418142\n",
            "batch: 135 loss: 0.01245064092380926\n",
            "batch: 136 loss: 0.012611886478494852\n",
            "batch: 137 loss: 0.012617625424172729\n",
            "batch: 138 loss: 0.012646721811499447\n",
            "batch: 139 loss: 0.012733029881026595\n",
            "batch: 140 loss: 0.012796223924960942\n",
            "batch: 141 loss: 0.012842841105069966\n",
            "batch: 142 loss: 0.012939681039657444\n",
            "batch: 143 loss: 0.013001661160495132\n",
            "batch: 144 loss: 0.013093971879687161\n",
            "batch: 145 loss: 0.013169031211640685\n",
            "batch: 146 loss: 0.013214676768984645\n",
            "batch: 147 loss: 0.013279254877474158\n",
            "batch: 148 loss: 0.01346905400743708\n",
            "batch: 149 loss: 0.013488052209373564\n",
            "batch: 150 loss: 0.013513564519118518\n",
            "batch: 151 loss: 0.013657725370954723\n",
            "batch: 152 loss: 0.01371892088232562\n",
            "batch: 153 loss: 0.013754105038475245\n",
            "batch: 154 loss: 0.013810749127995223\n",
            "batch: 155 loss: 0.013959033235441893\n",
            "batch: 156 loss: 0.014006276882719248\n",
            "batch: 157 loss: 0.014118800498079509\n",
            "batch: 158 loss: 0.014185626595746726\n",
            "batch: 159 loss: 0.014303339689504355\n",
            "batch: 160 loss: 0.014331468818243593\n",
            "batch: 161 loss: 0.01445944379037246\n",
            "batch: 162 loss: 0.014486922742333264\n",
            "batch: 163 loss: 0.014496493702288718\n",
            "batch: 164 loss: 0.01450606589904055\n",
            "batch: 165 loss: 0.014615163350012153\n",
            "batch: 166 loss: 0.014669668489601464\n",
            "batch: 167 loss: 0.014726144218351693\n",
            "batch: 168 loss: 0.014840237104799599\n",
            "batch: 169 loss: 0.014894988337066024\n",
            "batch: 170 loss: 0.014972998255398124\n",
            "batch: 171 loss: 0.015067688205745071\n",
            "batch: 172 loss: 0.01531795803597197\n",
            "batch: 173 loss: 0.015361388915684074\n",
            "batch: 174 loss: 0.015375276825856418\n",
            "batch: 175 loss: 0.015479583896230907\n",
            "batch: 176 loss: 0.015490073630120605\n",
            "batch: 177 loss: 0.015522983690258115\n",
            "batch: 178 loss: 0.01570065443729982\n",
            "batch: 179 loss: 0.01572761139040813\n",
            "batch: 180 loss: 0.015750637443270533\n",
            "batch: 181 loss: 0.01580451421579346\n",
            "batch: 182 loss: 0.015905508445110173\n",
            "batch: 183 loss: 0.01593678349768743\n",
            "batch: 184 loss: 0.015984338068868963\n",
            "batch: 185 loss: 0.01616207587113604\n",
            "batch: 186 loss: 0.016187682998832314\n",
            "batch: 187 loss: 0.016203313709702342\n",
            "batch: 188 loss: 0.01622084175189957\n",
            "batch: 189 loss: 0.016288674013223498\n",
            "batch: 190 loss: 0.016382007563021033\n",
            "batch: 191 loss: 0.016454256230499596\n",
            "batch: 192 loss: 0.01656267233332619\n",
            "batch: 193 loss: 0.01684555979212746\n",
            "batch: 194 loss: 0.01702060340484604\n",
            "batch: 195 loss: 0.017055601058062166\n",
            "batch: 196 loss: 0.017184852687176316\n",
            "batch: 197 loss: 0.017215896224137394\n",
            "batch: 198 loss: 0.017283039142843334\n",
            "batch: 199 loss: 0.01739344393229112\n",
            "batch: 200 loss: 0.017467026074882597\n",
            "batch: 201 loss: 0.01763210647320375\n",
            "batch: 202 loss: 0.017929747422691433\n",
            "batch: 203 loss: 0.01810666117584333\n",
            "batch: 204 loss: 0.018172394340392202\n",
            "batch: 205 loss: 0.018198131508659572\n",
            "batch: 206 loss: 0.018257636717986317\n",
            "batch: 207 loss: 0.018282676042523236\n",
            "batch: 208 loss: 0.018343732142355292\n",
            "batch: 209 loss: 0.018414318719413132\n",
            "batch: 210 loss: 0.018663913601543753\n",
            "batch: 211 loss: 0.018671040082816035\n",
            "batch: 212 loss: 0.018690788003150372\n",
            "batch: 213 loss: 0.018703966852743177\n",
            "batch: 214 loss: 0.018856372919399293\n",
            "batch: 215 loss: 0.019146100845653564\n",
            "batch: 216 loss: 0.019404885199386625\n",
            "batch: 217 loss: 0.019519368399400265\n",
            "batch: 218 loss: 0.019540774994064123\n",
            "batch: 219 loss: 0.019560975188855082\n",
            "batch: 220 loss: 0.019635346757713706\n",
            "batch: 221 loss: 0.019739369983319193\n",
            "batch: 222 loss: 0.019930736268404872\n",
            "batch: 223 loss: 0.02009220757568255\n",
            "batch: 224 loss: 0.020115881430450826\n",
            "batch: 225 loss: 0.020154273244086654\n",
            "batch: 226 loss: 0.020336217271629722\n",
            "batch: 227 loss: 0.020340450298506767\n",
            "batch: 228 loss: 0.02036982071818784\n",
            "batch: 229 loss: 0.02050386204244569\n",
            "batch: 230 loss: 0.020539318148512394\n",
            "batch: 231 loss: 0.02056034489395097\n",
            "batch: 232 loss: 0.020747254346031696\n",
            "batch: 233 loss: 0.02084254330070689\n",
            "batch: 234 loss: 0.02090844864072278\n",
            "batch: 235 loss: 0.020945164535660296\n",
            "batch: 236 loss: 0.020961221583653242\n",
            "batch: 237 loss: 0.021017372452188283\n",
            "batch: 238 loss: 0.021052059073466807\n",
            "batch: 239 loss: 0.02108472651662305\n",
            "batch: 240 loss: 0.02112560619832948\n",
            "batch: 241 loss: 0.02121805788995698\n",
            "batch: 242 loss: 0.021291967791039496\n",
            "batch: 243 loss: 0.0213359046545811\n",
            "batch: 244 loss: 0.021388387851882726\n",
            "batch: 245 loss: 0.021426788203883915\n",
            "batch: 246 loss: 0.021429999705636874\n",
            "batch: 247 loss: 0.021465793922776356\n",
            "batch: 248 loss: 0.02148873337940313\n",
            "batch: 249 loss: 0.02150719153159298\n",
            "batch: 250 loss: 0.021687643431359902\n",
            "batch: 251 loss: 0.02170816996716894\n",
            "batch: 252 loss: 0.02173352284380235\n",
            "batch: 253 loss: 0.021760510301450268\n",
            "batch: 254 loss: 0.021787666388088836\n",
            "batch: 255 loss: 0.02183094721310772\n",
            "batch: 256 loss: 0.021855537440860644\n",
            "batch: 257 loss: 0.021892849833006038\n",
            "batch: 258 loss: 0.021936244271928446\n",
            "batch: 259 loss: 0.022025711000198497\n",
            "batch: 260 loss: 0.02205379050434567\n",
            "batch: 261 loss: 0.02206068866350688\n",
            "batch: 262 loss: 0.022142862510168924\n",
            "batch: 263 loss: 0.022166690999874845\n",
            "batch: 264 loss: 0.022248624230036512\n",
            "batch: 265 loss: 0.022276089227059856\n",
            "batch: 266 loss: 0.022327416477957742\n",
            "batch: 267 loss: 0.022350615239003672\n",
            "batch: 268 loss: 0.022579556277254595\n",
            "batch: 269 loss: 0.02258463165932335\n",
            "batch: 270 loss: 0.02268680029385723\n",
            "batch: 271 loss: 0.022814736359054223\n",
            "batch: 272 loss: 0.022873622562969105\n",
            "batch: 273 loss: 0.02306093741604127\n",
            "batch: 274 loss: 0.023083503531524913\n",
            "batch: 275 loss: 0.02316123995394446\n",
            "batch: 276 loss: 0.023210568676004188\n",
            "batch: 277 loss: 0.023237263892078773\n",
            "batch: 278 loss: 0.023566398058319463\n",
            "batch: 279 loss: 0.023635201294207944\n",
            "batch: 280 loss: 0.02375583178200759\n",
            "batch: 281 loss: 0.02382313009002246\n",
            "batch: 282 loss: 0.024027645755792037\n",
            "batch: 283 loss: 0.02407813387014903\n",
            "batch: 284 loss: 0.024093419154407457\n",
            "batch: 285 loss: 0.024171026190044357\n",
            "batch: 286 loss: 0.024304621135117485\n",
            "batch: 287 loss: 0.024409127523424105\n",
            "batch: 288 loss: 0.02443833309900947\n",
            "batch: 289 loss: 0.024452413141028955\n",
            "batch: 290 loss: 0.024512918963329865\n",
            "batch: 291 loss: 0.02461775258858688\n",
            "batch: 292 loss: 0.02463691580039449\n",
            "batch: 293 loss: 0.02467237587017007\n",
            "batch: 294 loss: 0.02467939476319589\n",
            "batch: 295 loss: 0.02473072763928212\n",
            "batch: 296 loss: 0.024739346889080478\n",
            "batch: 297 loss: 0.02479922222835012\n",
            "batch: 298 loss: 0.02480368769285269\n",
            "batch: 299 loss: 0.024866479792864993\n",
            "batch: 300 loss: 0.0249351165976841\n",
            "batch: 301 loss: 0.02495311676268466\n",
            "batch: 302 loss: 0.024975618898170068\n",
            "batch: 303 loss: 0.02498623927612789\n",
            "batch: 304 loss: 0.024994832578347996\n",
            "batch: 305 loss: 0.025036745789693667\n",
            "batch: 306 loss: 0.02504017566679977\n",
            "batch: 307 loss: 0.025205271845450624\n",
            "batch: 308 loss: 0.025232357539003714\n",
            "batch: 309 loss: 0.025269014626508577\n",
            "batch: 310 loss: 0.02531060455716215\n",
            "batch: 311 loss: 0.02538834933913313\n",
            "batch: 312 loss: 0.025557139694457873\n",
            "batch: 313 loss: 0.025666835009818898\n",
            "batch: 314 loss: 0.02573404251760803\n",
            "batch: 315 loss: 0.02597925675637089\n",
            "batch: 316 loss: 0.026110089935129508\n",
            "batch: 317 loss: 0.026125308562768623\n",
            "batch: 318 loss: 0.026185323265148327\n",
            "batch: 319 loss: 0.026228403442306446\n",
            "batch: 320 loss: 0.026272194479359315\n",
            "batch: 321 loss: 0.026420138333691286\n",
            "batch: 322 loss: 0.02643180874059908\n",
            "batch: 323 loss: 0.026495866142911835\n",
            "batch: 324 loss: 0.026627630435628817\n",
            "batch: 325 loss: 0.026670215801103042\n",
            "batch: 326 loss: 0.026696432017488406\n",
            "batch: 327 loss: 0.026737201236886905\n",
            "batch: 328 loss: 0.026827965193195268\n",
            "batch: 329 loss: 0.026889881022972986\n",
            "batch: 330 loss: 0.02690171141247265\n",
            "batch: 331 loss: 0.02696762877772562\n",
            "batch: 332 loss: 0.027062041223747654\n",
            "batch: 333 loss: 0.027103912220103665\n",
            "batch: 334 loss: 0.027135640882654116\n",
            "batch: 335 loss: 0.027175362669629975\n",
            "batch: 336 loss: 0.027252790436847134\n",
            "batch: 337 loss: 0.02727861704188399\n",
            "batch: 338 loss: 0.027337842202512546\n",
            "batch: 339 loss: 0.02746601154538803\n",
            "batch: 340 loss: 0.027503883233992384\n",
            "batch: 341 loss: 0.027556871670065448\n",
            "batch: 342 loss: 0.027572403844213115\n",
            "batch: 343 loss: 0.02766347562870942\n",
            "batch: 344 loss: 0.027709145210450516\n",
            "batch: 345 loss: 0.027755068201338873\n",
            "batch: 346 loss: 0.02776236016745679\n",
            "batch: 347 loss: 0.027808355525834487\n",
            "batch: 348 loss: 0.027826807000441475\n",
            "batch: 349 loss: 0.027835574217839165\n",
            "batch: 350 loss: 0.02784141834056936\n",
            "batch: 351 loss: 0.028001344606047498\n",
            "batch: 352 loss: 0.02823994021094404\n",
            "batch: 353 loss: 0.028273945849156008\n",
            "batch: 354 loss: 0.028328903071349488\n",
            "batch: 355 loss: 0.028414445735281332\n",
            "batch: 356 loss: 0.028433396314969286\n",
            "batch: 357 loss: 0.02851394667266868\n",
            "batch: 358 loss: 0.02853972306079231\n",
            "batch: 359 loss: 0.0285704586149659\n",
            "batch: 360 loss: 0.028667801158269866\n",
            "batch: 361 loss: 0.028881171779474243\n",
            "batch: 362 loss: 0.028910747170215474\n",
            "batch: 363 loss: 0.02898741201288067\n",
            "batch: 364 loss: 0.029029739934718236\n",
            "batch: 365 loss: 0.029187210459029302\n",
            "batch: 366 loss: 0.029230615604436024\n",
            "batch: 367 loss: 0.029352511305129156\n",
            "batch: 368 loss: 0.02948533024243079\n",
            "batch: 369 loss: 0.02950217305473052\n",
            "batch: 370 loss: 0.029614362213527784\n",
            "batch: 371 loss: 0.02966978671750985\n",
            "batch: 372 loss: 0.029746358338510616\n",
            "batch: 373 loss: 0.029814180489396675\n",
            "batch: 374 loss: 0.03002113312087022\n",
            "batch: 375 loss: 0.03002646354190074\n",
            "batch: 376 loss: 0.030108114782487972\n",
            "batch: 377 loss: 0.030142044592415915\n",
            "batch: 378 loss: 0.030169807977741585\n",
            "batch: 379 loss: 0.030242806441849096\n",
            "batch: 380 loss: 0.03025811312883161\n",
            "batch: 381 loss: 0.03065606222837232\n",
            "batch: 382 loss: 0.03067045642132871\n",
            "batch: 383 loss: 0.030758426156593487\n",
            "batch: 384 loss: 0.030851377603365107\n",
            "batch: 385 loss: 0.03087524260650389\n",
            "batch: 386 loss: 0.03090829670499079\n",
            "batch: 387 loss: 0.031137021691305562\n",
            "batch: 388 loss: 0.03143305337498896\n",
            "batch: 389 loss: 0.03147367327730172\n",
            "batch: 390 loss: 0.03159468960086815\n",
            "batch: 391 loss: 0.03174742908100597\n",
            "batch: 392 loss: 0.03176844289782457\n",
            "batch: 393 loss: 0.031863011120585726\n",
            "batch: 394 loss: 0.03193787746760063\n",
            "batch: 395 loss: 0.03200498169544153\n",
            "batch: 396 loss: 0.032040815687505525\n",
            "batch: 397 loss: 0.03206069042417221\n",
            "batch: 398 loss: 0.03210172445210628\n",
            "batch: 399 loss: 0.032165650016395375\n",
            "batch: 400 loss: 0.03224952535959892\n",
            "batch: 401 loss: 0.032277611800236625\n",
            "batch: 402 loss: 0.032314875908894466\n",
            "batch: 403 loss: 0.03233148097875528\n",
            "batch: 404 loss: 0.03245663586142473\n",
            "batch: 405 loss: 0.03248422495345585\n",
            "batch: 406 loss: 0.03267254062811844\n",
            "batch: 407 loss: 0.03267736885673366\n",
            "batch: 408 loss: 0.03289179632789455\n",
            "batch: 409 loss: 0.0331073203755077\n",
            "batch: 410 loss: 0.03313453508890234\n",
            "batch: 411 loss: 0.03330144067085348\n",
            "batch: 412 loss: 0.033322328448062766\n",
            "batch: 413 loss: 0.033502767607336864\n",
            "batch: 414 loss: 0.033652548908954485\n",
            "batch: 415 loss: 0.03369689726806246\n",
            "batch: 416 loss: 0.03378370567387901\n",
            "batch: 417 loss: 0.03386962529248558\n",
            "batch: 418 loss: 0.03388561285263859\n",
            "batch: 419 loss: 0.03389427013951354\n",
            "batch: 420 loss: 0.0339539631146472\n",
            "batch: 421 loss: 0.034001852753339334\n",
            "batch: 422 loss: 0.034052029910264535\n",
            "batch: 423 loss: 0.034065643284237015\n",
            "batch: 424 loss: 0.034076348648173736\n",
            "batch: 425 loss: 0.03409615277010016\n",
            "batch: 426 loss: 0.034126947053475305\n",
            "batch: 427 loss: 0.03418806744436734\n",
            "batch: 428 loss: 0.03424353639106266\n",
            "batch: 429 loss: 0.034288040005369114\n",
            "batch: 430 loss: 0.034316693329019474\n",
            "batch: 431 loss: 0.03434164508688264\n",
            "batch: 432 loss: 0.034350391324376686\n",
            "batch: 433 loss: 0.03441968258074485\n",
            "batch: 434 loss: 0.03451780443242751\n",
            "batch: 435 loss: 0.034629779468989\n",
            "batch: 436 loss: 0.034795523714041335\n",
            "batch: 437 loss: 0.03498562149307691\n",
            "batch: 438 loss: 0.03511831785342656\n",
            "batch: 439 loss: 0.03534575643739663\n",
            "batch: 440 loss: 0.035466667983448136\n",
            "batch: 441 loss: 0.03561713700345717\n",
            "batch: 442 loss: 0.035763573411619294\n",
            "batch: 443 loss: 0.0357810986971017\n",
            "batch: 444 loss: 0.035822131488239393\n",
            "batch: 445 loss: 0.03588951184949837\n",
            "batch: 446 loss: 0.03591871086671017\n",
            "batch: 447 loss: 0.03596337375207804\n",
            "batch: 448 loss: 0.036100176544627174\n",
            "batch: 449 loss: 0.036245288224657994\n",
            "batch: 450 loss: 0.03636839867546223\n",
            "batch: 451 loss: 0.03639717446430586\n",
            "batch: 452 loss: 0.03646953393681906\n",
            "batch: 453 loss: 0.03650386965437792\n",
            "batch: 454 loss: 0.03651413488271646\n",
            "batch: 455 loss: 0.03653934443811886\n",
            "batch: 456 loss: 0.036656428173882885\n",
            "batch: 457 loss: 0.03672299670497887\n",
            "batch: 458 loss: 0.036732733116252345\n",
            "batch: 459 loss: 0.03680070115695708\n",
            "batch: 460 loss: 0.036808057937538254\n",
            "batch: 461 loss: 0.036828474573558194\n",
            "batch: 462 loss: 0.03692769455141388\n",
            "batch: 463 loss: 0.03698068965203129\n",
            "batch: 464 loss: 0.037030857261037456\n",
            "batch: 465 loss: 0.03706406595162116\n",
            "batch: 466 loss: 0.03706954095303081\n",
            "batch: 467 loss: 0.03722917511104606\n",
            "batch: 468 loss: 0.03723778350721113\n",
            "batch: 469 loss: 0.037328169890446586\n",
            "batch: 470 loss: 0.0375237168900203\n",
            "batch: 471 loss: 0.037590457134647294\n",
            "batch: 472 loss: 0.03776814924995415\n",
            "batch: 473 loss: 0.0379543094120454\n",
            "batch: 474 loss: 0.0379888078130316\n",
            "batch: 475 loss: 0.038022483837557956\n",
            "batch: 476 loss: 0.03808181281085126\n",
            "batch: 477 loss: 0.0380856046131812\n",
            "batch: 478 loss: 0.038103710686322304\n",
            "batch: 479 loss: 0.038218791989143935\n",
            "batch: 480 loss: 0.03824024357041344\n",
            "batch: 481 loss: 0.03827824340900406\n",
            "batch: 482 loss: 0.03829138272209093\n",
            "batch: 483 loss: 0.038312628466170284\n",
            "batch: 484 loss: 0.03837819475261495\n",
            "batch: 485 loss: 0.03838707380881533\n",
            "batch: 486 loss: 0.038598694512154905\n",
            "batch: 487 loss: 0.03860937469592318\n",
            "batch: 488 loss: 0.038630888262297956\n",
            "batch: 489 loss: 0.03863680235063657\n",
            "batch: 490 loss: 0.03869539956515655\n",
            "batch: 491 loss: 0.03881387211149558\n",
            "batch: 492 loss: 0.03890616306429729\n",
            "batch: 493 loss: 0.03891504804091528\n",
            "batch: 494 loss: 0.03915677846269682\n",
            "batch: 495 loss: 0.0392125371848233\n",
            "batch: 496 loss: 0.03927515680389479\n",
            "batch: 497 loss: 0.03934699622588232\n",
            "batch: 498 loss: 0.039505571090150626\n",
            "batch: 499 loss: 0.03952659651869908\n",
            "batch: 500 loss: 0.03953704788396135\n",
            "batch: 501 loss: 0.039577142080757764\n",
            "batch: 502 loss: 0.039586432844866064\n",
            "batch: 503 loss: 0.039600428075063976\n",
            "batch: 504 loss: 0.039614538543391975\n",
            "batch: 505 loss: 0.03993918665545061\n",
            "batch: 506 loss: 0.03995450227754191\n",
            "batch: 507 loss: 0.03998821494029835\n",
            "batch: 508 loss: 0.04001771976100281\n",
            "batch: 509 loss: 0.04010807901667431\n",
            "batch: 510 loss: 0.040135956503916534\n",
            "batch: 511 loss: 0.04029761665361002\n",
            "batch: 512 loss: 0.04051005695061758\n",
            "batch: 513 loss: 0.040672031917143615\n",
            "batch: 514 loss: 0.040674854402430356\n",
            "batch: 515 loss: 0.04069413082394749\n",
            "batch: 516 loss: 0.04073485748562962\n",
            "batch: 517 loss: 0.04084656144026667\n",
            "batch: 518 loss: 0.04086249879095703\n",
            "batch: 519 loss: 0.040870285616256295\n",
            "batch: 520 loss: 0.04100158625934273\n",
            "batch: 521 loss: 0.041134150029160085\n",
            "batch: 522 loss: 0.041172429000027475\n",
            "batch: 523 loss: 0.041210180011577904\n",
            "batch: 524 loss: 0.04131123096961528\n",
            "batch: 525 loss: 0.041351870045997205\n",
            "batch: 526 loss: 0.04140271141473204\n",
            "batch: 527 loss: 0.041511746683157984\n",
            "batch: 528 loss: 0.041555930205620824\n",
            "batch: 529 loss: 0.041601847314275804\n",
            "batch: 530 loss: 0.04164826962072402\n",
            "batch: 531 loss: 0.04165428207907826\n",
            "batch: 532 loss: 0.04167490455228835\n",
            "batch: 533 loss: 0.04167914924398065\n",
            "batch: 534 loss: 0.04189119501784444\n",
            "batch: 535 loss: 0.04193257492035627\n",
            "batch: 536 loss: 0.04205832063406706\n",
            "batch: 537 loss: 0.042122450694441795\n",
            "batch: 538 loss: 0.04215924888476729\n",
            "batch: 539 loss: 0.042205178420990704\n",
            "batch: 540 loss: 0.04229517643526196\n",
            "batch: 541 loss: 0.04239008517190814\n",
            "batch: 542 loss: 0.0424214883223176\n",
            "batch: 543 loss: 0.0425770917609334\n",
            "batch: 544 loss: 0.042748387940227985\n",
            "batch: 545 loss: 0.04284139437973499\n",
            "batch: 546 loss: 0.04288891330361366\n",
            "batch: 547 loss: 0.04290752563998103\n",
            "batch: 548 loss: 0.042944122634828094\n",
            "batch: 549 loss: 0.04296659468859434\n",
            "batch: 550 loss: 0.04318360579758883\n",
            "batch: 551 loss: 0.04325539160519838\n",
            "batch: 552 loss: 0.043454086877405644\n",
            "batch: 553 loss: 0.043567498527467254\n",
            "batch: 554 loss: 0.043693395130336286\n",
            "batch: 555 loss: 0.043716112231835726\n",
            "batch: 556 loss: 0.0437504800837487\n",
            "batch: 557 loss: 0.043752721338998525\n",
            "batch: 558 loss: 0.043871730744373054\n",
            "batch: 559 loss: 0.04391725620208308\n",
            "batch: 560 loss: 0.043934232770930975\n",
            "batch: 561 loss: 0.04395256770355627\n",
            "batch: 562 loss: 0.044099027551244945\n",
            "batch: 563 loss: 0.04415381447924301\n",
            "batch: 564 loss: 0.04416378027247265\n",
            "batch: 565 loss: 0.044229522526729854\n",
            "batch: 566 loss: 0.04434406077908352\n",
            "batch: 567 loss: 0.0445704330210574\n",
            "batch: 568 loss: 0.04464427999453619\n",
            "batch: 569 loss: 0.04464810405950993\n",
            "batch: 570 loss: 0.04466406422760338\n",
            "batch: 571 loss: 0.04499009945895523\n",
            "batch: 572 loss: 0.045117212398909035\n",
            "batch: 573 loss: 0.04522728559281677\n",
            "batch: 574 loss: 0.04531041985657066\n",
            "batch: 575 loss: 0.04534962208475918\n",
            "batch: 576 loss: 0.04536264692340046\n",
            "batch: 577 loss: 0.045628336087800564\n",
            "batch: 578 loss: 0.04585587868187577\n",
            "batch: 579 loss: 0.04600002670381218\n",
            "batch: 580 loss: 0.04608898911718279\n",
            "batch: 581 loss: 0.04620174092892557\n",
            "batch: 582 loss: 0.046320945628918704\n",
            "batch: 583 loss: 0.046371152666397394\n",
            "batch: 584 loss: 0.04639290544483811\n",
            "batch: 585 loss: 0.04641713645774871\n",
            "batch: 586 loss: 0.04661589924711734\n",
            "batch: 587 loss: 0.04666636801231652\n",
            "batch: 588 loss: 0.04674451929796487\n",
            "batch: 589 loss: 0.046809489612467586\n",
            "batch: 590 loss: 0.047172064875252544\n",
            "batch: 591 loss: 0.047187756177969276\n",
            "batch: 592 loss: 0.04720236043073237\n",
            "batch: 593 loss: 0.047262575013563034\n",
            "batch: 594 loss: 0.047337466491386294\n",
            "batch: 595 loss: 0.04740417919866741\n",
            "batch: 596 loss: 0.047508688865229486\n",
            "batch: 597 loss: 0.04769170187227428\n",
            "batch: 598 loss: 0.04772161580622196\n",
            "batch: 599 loss: 0.047728704761713744\n",
            "batch: 600 loss: 0.04778260323032737\n",
            "batch: 601 loss: 0.047876270059496163\n",
            "batch: 602 loss: 0.04792971778661013\n",
            "batch: 603 loss: 0.04795040757767856\n",
            "batch: 604 loss: 0.04796247700881213\n",
            "batch: 605 loss: 0.047996890659444034\n",
            "batch: 606 loss: 0.04825383200775832\n",
            "batch: 607 loss: 0.04826907314080745\n",
            "batch: 608 loss: 0.04828955931309611\n",
            "batch: 609 loss: 0.048343852591700855\n",
            "batch: 610 loss: 0.04836168735194951\n",
            "batch: 611 loss: 0.04845010078419\n",
            "batch: 612 loss: 0.04848931003082543\n",
            "batch: 613 loss: 0.0486387514071539\n",
            "batch: 614 loss: 0.04875225951243192\n",
            "batch: 615 loss: 0.049083687980659305\n",
            "batch: 616 loss: 0.04925984371174127\n",
            "batch: 617 loss: 0.04931195483077318\n",
            "batch: 618 loss: 0.04935775784123689\n",
            "batch: 619 loss: 0.049415177767165\n",
            "batch: 620 loss: 0.049604912643320856\n",
            "batch: 621 loss: 0.049712415073998276\n",
            "batch: 622 loss: 0.049720752145163714\n",
            "batch: 623 loss: 0.049727998107671735\n",
            "batch: 624 loss: 0.04975432158634067\n",
            "batch: 625 loss: 0.04979347829148174\n",
            "batch: 626 loss: 0.0498459578640759\n",
            "batch: 627 loss: 0.04985681849904358\n",
            "batch: 628 loss: 0.04990145943500102\n",
            "batch: 629 loss: 0.049990695359185336\n",
            "batch: 630 loss: 0.05001346289925277\n",
            "batch: 631 loss: 0.05002831082604826\n",
            "batch: 632 loss: 0.0500594660770148\n",
            "batch: 633 loss: 0.05010667040012777\n",
            "batch: 634 loss: 0.05024730943702161\n",
            "batch: 635 loss: 0.05048581441305578\n",
            "batch: 636 loss: 0.05054179160110652\n",
            "batch: 637 loss: 0.05063161399774253\n",
            "batch: 638 loss: 0.05065476276911795\n",
            "batch: 639 loss: 0.0507252328786999\n",
            "batch: 640 loss: 0.05080040376074612\n",
            "batch: 641 loss: 0.0510134568978101\n",
            "batch: 642 loss: 0.05113545793481171\n",
            "batch: 643 loss: 0.051141510056797415\n",
            "batch: 644 loss: 0.05115814176062122\n",
            "batch: 645 loss: 0.05122203966835514\n",
            "batch: 646 loss: 0.051476530759129675\n",
            "batch: 647 loss: 0.05149743480654433\n",
            "batch: 648 loss: 0.05156176831992343\n",
            "batch: 649 loss: 0.0516367667731829\n",
            "batch: 650 loss: 0.05168837980600074\n",
            "batch: 651 loss: 0.051773387279827145\n",
            "batch: 652 loss: 0.0520007877019234\n",
            "batch: 653 loss: 0.05202151403063908\n",
            "batch: 654 loss: 0.05209070017421618\n",
            "batch: 655 loss: 0.052381988967303186\n",
            "batch: 656 loss: 0.052389428045134995\n",
            "batch: 657 loss: 0.05245388501463458\n",
            "batch: 658 loss: 0.05246412523603067\n",
            "batch: 659 loss: 0.05249770708149299\n",
            "batch: 660 loss: 0.05262611582642421\n",
            "batch: 661 loss: 0.052666810171213004\n",
            "batch: 662 loss: 0.052670484343077986\n",
            "batch: 663 loss: 0.05274663853039965\n",
            "batch: 664 loss: 0.05277067830739543\n",
            "batch: 665 loss: 0.05279162056883797\n",
            "batch: 666 loss: 0.05284347022464499\n",
            "batch: 667 loss: 0.0528842435493134\n",
            "batch: 668 loss: 0.05290509200980887\n",
            "batch: 669 loss: 0.052953622763510795\n",
            "batch: 670 loss: 0.05309278086340055\n",
            "batch: 671 loss: 0.053114672790747136\n",
            "batch: 672 loss: 0.05313391658989713\n",
            "batch: 673 loss: 0.05330502462713048\n",
            "batch: 674 loss: 0.053488032791297886\n",
            "batch: 675 loss: 0.05353873470006511\n",
            "batch: 676 loss: 0.05357657555071637\n",
            "batch: 677 loss: 0.05360173662891612\n",
            "batch: 678 loss: 0.05371622469415888\n",
            "batch: 679 loss: 0.05402361368527636\n",
            "batch: 680 loss: 0.054035448640119284\n",
            "batch: 681 loss: 0.05427382625592873\n",
            "batch: 682 loss: 0.054336419567000124\n",
            "batch: 683 loss: 0.05440952244354412\n",
            "batch: 684 loss: 0.05442234509019181\n",
            "batch: 685 loss: 0.05443971717311069\n",
            "batch: 686 loss: 0.054478605988901106\n",
            "batch: 687 loss: 0.054632087889593096\n",
            "batch: 688 loss: 0.05470023519871756\n",
            "batch: 689 loss: 0.0547276379945688\n",
            "batch: 690 loss: 0.054828236396890134\n",
            "batch: 691 loss: 0.054988967116456476\n",
            "batch: 692 loss: 0.05503107477305457\n",
            "batch: 693 loss: 0.05511209163395688\n",
            "batch: 694 loss: 0.05513240654719993\n",
            "batch: 695 loss: 0.05517604151694104\n",
            "batch: 696 loss: 0.055195228069555013\n",
            "batch: 697 loss: 0.055548063963186\n",
            "batch: 698 loss: 0.055638708203565326\n",
            "batch: 699 loss: 0.055753103374969214\n",
            "batch: 700 loss: 0.05579618921829387\n",
            "batch: 701 loss: 0.055835413176100704\n",
            "batch: 702 loss: 0.05586095960764215\n",
            "batch: 703 loss: 0.055940357442479584\n",
            "batch: 704 loss: 0.055957810442429035\n",
            "batch: 705 loss: 0.0559623036426492\n",
            "batch: 706 loss: 0.05596765671344474\n",
            "batch: 707 loss: 0.05600151635752991\n",
            "batch: 708 loss: 0.056008551177568734\n",
            "batch: 709 loss: 0.056020450529642406\n",
            "batch: 710 loss: 0.056097835187800225\n",
            "batch: 711 loss: 0.05618623534310609\n",
            "batch: 712 loss: 0.0562811346994713\n",
            "batch: 713 loss: 0.05631884642038494\n",
            "batch: 714 loss: 0.05633253149781376\n",
            "batch: 715 loss: 0.05650531809125096\n",
            "batch: 716 loss: 0.05659838650468737\n",
            "batch: 717 loss: 0.05664128029439598\n",
            "batch: 718 loss: 0.0566668601995334\n",
            "batch: 719 loss: 0.05699449992831796\n",
            "batch: 720 loss: 0.0571286978488788\n",
            "batch: 721 loss: 0.05720556068327278\n",
            "batch: 722 loss: 0.05727775993105024\n",
            "batch: 723 loss: 0.05751470730360597\n",
            "batch: 724 loss: 0.05754576282110065\n",
            "batch: 725 loss: 0.05783425925578922\n",
            "batch: 726 loss: 0.057983579783700404\n",
            "batch: 727 loss: 0.058004624587483705\n",
            "batch: 728 loss: 0.0581339501561597\n",
            "batch: 729 loss: 0.05814773874357343\n",
            "batch: 730 loss: 0.05848262603953481\n",
            "batch: 731 loss: 0.058548895467072724\n",
            "batch: 732 loss: 0.0586565227471292\n",
            "batch: 733 loss: 0.058698492158204316\n",
            "batch: 734 loss: 0.05872608006745577\n",
            "batch: 735 loss: 0.05907601062208414\n",
            "batch: 736 loss: 0.05921855735033751\n",
            "batch: 737 loss: 0.059345382653176786\n",
            "batch: 738 loss: 0.059437081746757034\n",
            "batch: 739 loss: 0.05945643152669072\n",
            "batch: 740 loss: 0.05950414342060685\n",
            "batch: 741 loss: 0.059566468212753534\n",
            "batch: 742 loss: 0.05963771731033921\n",
            "batch: 743 loss: 0.05979833406582475\n",
            "batch: 744 loss: 0.059833445720374585\n",
            "batch: 745 loss: 0.05984506143070757\n",
            "batch: 746 loss: 0.05994742532260716\n",
            "batch: 747 loss: 0.06003790493495762\n",
            "batch: 748 loss: 0.06027935595996678\n",
            "batch: 749 loss: 0.06030272816680372\n",
            "batch: 750 loss: 0.060336678026244046\n",
            "batch: 751 loss: 0.06058735596947372\n",
            "batch: 752 loss: 0.060619430148974064\n",
            "batch: 753 loss: 0.060790309915319085\n",
            "batch: 754 loss: 0.06086581574566662\n",
            "batch: 755 loss: 0.060891202894970776\n",
            "batch: 756 loss: 0.06095999790541828\n",
            "batch: 757 loss: 0.060980971222743395\n",
            "batch: 758 loss: 0.06100832392461598\n",
            "batch: 759 loss: 0.061050582630559805\n",
            "batch: 760 loss: 0.06139495073072612\n",
            "batch: 761 loss: 0.06146118798665702\n",
            "batch: 762 loss: 0.061543368441984055\n",
            "batch: 763 loss: 0.06166974526457489\n",
            "batch: 764 loss: 0.06171414401568472\n",
            "batch: 765 loss: 0.06176616847328842\n",
            "batch: 766 loss: 0.06188666163943708\n",
            "batch: 767 loss: 0.061914352810010315\n",
            "batch: 768 loss: 0.06212156513892114\n",
            "batch: 769 loss: 0.06213663978967816\n",
            "batch: 770 loss: 0.06230328340921551\n",
            "batch: 771 loss: 0.062322264050133525\n",
            "batch: 772 loss: 0.062414308940060434\n",
            "batch: 773 loss: 0.062477024634368716\n",
            "batch: 774 loss: 0.06249629050586373\n",
            "batch: 775 loss: 0.06254248254094273\n",
            "batch: 776 loss: 0.06275499890837818\n",
            "batch: 777 loss: 0.06282756731752306\n",
            "batch: 778 loss: 0.06284123394452036\n",
            "batch: 779 loss: 0.06299296126328409\n",
            "batch: 780 loss: 0.06327679706178606\n",
            "batch: 781 loss: 0.06329583996720613\n",
            "batch: 782 loss: 0.06330391967389733\n",
            "batch: 783 loss: 0.06332335246820003\n",
            "batch: 784 loss: 0.06353729730565101\n",
            "batch: 785 loss: 0.06357183650601655\n",
            "batch: 786 loss: 0.06366080035734922\n",
            "batch: 787 loss: 0.06369498090166599\n",
            "batch: 788 loss: 0.06392950218636542\n",
            "batch: 789 loss: 0.06410952500719577\n",
            "batch: 790 loss: 0.06412603124696761\n",
            "batch: 791 loss: 0.06420267392415553\n",
            "batch: 792 loss: 0.06422633499000222\n",
            "batch: 793 loss: 0.06446258226130158\n",
            "batch: 794 loss: 0.0645925201633945\n",
            "batch: 795 loss: 0.06461714802030474\n",
            "batch: 796 loss: 0.06467578948754817\n",
            "batch: 797 loss: 0.06474313170928508\n",
            "batch: 798 loss: 0.06476457555312663\n",
            "batch: 799 loss: 0.06480373196769505\n",
            "batch: 800 loss: 0.06485164435673504\n",
            "batch: 801 loss: 0.06486476143170149\n",
            "batch: 802 loss: 0.06492316664848477\n",
            "batch: 803 loss: 0.06502050975803286\n",
            "batch: 804 loss: 0.0651696881884709\n",
            "batch: 805 loss: 0.06532694225851446\n",
            "batch: 806 loss: 0.06534869253728538\n",
            "batch: 807 loss: 0.06559557440970093\n",
            "batch: 808 loss: 0.0658314141491428\n",
            "batch: 809 loss: 0.06584344689268619\n",
            "batch: 810 loss: 0.06593267304915935\n",
            "batch: 811 loss: 0.06624134765285998\n",
            "batch: 812 loss: 0.06637973275501281\n",
            "batch: 813 loss: 0.0665444576414302\n",
            "batch: 814 loss: 0.06672347128111869\n",
            "batch: 815 loss: 0.06687034605164081\n",
            "batch: 816 loss: 0.06691280853468924\n",
            "batch: 817 loss: 0.0669243010468781\n",
            "batch: 818 loss: 0.0672189707942307\n",
            "batch: 819 loss: 0.06725143993273378\n",
            "batch: 820 loss: 0.06744758037105203\n",
            "batch: 821 loss: 0.06771182766929269\n",
            "batch: 822 loss: 0.06781260342523455\n",
            "batch: 823 loss: 0.06809204662963748\n",
            "batch: 824 loss: 0.06813495675846934\n",
            "batch: 825 loss: 0.0681525528356433\n",
            "batch: 826 loss: 0.06817691753990948\n",
            "batch: 827 loss: 0.06838463396020233\n",
            "batch: 828 loss: 0.06844191389344632\n",
            "batch: 829 loss: 0.06845675173215568\n",
            "batch: 830 loss: 0.06848935667984188\n",
            "batch: 831 loss: 0.0685709861498326\n",
            "batch: 832 loss: 0.06868960656039416\n",
            "batch: 833 loss: 0.06870022746920586\n",
            "batch: 834 loss: 0.06876344111561775\n",
            "batch: 835 loss: 0.06883812770992517\n",
            "batch: 836 loss: 0.0688632883373648\n",
            "batch: 837 loss: 0.06889899592660367\n",
            "batch: 838 loss: 0.06906030691228807\n",
            "batch: 839 loss: 0.06911322001181543\n",
            "batch: 840 loss: 0.06918465394340456\n",
            "batch: 841 loss: 0.06921017954871059\n",
            "batch: 842 loss: 0.06923372335731984\n",
            "batch: 843 loss: 0.06941156546771526\n",
            "batch: 844 loss: 0.06948583322763444\n",
            "batch: 845 loss: 0.06958800759911538\n",
            "batch: 846 loss: 0.06964787642285228\n",
            "batch: 847 loss: 0.06991508189961314\n",
            "batch: 848 loss: 0.07010510581359267\n",
            "batch: 849 loss: 0.0701439501196146\n",
            "batch: 850 loss: 0.07025735227763653\n",
            "batch: 851 loss: 0.07028404073789715\n",
            "batch: 852 loss: 0.07032599821314216\n",
            "batch: 853 loss: 0.07036423931270838\n",
            "batch: 854 loss: 0.07044864477962255\n",
            "batch: 855 loss: 0.07049484430253505\n",
            "batch: 856 loss: 0.07050155354570597\n",
            "batch: 857 loss: 0.07073369100224226\n",
            "batch: 858 loss: 0.07082485915254802\n",
            "batch: 859 loss: 0.07086811307352037\n",
            "batch: 860 loss: 0.07102640879433603\n",
            "batch: 861 loss: 0.07103670761082322\n",
            "batch: 862 loss: 0.07109578016493469\n",
            "batch: 863 loss: 0.07111587543506176\n",
            "batch: 864 loss: 0.07126668262202293\n",
            "batch: 865 loss: 0.07145104001183063\n",
            "batch: 866 loss: 0.0715646834941581\n",
            "batch: 867 loss: 0.07169142625946552\n",
            "batch: 868 loss: 0.0718505940856412\n",
            "batch: 869 loss: 0.07204967823345214\n",
            "batch: 870 loss: 0.07210104918945581\n",
            "batch: 871 loss: 0.0721543110916391\n",
            "batch: 872 loss: 0.07217434747237712\n",
            "batch: 873 loss: 0.07224188010860234\n",
            "batch: 874 loss: 0.07227571815717965\n",
            "batch: 875 loss: 0.07241823301184923\n",
            "batch: 876 loss: 0.07243225149530917\n",
            "batch: 877 loss: 0.07248815787304193\n",
            "batch: 878 loss: 0.07267270002234727\n",
            "batch: 879 loss: 0.07269017711747437\n",
            "batch: 880 loss: 0.07272327138949186\n",
            "batch: 881 loss: 0.07273941720370203\n",
            "batch: 882 loss: 0.0728232761034742\n",
            "batch: 883 loss: 0.07283377085719257\n",
            "batch: 884 loss: 0.07297380828950555\n",
            "batch: 885 loss: 0.07317848003003746\n",
            "batch: 886 loss: 0.07330726982746273\n",
            "batch: 887 loss: 0.07349729338381439\n",
            "batch: 888 loss: 0.07361652581486851\n",
            "batch: 889 loss: 0.0737934849569574\n",
            "batch: 890 loss: 0.07395573167596012\n",
            "batch: 891 loss: 0.07415091990027577\n",
            "batch: 892 loss: 0.07426708066556603\n",
            "batch: 893 loss: 0.07438469671551139\n",
            "batch: 894 loss: 0.07444665714446455\n",
            "batch: 895 loss: 0.07446707914490253\n",
            "batch: 896 loss: 0.07465131756383926\n",
            "batch: 897 loss: 0.07475029732007533\n",
            "batch: 898 loss: 0.07487753519136459\n",
            "batch: 899 loss: 0.07491488403547555\n",
            "batch: 900 loss: 0.0751009473549202\n",
            "batch: 901 loss: 0.07514784303028137\n",
            "batch: 902 loss: 0.07527201606053859\n",
            "batch: 903 loss: 0.07528877102676779\n",
            "batch: 904 loss: 0.07558319910708815\n",
            "batch: 905 loss: 0.07564087248686702\n",
            "batch: 906 loss: 0.07565220834780484\n",
            "batch: 907 loss: 0.07571400425303727\n",
            "batch: 908 loss: 0.07578310669679195\n",
            "batch: 909 loss: 0.07585056642908602\n",
            "batch: 910 loss: 0.07593680236209184\n",
            "batch: 911 loss: 0.07597717553842813\n",
            "batch: 912 loss: 0.0763612723397091\n",
            "batch: 913 loss: 0.07636362540815025\n",
            "batch: 914 loss: 0.07645817980263382\n",
            "batch: 915 loss: 0.07651474419701844\n",
            "batch: 916 loss: 0.07657644439581782\n",
            "batch: 917 loss: 0.07663863293174654\n",
            "batch: 918 loss: 0.07669898759666831\n",
            "batch: 919 loss: 0.07678790787700564\n",
            "batch: 920 loss: 0.07697451209370047\n",
            "batch: 921 loss: 0.07699758927617222\n",
            "batch: 922 loss: 0.07705143175739795\n",
            "batch: 923 loss: 0.07705898312153295\n",
            "batch: 924 loss: 0.07708982917713002\n",
            "batch: 925 loss: 0.07711657783063129\n",
            "batch: 926 loss: 0.07717524452926591\n",
            "batch: 927 loss: 0.07720938775734976\n",
            "batch: 928 loss: 0.07732844129996375\n",
            "batch: 929 loss: 0.07736734890611842\n",
            "batch: 930 loss: 0.07757097850413994\n",
            "batch: 931 loss: 0.07775947901280597\n",
            "batch: 932 loss: 0.077922720071394\n",
            "batch: 933 loss: 0.07805575494142249\n",
            "batch: 934 loss: 0.07814859608234838\n",
            "batch: 935 loss: 0.07817042479710654\n",
            "batch: 936 loss: 0.07817679901560769\n",
            "batch: 937 loss: 0.07820361548615619\n",
            "batch: 938 loss: 0.07828080306900666\n",
            "batch: 939 loss: 0.07829094515321776\n",
            "batch: 940 loss: 0.07850513200042769\n",
            "batch: 941 loss: 0.07859920557914302\n",
            "batch: 942 loss: 0.07862909295922145\n",
            "batch: 943 loss: 0.07880689066415653\n",
            "batch: 944 loss: 0.07885252803331241\n",
            "batch: 945 loss: 0.07888940874254331\n",
            "batch: 946 loss: 0.07890120502514765\n",
            "batch: 947 loss: 0.07915141748590394\n",
            "batch: 948 loss: 0.0793131375531666\n",
            "batch: 949 loss: 0.07938831525249407\n",
            "batch: 950 loss: 0.07939334332803265\n",
            "batch: 951 loss: 0.0794522745446302\n",
            "batch: 952 loss: 0.07951454968610779\n",
            "batch: 953 loss: 0.07964482399681583\n",
            "batch: 954 loss: 0.07971963777998463\n",
            "batch: 955 loss: 0.0797286654706113\n",
            "batch: 956 loss: 0.07981201501889154\n",
            "batch: 957 loss: 0.07988326046569273\n",
            "batch: 958 loss: 0.07996594731463119\n",
            "batch: 959 loss: 0.07997329870378599\n",
            "batch: 960 loss: 0.08001384711405263\n",
            "batch: 961 loss: 0.08021984626492486\n",
            "batch: 962 loss: 0.08036339797219262\n",
            "batch: 963 loss: 0.08037427758192643\n",
            "batch: 964 loss: 0.08038373363157734\n",
            "batch: 965 loss: 0.08051289904257283\n",
            "batch: 966 loss: 0.08064995205542072\n",
            "batch: 967 loss: 0.08075885893544182\n",
            "batch: 968 loss: 0.08079216941958293\n",
            "batch: 969 loss: 0.08089199438458308\n",
            "batch: 970 loss: 0.08094354216149077\n",
            "batch: 971 loss: 0.08101036138227209\n",
            "batch: 972 loss: 0.08116036359360441\n",
            "batch: 973 loss: 0.08127148015936837\n",
            "batch: 974 loss: 0.08128429666114971\n",
            "batch: 975 loss: 0.08137397635681555\n",
            "batch: 976 loss: 0.08142864218307659\n",
            "batch: 977 loss: 0.08146507901651785\n",
            "batch: 978 loss: 0.08150425705267117\n",
            "batch: 979 loss: 0.08170654869033024\n",
            "batch: 980 loss: 0.0817732956330292\n",
            "batch: 981 loss: 0.08179738965583966\n",
            "batch: 982 loss: 0.08187191791040822\n",
            "batch: 983 loss: 0.08188720837468282\n",
            "batch: 984 loss: 0.08193500996613876\n",
            "batch: 985 loss: 0.08196492478111758\n",
            "batch: 986 loss: 0.08200807694578544\n",
            "batch: 987 loss: 0.08214885808015242\n",
            "batch: 988 loss: 0.08220190755138174\n",
            "batch: 989 loss: 0.08220862371427938\n",
            "batch: 990 loss: 0.08228997474862262\n",
            "batch: 991 loss: 0.08231897320738062\n",
            "batch: 992 loss: 0.08234583227662369\n",
            "batch: 993 loss: 0.08236501385411248\n",
            "batch: 994 loss: 0.0824511952563189\n",
            "batch: 995 loss: 0.08245476147159934\n",
            "batch: 996 loss: 0.08255194549635053\n",
            "batch: 997 loss: 0.08259443830326199\n",
            "batch: 998 loss: 0.08260409885644912\n",
            "batch: 1000 loss: 0.08273121424019336\n",
            "batch: 1001 loss: 0.0828004736751318\n",
            "batch: 1002 loss: 0.08282718365453183\n",
            "batch: 1003 loss: 0.08293265723250806\n",
            "batch: 1004 loss: 0.08294077230710536\n",
            "batch: 1005 loss: 0.08304647317249328\n",
            "batch: 1006 loss: 0.08313652585912495\n",
            "batch: 1007 loss: 0.08321379206795246\n",
            "batch: 1008 loss: 0.08333785005379468\n",
            "batch: 1009 loss: 0.08339234972838312\n",
            "batch: 1010 loss: 0.08350548356119543\n",
            "batch: 1011 loss: 0.08352551784086973\n",
            "batch: 1012 loss: 0.08365099011827261\n",
            "batch: 1013 loss: 0.08368933939281852\n",
            "batch: 1014 loss: 0.08372978612501174\n",
            "batch: 1015 loss: 0.08396143790800124\n",
            "batch: 1016 loss: 0.08397671422827989\n",
            "batch: 1017 loss: 0.08406480171252043\n",
            "batch: 1018 loss: 0.08412199882883578\n",
            "batch: 1019 loss: 0.08418229623232037\n",
            "batch: 1020 loss: 0.08422675247583539\n",
            "batch: 1021 loss: 0.08451282022986562\n",
            "batch: 1022 loss: 0.08454349149484187\n",
            "batch: 1023 loss: 0.08460948933381587\n",
            "batch: 1024 loss: 0.0846209753518924\n",
            "batch: 1025 loss: 0.08476581644173711\n",
            "batch: 1026 loss: 0.08479934611078352\n",
            "batch: 1027 loss: 0.08493137483950704\n",
            "batch: 1028 loss: 0.08524794312473387\n",
            "batch: 1029 loss: 0.08544207871612161\n",
            "batch: 1030 loss: 0.08545027455314994\n",
            "batch: 1031 loss: 0.08552383409067989\n",
            "batch: 1032 loss: 0.08554621570557355\n",
            "batch: 1033 loss: 0.08556949098594487\n",
            "batch: 1034 loss: 0.08579342109151185\n",
            "batch: 1035 loss: 0.08582794406078756\n",
            "batch: 1036 loss: 0.085901068655774\n",
            "batch: 1037 loss: 0.08601051495783031\n",
            "batch: 1038 loss: 0.08602136955503374\n",
            "batch: 1039 loss: 0.08610293766204268\n",
            "batch: 1040 loss: 0.08624434018973261\n",
            "batch: 1041 loss: 0.08646666527632624\n",
            "batch: 1042 loss: 0.08647597412485629\n",
            "batch: 1043 loss: 0.08660339575726539\n",
            "batch: 1044 loss: 0.0866848928378895\n",
            "batch: 1045 loss: 0.0868528964119032\n",
            "batch: 1046 loss: 0.08690280422661453\n",
            "batch: 1047 loss: 0.08708353605959565\n",
            "batch: 1048 loss: 0.08716293402854353\n",
            "batch: 1049 loss: 0.08724626798275859\n",
            "batch: 1050 loss: 0.08732851995620877\n",
            "batch: 1051 loss: 0.0876062636533752\n",
            "batch: 1052 loss: 0.08763560159038752\n",
            "batch: 1053 loss: 0.08778898499440402\n",
            "batch: 1054 loss: 0.08783585373591632\n",
            "batch: 1055 loss: 0.08801534573268145\n",
            "batch: 1056 loss: 0.08807114661019295\n",
            "batch: 1057 loss: 0.0882861425159499\n",
            "batch: 1058 loss: 0.08833015102054924\n",
            "batch: 1059 loss: 0.08841121826972813\n",
            "batch: 1060 loss: 0.08844997145142407\n",
            "batch: 1061 loss: 0.08858416722621769\n",
            "batch: 1062 loss: 0.08877037934865803\n",
            "batch: 1063 loss: 0.08877588462503627\n",
            "batch: 1064 loss: 0.08879498562822119\n",
            "batch: 1065 loss: 0.08882252922886982\n",
            "batch: 1066 loss: 0.0888472891044803\n",
            "batch: 1067 loss: 0.08885547642363235\n",
            "batch: 1068 loss: 0.0889383414532058\n",
            "batch: 1069 loss: 0.08903936424059794\n",
            "batch: 1070 loss: 0.08907475651381537\n",
            "batch: 1071 loss: 0.08919825058756396\n",
            "batch: 1072 loss: 0.08921164401853457\n",
            "batch: 1073 loss: 0.08922884263331071\n",
            "batch: 1074 loss: 0.08951857076818123\n",
            "batch: 1075 loss: 0.08954384583840147\n",
            "batch: 1076 loss: 0.0896027889274992\n",
            "batch: 1077 loss: 0.08965058610076085\n",
            "batch: 1078 loss: 0.08968394350493326\n",
            "batch: 1079 loss: 0.0897033709329553\n",
            "batch: 1080 loss: 0.08977865182282403\n",
            "batch: 1081 loss: 0.08978816571319476\n",
            "batch: 1082 loss: 0.08994088653707877\n",
            "batch: 1083 loss: 0.0899807869666256\n",
            "batch: 1084 loss: 0.09004608343029395\n",
            "batch: 1085 loss: 0.09044652501726523\n",
            "batch: 1086 loss: 0.0905226808139123\n",
            "batch: 1087 loss: 0.09057255529845133\n",
            "batch: 1088 loss: 0.09061603547120467\n",
            "batch: 1089 loss: 0.09083468399429694\n",
            "batch: 1090 loss: 0.09092480877274647\n",
            "batch: 1091 loss: 0.09100353387976065\n",
            "batch: 1092 loss: 0.09103455082932486\n",
            "batch: 1093 loss: 0.09107422714540735\n",
            "batch: 1094 loss: 0.09112323765316978\n",
            "batch: 1095 loss: 0.09124933710554614\n",
            "batch: 1096 loss: 0.09126477699866518\n",
            "batch: 1097 loss: 0.09126918747276068\n",
            "batch: 1098 loss: 0.09129749819450081\n",
            "batch: 1099 loss: 0.09137861747853458\n",
            "batch: 1100 loss: 0.09141109119541943\n",
            "batch: 1101 loss: 0.09159089829213918\n",
            "batch: 1102 loss: 0.09161373741738499\n",
            "batch: 1103 loss: 0.0918250158559531\n",
            "batch: 1104 loss: 0.09190196124278009\n",
            "batch: 1105 loss: 0.09200241430662573\n",
            "batch: 1106 loss: 0.09220945242606103\n",
            "batch: 1107 loss: 0.09236379090510309\n",
            "batch: 1108 loss: 0.09238077128492296\n",
            "batch: 1109 loss: 0.0923930755732581\n",
            "batch: 1110 loss: 0.09254297048132866\n",
            "batch: 1111 loss: 0.09286907401960343\n",
            "batch: 1112 loss: 0.09288237889111042\n",
            "batch: 1113 loss: 0.09297393740713597\n",
            "batch: 1114 loss: 0.0930476358756423\n",
            "batch: 1115 loss: 0.09318436392396688\n",
            "batch: 1116 loss: 0.09320018470846117\n",
            "batch: 1117 loss: 0.09339212140999735\n",
            "batch: 1118 loss: 0.09340122529491782\n",
            "batch: 1119 loss: 0.0934534733593464\n",
            "batch: 1120 loss: 0.09346651108842344\n",
            "batch: 1121 loss: 0.09351939554791898\n",
            "batch: 1122 loss: 0.09367475147824735\n",
            "batch: 1123 loss: 0.09369886491354555\n",
            "batch: 1124 loss: 0.09394741370435804\n",
            "batch: 1125 loss: 0.09428676815982907\n",
            "batch: 1126 loss: 0.09433875019755214\n",
            "batch: 1127 loss: 0.09435272453073412\n",
            "batch: 1128 loss: 0.0944991349959746\n",
            "batch: 1129 loss: 0.09451072833221406\n",
            "batch: 1130 loss: 0.09451621996704489\n",
            "batch: 1131 loss: 0.09455355572048575\n",
            "batch: 1132 loss: 0.09467710167262704\n",
            "batch: 1133 loss: 0.09471755556482822\n",
            "batch: 1134 loss: 0.09478983901906758\n",
            "batch: 1135 loss: 0.09483001133892685\n",
            "batch: 1136 loss: 0.09486202099639922\n",
            "batch: 1137 loss: 0.09489841100666672\n",
            "batch: 1138 loss: 0.09496737648639828\n",
            "batch: 1139 loss: 0.09517259927187115\n",
            "batch: 1140 loss: 0.09536574010644108\n",
            "batch: 1141 loss: 0.09551062348578125\n",
            "batch: 1142 loss: 0.09552850562613457\n",
            "batch: 1143 loss: 0.0957225564001128\n",
            "batch: 1144 loss: 0.09573263601306826\n",
            "batch: 1145 loss: 0.09586323476675898\n",
            "batch: 1146 loss: 0.09598042842838914\n",
            "batch: 1147 loss: 0.09605725072417408\n",
            "batch: 1148 loss: 0.09609701916668564\n",
            "batch: 1149 loss: 0.09624690164718777\n",
            "batch: 1150 loss: 0.09632431778404861\n",
            "batch: 1151 loss: 0.0963324440047145\n",
            "batch: 1152 loss: 0.09645193079859019\n",
            "batch: 1153 loss: 0.0966181005910039\n",
            "batch: 1154 loss: 0.09664705567061901\n",
            "batch: 1155 loss: 0.09676277148723603\n",
            "batch: 1156 loss: 0.09686447825282812\n",
            "batch: 1157 loss: 0.09687792378477753\n",
            "batch: 1158 loss: 0.09705004344694317\n",
            "batch: 1159 loss: 0.097339044643566\n",
            "batch: 1160 loss: 0.09758315135352313\n",
            "batch: 1161 loss: 0.09766098594479262\n",
            "batch: 1162 loss: 0.09771184807084501\n",
            "batch: 1163 loss: 0.09779134088568389\n",
            "batch: 1164 loss: 0.0979754641931504\n",
            "batch: 1165 loss: 0.0980417216848582\n",
            "batch: 1166 loss: 0.09819881947152316\n",
            "batch: 1167 loss: 0.09843596857599914\n",
            "batch: 1168 loss: 0.09850943551771343\n",
            "batch: 1169 loss: 0.09855725107900798\n",
            "batch: 1170 loss: 0.09862712868861855\n",
            "batch: 1171 loss: 0.09867856830917299\n",
            "batch: 1172 loss: 0.09869628912955522\n",
            "batch: 1173 loss: 0.09888582334667444\n",
            "batch: 1174 loss: 0.09906636118143797\n",
            "batch: 1175 loss: 0.09910870252922177\n",
            "batch: 1176 loss: 0.09924644801393151\n",
            "batch: 1177 loss: 0.09963794389739633\n",
            "batch: 1178 loss: 0.09984770003333687\n",
            "batch: 1179 loss: 0.09986352889984847\n",
            "batch: 1180 loss: 0.0999131413474679\n",
            "batch: 1181 loss: 0.09995846512913704\n",
            "batch: 1182 loss: 0.10008030009269714\n",
            "batch: 1183 loss: 0.10008943143486977\n",
            "batch: 1184 loss: 0.10014141011238098\n",
            "batch: 1185 loss: 0.10033726158738136\n",
            "batch: 1186 loss: 0.10042314795404672\n",
            "batch: 1187 loss: 0.10043984809145332\n",
            "batch: 1188 loss: 0.10058068342134356\n",
            "batch: 1189 loss: 0.10060049737617373\n",
            "batch: 1190 loss: 0.10075112357363104\n",
            "batch: 1191 loss: 0.10084316040948034\n",
            "batch: 1192 loss: 0.10085015028063207\n",
            "batch: 1193 loss: 0.10104871926549822\n",
            "batch: 1194 loss: 0.1010841998429969\n",
            "batch: 1195 loss: 0.10112651726324111\n",
            "batch: 1196 loss: 0.10117595515493304\n",
            "batch: 1197 loss: 0.1011791065512225\n",
            "batch: 1198 loss: 0.10122070176433771\n",
            "batch: 1199 loss: 0.10124039382580667\n",
            "batch: 1200 loss: 0.10138218722585589\n",
            "batch: 1201 loss: 0.10139785685297102\n",
            "batch: 1202 loss: 0.10143244442623109\n",
            "batch: 1203 loss: 0.10150565193872899\n",
            "batch: 1204 loss: 0.10158922350686043\n",
            "batch: 1205 loss: 0.101616898576729\n",
            "batch: 1206 loss: 0.10170199910085648\n",
            "batch: 1207 loss: 0.10171719787735492\n",
            "batch: 1208 loss: 0.10173875943291932\n",
            "batch: 1209 loss: 0.10181020264793188\n",
            "batch: 1210 loss: 0.10198633215297014\n",
            "batch: 1211 loss: 0.10199419836234301\n",
            "batch: 1212 loss: 0.1020304835466668\n",
            "batch: 1213 loss: 0.10204510641377419\n",
            "batch: 1214 loss: 0.10216648322623223\n",
            "batch: 1215 loss: 0.10220298381801694\n",
            "batch: 1216 loss: 0.10231029499974102\n",
            "batch: 1217 loss: 0.10233042741846293\n",
            "batch: 1218 loss: 0.10249322394561022\n",
            "batch: 1219 loss: 0.10257497885357589\n",
            "batch: 1220 loss: 0.10262651253771037\n",
            "batch: 1221 loss: 0.10265291558485479\n",
            "batch: 1222 loss: 0.10274386428575963\n",
            "batch: 1223 loss: 0.10289332990627736\n",
            "batch: 1224 loss: 0.10290995380003005\n",
            "batch: 1225 loss: 0.10300275668222457\n",
            "batch: 1226 loss: 0.10301601194962859\n",
            "batch: 1227 loss: 0.10305526497215033\n",
            "batch: 1228 loss: 0.10307327678613365\n",
            "batch: 1229 loss: 0.10312390204705298\n",
            "batch: 1230 loss: 0.1031339394627139\n",
            "batch: 1231 loss: 0.10315729265939444\n",
            "batch: 1232 loss: 0.10321279645245522\n",
            "batch: 1233 loss: 0.10322288381215185\n",
            "batch: 1234 loss: 0.10332448671665043\n",
            "batch: 1235 loss: 0.1033828909760341\n",
            "batch: 1236 loss: 0.10344214856531471\n",
            "batch: 1237 loss: 0.10348849033471197\n",
            "batch: 1238 loss: 0.10350038569513709\n",
            "batch: 1239 loss: 0.1035496254907921\n",
            "batch: 1240 loss: 0.10361902521271259\n",
            "batch: 1241 loss: 0.10363831053767353\n",
            "batch: 1242 loss: 0.10386105424258858\n",
            "batch: 1243 loss: 0.10395258594397455\n",
            "batch: 1244 loss: 0.1040117153832689\n",
            "batch: 1245 loss: 0.10408489707205444\n",
            "batch: 1246 loss: 0.1041844220245257\n",
            "batch: 1247 loss: 0.1042967020953074\n",
            "batch: 1248 loss: 0.1043632864812389\n",
            "batch: 1249 loss: 0.10440082219708711\n",
            "batch: 1250 loss: 0.10442957994807511\n",
            "batch: 1251 loss: 0.10456610516179353\n",
            "batch: 1252 loss: 0.10462118771765382\n",
            "batch: 1253 loss: 0.1046642188699916\n",
            "batch: 1254 loss: 0.10472481757868081\n",
            "batch: 1255 loss: 0.10478915537614375\n",
            "batch: 1256 loss: 0.10481082265172154\n",
            "batch: 1257 loss: 0.10485855511296541\n",
            "batch: 1258 loss: 0.10488379721250385\n",
            "batch: 1259 loss: 0.10488876673951746\n",
            "batch: 1260 loss: 0.10498341243341565\n",
            "batch: 1261 loss: 0.10499234473425895\n",
            "batch: 1262 loss: 0.10500123094208538\n",
            "batch: 1263 loss: 0.10514874230511487\n",
            "batch: 1264 loss: 0.10515922485943884\n",
            "batch: 1265 loss: 0.10520229454617948\n",
            "batch: 1266 loss: 0.10522621658165007\n",
            "batch: 1267 loss: 0.10533678480703383\n",
            "batch: 1268 loss: 0.10547680099029094\n",
            "batch: 1269 loss: 0.10549848345015198\n",
            "batch: 1270 loss: 0.10571402165386826\n",
            "batch: 1271 loss: 0.10571860057953746\n",
            "batch: 1272 loss: 0.10576464323792606\n",
            "batch: 1273 loss: 0.10584207974467427\n",
            "batch: 1274 loss: 0.10590494011435658\n",
            "batch: 1275 loss: 0.1060491818645969\n",
            "batch: 1276 loss: 0.10607398779969662\n",
            "batch: 1277 loss: 0.10612695502024144\n",
            "batch: 1278 loss: 0.10615016130637378\n",
            "batch: 1279 loss: 0.10616466555185616\n",
            "batch: 1280 loss: 0.10621017058379949\n",
            "batch: 1281 loss: 0.10638298322446645\n",
            "batch: 1282 loss: 0.10639572572521866\n",
            "batch: 1283 loss: 0.10641476705484092\n",
            "batch: 1284 loss: 0.10642893916927278\n",
            "batch: 1285 loss: 0.10648261651210487\n",
            "batch: 1286 loss: 0.10668012064509094\n",
            "batch: 1287 loss: 0.10670315889641642\n",
            "batch: 1288 loss: 0.10673102394863963\n",
            "batch: 1289 loss: 0.10701899371668697\n",
            "batch: 1290 loss: 0.10706072426214815\n",
            "batch: 1291 loss: 0.10706799752218649\n",
            "batch: 1292 loss: 0.10713487539393828\n",
            "batch: 1293 loss: 0.10727121754689142\n",
            "batch: 1294 loss: 0.10732449967740104\n",
            "batch: 1295 loss: 0.10756290652928874\n",
            "batch: 1296 loss: 0.10757710913522169\n",
            "batch: 1297 loss: 0.10766684006853029\n",
            "batch: 1298 loss: 0.10787768029375001\n",
            "batch: 1299 loss: 0.10789675933448598\n",
            "batch: 1300 loss: 0.10790290178125725\n",
            "batch: 1301 loss: 0.10795264271413907\n",
            "batch: 1302 loss: 0.10800597625738009\n",
            "batch: 1303 loss: 0.10802117760153487\n",
            "batch: 1304 loss: 0.10807208925532177\n",
            "batch: 1305 loss: 0.1082742795352824\n",
            "batch: 1306 loss: 0.10840978470491246\n",
            "batch: 1307 loss: 0.10858902695821598\n",
            "batch: 1308 loss: 0.10862620588066056\n",
            "batch: 1309 loss: 0.10892186321737245\n",
            "batch: 1310 loss: 0.10892655769130215\n",
            "batch: 1311 loss: 0.10896058844169602\n",
            "batch: 1312 loss: 0.10912662182888017\n",
            "batch: 1313 loss: 0.10914039359567687\n",
            "batch: 1314 loss: 0.10915827215788886\n",
            "batch: 1315 loss: 0.10916764126578346\n",
            "batch: 1316 loss: 0.10917961952323094\n",
            "batch: 1317 loss: 0.10921011396916583\n",
            "batch: 1318 loss: 0.10940862172516062\n",
            "batch: 1319 loss: 0.1100251558390446\n",
            "batch: 1320 loss: 0.11022007564874366\n",
            "batch: 1321 loss: 0.11026845717476681\n",
            "batch: 1322 loss: 0.11029596833745017\n",
            "batch: 1323 loss: 0.11030893890978768\n",
            "batch: 1324 loss: 0.1103885614243336\n",
            "batch: 1325 loss: 0.11041881568403915\n",
            "batch: 1326 loss: 0.11048338045598939\n",
            "batch: 1327 loss: 0.11064406109275296\n",
            "batch: 1328 loss: 0.11074983048858121\n",
            "batch: 1329 loss: 0.11076271588588134\n",
            "batch: 1330 loss: 0.11116085560107604\n",
            "batch: 1331 loss: 0.11132347768032923\n",
            "batch: 1332 loss: 0.11137532669166103\n",
            "batch: 1333 loss: 0.11148407328734175\n",
            "batch: 1334 loss: 0.11150565411755815\n",
            "batch: 1335 loss: 0.1115148968663998\n",
            "batch: 1336 loss: 0.11175333924265578\n",
            "batch: 1337 loss: 0.11179151901276782\n",
            "batch: 1338 loss: 0.11185784203978255\n",
            "batch: 1339 loss: 0.1118839994003065\n",
            "batch: 1340 loss: 0.11204602519469335\n",
            "batch: 1341 loss: 0.11209388571279123\n",
            "batch: 1342 loss: 0.11210756265604868\n",
            "batch: 1343 loss: 0.11219126279884949\n",
            "batch: 1344 loss: 0.11221054150396959\n",
            "batch: 1345 loss: 0.11232377992058173\n",
            "batch: 1346 loss: 0.11239937499398366\n",
            "batch: 1347 loss: 0.11243284597853198\n",
            "batch: 1348 loss: 0.11254897489259019\n",
            "batch: 1349 loss: 0.11257311572181061\n",
            "batch: 1350 loss: 0.11260177147807554\n",
            "batch: 1351 loss: 0.11270854153158143\n",
            "batch: 1352 loss: 0.11273191753448919\n",
            "batch: 1353 loss: 0.11291320646228269\n",
            "batch: 1354 loss: 0.11305314210476354\n",
            "batch: 1355 loss: 0.11316935247601942\n",
            "batch: 1356 loss: 0.11318731218622997\n",
            "batch: 1357 loss: 0.11325410248385742\n",
            "batch: 1358 loss: 0.11327338374825194\n",
            "batch: 1359 loss: 0.11332689495803788\n",
            "batch: 1360 loss: 0.11393882842781022\n",
            "batch: 1361 loss: 0.11398110862495378\n",
            "batch: 1362 loss: 0.11404914835514501\n",
            "batch: 1363 loss: 0.11407569664763287\n",
            "batch: 1364 loss: 0.11413408703403548\n",
            "batch: 1365 loss: 0.11419003215478733\n",
            "batch: 1366 loss: 0.11423523723380641\n",
            "batch: 1367 loss: 0.11424896358000114\n",
            "batch: 1368 loss: 0.11426097451196983\n",
            "batch: 1369 loss: 0.11431808977993205\n",
            "batch: 1370 loss: 0.11435164801077917\n",
            "batch: 1371 loss: 0.1144764010538347\n",
            "batch: 1372 loss: 0.11451803593011572\n",
            "batch: 1373 loss: 0.11471470014424995\n",
            "batch: 1374 loss: 0.11473427409725263\n",
            "batch: 1375 loss: 0.11498388155596331\n",
            "batch: 1376 loss: 0.11506294388370589\n",
            "batch: 1377 loss: 0.11513698785053567\n",
            "batch: 1378 loss: 0.11517180287884549\n",
            "batch: 1379 loss: 0.11526105667697266\n",
            "batch: 1380 loss: 0.11527694881381467\n",
            "batch: 1381 loss: 0.11534670323552564\n",
            "batch: 1382 loss: 0.11538423179509118\n",
            "batch: 1383 loss: 0.11546036608191207\n",
            "batch: 1384 loss: 0.11553137680562213\n",
            "batch: 1385 loss: 0.11558953541191294\n",
            "batch: 1386 loss: 0.1156218725447543\n",
            "batch: 1387 loss: 0.11564326365338638\n",
            "batch: 1388 loss: 0.11577112445281819\n",
            "batch: 1389 loss: 0.11580850982340053\n",
            "batch: 1390 loss: 0.11587762772710994\n",
            "batch: 1391 loss: 0.1161496888664551\n",
            "batch: 1392 loss: 0.11644716211827472\n",
            "batch: 1393 loss: 0.11657220972748474\n",
            "batch: 1394 loss: 0.11659339829394594\n",
            "batch: 1395 loss: 0.11665092763165012\n",
            "batch: 1396 loss: 0.1166724245720543\n",
            "batch: 1397 loss: 0.11677539421105758\n",
            "batch: 1398 loss: 0.11682945333654061\n",
            "batch: 1399 loss: 0.11685068677039817\n",
            "batch: 1400 loss: 0.11687369971396401\n",
            "batch: 1401 loss: 0.11687751022190787\n",
            "batch: 1402 loss: 0.11689921603747644\n",
            "batch: 1403 loss: 0.11697749785729684\n",
            "batch: 1404 loss: 0.11722033010073937\n",
            "batch: 1405 loss: 0.11752001331397333\n",
            "batch: 1406 loss: 0.11755801542126573\n",
            "batch: 1407 loss: 0.11775729452096857\n",
            "batch: 1408 loss: 0.11780037960433401\n",
            "batch: 1409 loss: 0.11793208315991796\n",
            "batch: 1410 loss: 0.11804516957723536\n",
            "batch: 1411 loss: 0.11811748905503192\n",
            "batch: 1412 loss: 0.11816920279734767\n",
            "batch: 1413 loss: 0.1181886476802174\n",
            "batch: 1414 loss: 0.11827119698398747\n",
            "batch: 1415 loss: 0.11838704065256753\n",
            "batch: 1416 loss: 0.11843063133605757\n",
            "batch: 1417 loss: 0.1184626315983478\n",
            "batch: 1418 loss: 0.11849357525841334\n",
            "batch: 1419 loss: 0.1185046161285136\n",
            "batch: 1420 loss: 0.11865125277847983\n",
            "batch: 1421 loss: 0.11885384875745512\n",
            "batch: 1422 loss: 0.11887429677904583\n",
            "batch: 1423 loss: 0.11889383530453779\n",
            "batch: 1424 loss: 0.11892245748848654\n",
            "batch: 1425 loss: 0.11907182534248568\n",
            "batch: 1426 loss: 0.11909474986628629\n",
            "batch: 1427 loss: 0.119104553690413\n",
            "batch: 1428 loss: 0.11912634778977371\n",
            "batch: 1429 loss: 0.1192806091106031\n",
            "batch: 1430 loss: 0.11938414833904244\n",
            "batch: 1431 loss: 0.1194437796419952\n",
            "batch: 1432 loss: 0.11953091860772111\n",
            "batch: 1433 loss: 0.11958014177740552\n",
            "batch: 1434 loss: 0.11965770399034954\n",
            "batch: 1435 loss: 0.11969307212741115\n",
            "batch: 1436 loss: 0.11970896340929903\n",
            "batch: 1437 loss: 0.12011398364626802\n",
            "batch: 1438 loss: 0.12015341999032535\n",
            "batch: 1439 loss: 0.12020977498986758\n",
            "batch: 1440 loss: 0.12027970133372583\n",
            "batch: 1441 loss: 0.12035670880624093\n",
            "batch: 1442 loss: 0.12036903471522964\n",
            "batch: 1443 loss: 0.1204621723445598\n",
            "batch: 1444 loss: 0.1204702439114917\n",
            "batch: 1445 loss: 0.12060795576428063\n",
            "batch: 1446 loss: 0.12063798519526608\n",
            "batch: 1447 loss: 0.12095102154766209\n",
            "batch: 1448 loss: 0.12118935615872033\n",
            "batch: 1449 loss: 0.12135480629955418\n",
            "batch: 1450 loss: 0.12136801622179337\n",
            "batch: 1451 loss: 0.12138420463656076\n",
            "batch: 1452 loss: 0.12160167985712178\n",
            "batch: 1453 loss: 0.12182442530547269\n",
            "batch: 1454 loss: 0.12190947375749238\n",
            "batch: 1455 loss: 0.121928374330746\n",
            "batch: 1456 loss: 0.12196867561643011\n",
            "batch: 1457 loss: 0.12202214368362911\n",
            "batch: 1458 loss: 0.12203891675476916\n",
            "batch: 1459 loss: 0.12205208591581322\n",
            "batch: 1460 loss: 0.12205953315622173\n",
            "batch: 1461 loss: 0.12206910067959689\n",
            "batch: 1462 loss: 0.12209122122242115\n",
            "batch: 1463 loss: 0.1222253266365733\n",
            "batch: 1464 loss: 0.12222851016768255\n",
            "batch: 1465 loss: 0.12246076361485757\n",
            "batch: 1466 loss: 0.12262206577905453\n",
            "batch: 1467 loss: 0.12266148115717806\n",
            "batch: 1468 loss: 0.12268253143900074\n",
            "batch: 1469 loss: 0.12274315655254758\n",
            "batch: 1470 loss: 0.12279649035283365\n",
            "batch: 1471 loss: 0.12285122702666558\n",
            "batch: 1472 loss: 0.12290311959036626\n",
            "batch: 1473 loss: 0.12295500889816321\n",
            "batch: 1474 loss: 0.12299697721027769\n",
            "batch: 1475 loss: 0.1230315328577999\n",
            "batch: 1476 loss: 0.12304370872327126\n",
            "batch: 1477 loss: 0.12305366984498688\n",
            "batch: 1478 loss: 0.12309144795802422\n",
            "batch: 1479 loss: 0.12312251781788655\n",
            "batch: 1480 loss: 0.12316915856790729\n",
            "batch: 1481 loss: 0.12322327397507615\n",
            "batch: 1482 loss: 0.1233224305708427\n",
            "batch: 1483 loss: 0.12346102869999595\n",
            "batch: 1484 loss: 0.12347750315186568\n",
            "batch: 1485 loss: 0.12355799771216698\n",
            "batch: 1486 loss: 0.12360422140848823\n",
            "batch: 1487 loss: 0.12369839796912857\n",
            "batch: 1488 loss: 0.1237039008170832\n",
            "batch: 1489 loss: 0.12373950318922289\n",
            "batch: 1490 loss: 0.12382036319305188\n",
            "batch: 1491 loss: 0.12383354461868294\n",
            "batch: 1492 loss: 0.12396096122940072\n",
            "batch: 1493 loss: 0.12402689714659937\n",
            "batch: 1494 loss: 0.12416122676362283\n",
            "batch: 1495 loss: 0.12416611448698676\n",
            "batch: 1496 loss: 0.12424958527856507\n",
            "batch: 1497 loss: 0.12426811311230995\n",
            "batch: 1498 loss: 0.12431749305338599\n",
            "batch: 1499 loss: 0.12434584752493538\n",
            "batch: 1500 loss: 0.12443287991755642\n",
            "batch: 1501 loss: 0.12449308219575324\n",
            "batch: 1502 loss: 0.12455140361958184\n",
            "batch: 1503 loss: 0.12465319144004025\n",
            "batch: 1504 loss: 0.1246695697105024\n",
            "batch: 1505 loss: 0.12468339007464238\n",
            "batch: 1506 loss: 0.12469271800410933\n",
            "batch: 1507 loss: 0.12478377837431617\n",
            "batch: 1508 loss: 0.12503305992973038\n",
            "batch: 1509 loss: 0.12505073221889323\n",
            "batch: 1510 loss: 0.12509926401940175\n",
            "batch: 1511 loss: 0.12510664803092367\n",
            "batch: 1512 loss: 0.1251860623464454\n",
            "batch: 1513 loss: 0.12539107881044037\n",
            "batch: 1514 loss: 0.12558713833545335\n",
            "batch: 1515 loss: 0.1256011137312744\n",
            "batch: 1516 loss: 0.12562119631492533\n",
            "batch: 1517 loss: 0.1259222553523723\n",
            "batch: 1518 loss: 0.12593579001282343\n",
            "batch: 1519 loss: 0.1259454976443667\n",
            "batch: 1520 loss: 0.1260627931926865\n",
            "batch: 1521 loss: 0.1260686794242356\n",
            "batch: 1522 loss: 0.12613709288300015\n",
            "batch: 1523 loss: 0.12630154360295273\n",
            "batch: 1524 loss: 0.12630637696362101\n",
            "batch: 1525 loss: 0.12659620204544625\n",
            "batch: 1526 loss: 0.12660688875964843\n",
            "batch: 1527 loss: 0.12672847758582792\n",
            "batch: 1528 loss: 0.12690102398744785\n",
            "batch: 1529 loss: 0.12718766653886995\n",
            "batch: 1530 loss: 0.1271993885913398\n",
            "batch: 1531 loss: 0.12733075246005318\n",
            "batch: 1532 loss: 0.12739864743291401\n",
            "batch: 1533 loss: 0.12749363780557177\n",
            "batch: 1534 loss: 0.1277353024536278\n",
            "batch: 1535 loss: 0.127745155868819\n",
            "batch: 1536 loss: 0.1278453361594584\n",
            "batch: 1537 loss: 0.1278740750288125\n",
            "batch: 1538 loss: 0.12788913233554922\n",
            "batch: 1539 loss: 0.1282522968200501\n",
            "batch: 1540 loss: 0.12825946027762256\n",
            "batch: 1541 loss: 0.12838341952837073\n",
            "batch: 1542 loss: 0.1284266541188117\n",
            "batch: 1543 loss: 0.12846346335462294\n",
            "batch: 1544 loss: 0.12849825511104426\n",
            "batch: 1545 loss: 0.1285061183718499\n",
            "batch: 1546 loss: 0.12868565516150557\n",
            "batch: 1547 loss: 0.1289370939580258\n",
            "batch: 1548 loss: 0.12901476620859467\n",
            "batch: 1549 loss: 0.12915519515401683\n",
            "batch: 1550 loss: 0.1292937590999063\n",
            "batch: 1551 loss: 0.12929967251583002\n",
            "batch: 1552 loss: 0.1293305090905633\n",
            "batch: 1553 loss: 0.12935414621583186\n",
            "batch: 1554 loss: 0.1293648116120603\n",
            "batch: 1555 loss: 0.12937932565878146\n",
            "batch: 1556 loss: 0.1293901486254763\n",
            "batch: 1557 loss: 0.129401045095874\n",
            "batch: 1558 loss: 0.1294644205614459\n",
            "batch: 1559 loss: 0.1294867505140137\n",
            "batch: 1560 loss: 0.12950916073913685\n",
            "batch: 1561 loss: 0.12951857242058032\n",
            "batch: 1562 loss: 0.1295817009366583\n",
            "batch: 1563 loss: 0.1296749982915353\n",
            "batch: 1564 loss: 0.12990175557951442\n",
            "batch: 1565 loss: 0.12992664884845725\n",
            "batch: 1566 loss: 0.12994794401037507\n",
            "batch: 1567 loss: 0.12998495930689388\n",
            "batch: 1568 loss: 0.13003123293328098\n",
            "batch: 1569 loss: 0.1301093966390472\n",
            "batch: 1570 loss: 0.13033743182080798\n",
            "batch: 1571 loss: 0.13034553410555236\n",
            "batch: 1572 loss: 0.1303849517113995\n",
            "batch: 1573 loss: 0.13078363516996613\n",
            "batch: 1574 loss: 0.13090378541569225\n",
            "batch: 1575 loss: 0.13156316376547328\n",
            "batch: 1576 loss: 0.13184103984455578\n",
            "batch: 1577 loss: 0.13187723054061642\n",
            "batch: 1578 loss: 0.13207204864989036\n",
            "batch: 1579 loss: 0.13230349761317484\n",
            "batch: 1580 loss: 0.1323987715325784\n",
            "batch: 1581 loss: 0.13247175407479517\n",
            "batch: 1582 loss: 0.132522296392126\n",
            "batch: 1583 loss: 0.13257592368940824\n",
            "batch: 1584 loss: 0.13257938860380092\n",
            "batch: 1585 loss: 0.13276021973812022\n",
            "batch: 1586 loss: 0.13277116307173856\n",
            "batch: 1587 loss: 0.13279983527888545\n",
            "batch: 1588 loss: 0.1328492373668123\n",
            "batch: 1589 loss: 0.13288578267698176\n",
            "batch: 1590 loss: 0.13304470952157862\n",
            "batch: 1591 loss: 0.1332001464397181\n",
            "batch: 1592 loss: 0.13320813219086267\n",
            "batch: 1593 loss: 0.13332002372131682\n",
            "batch: 1594 loss: 0.13334440299519337\n",
            "batch: 1595 loss: 0.1334843706751708\n",
            "batch: 1596 loss: 0.13355079440423287\n",
            "batch: 1597 loss: 0.13359667379059828\n",
            "batch: 1598 loss: 0.1336982372517232\n",
            "batch: 1599 loss: 0.1337903945709113\n",
            "batch: 1600 loss: 0.13381728524365463\n",
            "batch: 1601 loss: 0.1338375472689513\n",
            "batch: 1602 loss: 0.1339523804972414\n",
            "batch: 1603 loss: 0.13409488134481945\n",
            "batch: 1604 loss: 0.13414975474425592\n",
            "batch: 1605 loss: 0.13419618833833374\n",
            "batch: 1606 loss: 0.13430827365093864\n",
            "batch: 1607 loss: 0.13447200856381095\n",
            "batch: 1608 loss: 0.13449150337115862\n",
            "batch: 1609 loss: 0.13454483909741977\n",
            "batch: 1610 loss: 0.13457670544297434\n",
            "batch: 1611 loss: 0.13458656896487808\n",
            "batch: 1612 loss: 0.1346135962291155\n",
            "batch: 1613 loss: 0.1346198232898023\n",
            "batch: 1614 loss: 0.13463451757538134\n",
            "batch: 1615 loss: 0.1347533600057941\n",
            "batch: 1616 loss: 0.13480558277177623\n",
            "batch: 1617 loss: 0.13490041331457905\n",
            "batch: 1618 loss: 0.1352032775382977\n",
            "batch: 1619 loss: 0.13527363392966799\n",
            "batch: 1620 loss: 0.13532949654269033\n",
            "batch: 1621 loss: 0.1354095239515882\n",
            "batch: 1622 loss: 0.13567035155254417\n",
            "batch: 1623 loss: 0.1357548262651544\n",
            "batch: 1624 loss: 0.13581980007397942\n",
            "batch: 1625 loss: 0.135872364963172\n",
            "batch: 1626 loss: 0.1359241192366462\n",
            "batch: 1627 loss: 0.13605485603469425\n",
            "batch: 1628 loss: 0.13609560975315982\n",
            "batch: 1629 loss: 0.13619667167845181\n",
            "batch: 1630 loss: 0.13627128327521495\n",
            "batch: 1631 loss: 0.13633822388085537\n",
            "batch: 1632 loss: 0.1363733802351635\n",
            "batch: 1633 loss: 0.13651102424296552\n",
            "batch: 1634 loss: 0.13654281356814318\n",
            "batch: 1635 loss: 0.13660062950733118\n",
            "batch: 1636 loss: 0.13663353075343185\n",
            "batch: 1637 loss: 0.13668292740988544\n",
            "batch: 1638 loss: 0.1367235559548717\n",
            "batch: 1639 loss: 0.13687544055539183\n",
            "batch: 1640 loss: 0.13701516908663325\n",
            "batch: 1641 loss: 0.13702389060682618\n",
            "batch: 1642 loss: 0.13705229005939326\n",
            "batch: 1643 loss: 0.13709153274423444\n",
            "batch: 1644 loss: 0.13711380665539763\n",
            "batch: 1645 loss: 0.13712640906474552\n",
            "batch: 1646 loss: 0.13759067578217946\n",
            "batch: 1647 loss: 0.13761473276629113\n",
            "batch: 1648 loss: 0.13775525059713983\n",
            "batch: 1649 loss: 0.1378912311734166\n",
            "batch: 1650 loss: 0.13793324685259722\n",
            "batch: 1651 loss: 0.13803710249229334\n",
            "batch: 1652 loss: 0.13824411206110382\n",
            "batch: 1653 loss: 0.13851667718752286\n",
            "batch: 1654 loss: 0.1385271614182275\n",
            "batch: 1655 loss: 0.1385661410454195\n",
            "batch: 1656 loss: 0.13865895430627279\n",
            "batch: 1657 loss: 0.1387064923036378\n",
            "batch: 1658 loss: 0.13877755686524323\n",
            "batch: 1659 loss: 0.13886154848220758\n",
            "batch: 1660 loss: 0.13890932318451815\n",
            "batch: 1661 loss: 0.1389246660869103\n",
            "batch: 1662 loss: 0.1389781758885365\n",
            "batch: 1663 loss: 0.13937172887730412\n",
            "batch: 1664 loss: 0.13938412304664963\n",
            "batch: 1665 loss: 0.13939645310747437\n",
            "batch: 1666 loss: 0.13943528946000153\n",
            "batch: 1667 loss: 0.13947122564422898\n",
            "batch: 1668 loss: 0.1395233511987608\n",
            "batch: 1669 loss: 0.13964308876427822\n",
            "batch: 1670 loss: 0.13971930734696797\n",
            "batch: 1671 loss: 0.13977548892679625\n",
            "batch: 1672 loss: 0.13982902810606174\n",
            "batch: 1673 loss: 0.13984404694358818\n",
            "batch: 1674 loss: 0.13999772340874186\n",
            "batch: 1675 loss: 0.14003111850540154\n",
            "batch: 1676 loss: 0.14019979380886072\n",
            "batch: 1677 loss: 0.14021692400868052\n",
            "batch: 1678 loss: 0.1402596788487863\n",
            "batch: 1679 loss: 0.14034847930888644\n",
            "batch: 1680 loss: 0.14036283899168484\n",
            "batch: 1681 loss: 0.14038440382364206\n",
            "batch: 1682 loss: 0.14051580858114177\n",
            "batch: 1683 loss: 0.1405305085813161\n",
            "batch: 1684 loss: 0.14061710463068447\n",
            "batch: 1685 loss: 0.14066680533043108\n",
            "batch: 1686 loss: 0.14071593643701635\n",
            "batch: 1687 loss: 0.14079655253118836\n",
            "batch: 1688 loss: 0.1408888300580438\n",
            "batch: 1689 loss: 0.1410163391304668\n",
            "batch: 1690 loss: 0.14127835849649273\n",
            "batch: 1691 loss: 0.14133331273100339\n",
            "batch: 1692 loss: 0.1413499436506536\n",
            "batch: 1693 loss: 0.14149006959586405\n",
            "batch: 1694 loss: 0.14151098326197825\n",
            "batch: 1695 loss: 0.14154495689249597\n",
            "batch: 1696 loss: 0.14155845307814888\n",
            "batch: 1697 loss: 0.1415759220297914\n",
            "batch: 1698 loss: 0.14159354013646952\n",
            "batch: 1699 loss: 0.1416632341563236\n",
            "batch: 1700 loss: 0.14170192006672733\n",
            "batch: 1701 loss: 0.1417948032214772\n",
            "batch: 1702 loss: 0.14180494608799926\n",
            "batch: 1703 loss: 0.14186249034176582\n",
            "batch: 1704 loss: 0.14194200187246314\n",
            "batch: 1705 loss: 0.14197153479303234\n",
            "batch: 1706 loss: 0.14203107872302645\n",
            "batch: 1707 loss: 0.14211074901814572\n",
            "batch: 1708 loss: 0.14218448574538342\n",
            "batch: 1709 loss: 0.14221273795398884\n",
            "batch: 1710 loss: 0.142317160962848\n",
            "batch: 1711 loss: 0.14238256052765064\n",
            "batch: 1712 loss: 0.14258256886037998\n",
            "batch: 1713 loss: 0.14259897615271622\n",
            "batch: 1714 loss: 0.14261740847374313\n",
            "batch: 1715 loss: 0.14277320506121033\n",
            "batch: 1716 loss: 0.14279057733970693\n",
            "batch: 1717 loss: 0.14279775332356803\n",
            "batch: 1718 loss: 0.14288704596902244\n",
            "batch: 1719 loss: 0.14289209005306475\n",
            "batch: 1720 loss: 0.1429956998087\n",
            "batch: 1721 loss: 0.14313506481121294\n",
            "batch: 1722 loss: 0.14314549144054764\n",
            "batch: 1723 loss: 0.14322216168488375\n",
            "batch: 1724 loss: 0.1433423122956883\n",
            "batch: 1725 loss: 0.14336027483153158\n",
            "batch: 1726 loss: 0.14344396023708395\n",
            "batch: 1727 loss: 0.14345593994553202\n",
            "batch: 1728 loss: 0.14347829735348933\n",
            "batch: 1729 loss: 0.14351618472929112\n",
            "batch: 1730 loss: 0.14356832639570347\n",
            "batch: 1731 loss: 0.14361495347018355\n",
            "batch: 1732 loss: 0.14381091256137005\n",
            "batch: 1733 loss: 0.1438266121286433\n",
            "batch: 1734 loss: 0.14385055660898796\n",
            "batch: 1735 loss: 0.1438757365278434\n",
            "batch: 1736 loss: 0.14388095772243104\n",
            "batch: 1737 loss: 0.1440701433715876\n",
            "batch: 1738 loss: 0.14407647218578495\n",
            "batch: 1739 loss: 0.1441117486807052\n",
            "batch: 1740 loss: 0.1441207268855069\n",
            "batch: 1741 loss: 0.14414233807311394\n",
            "batch: 1742 loss: 0.14424059586809015\n",
            "batch: 1743 loss: 0.14436148134456017\n",
            "batch: 1744 loss: 0.14458638014481404\n",
            "batch: 1745 loss: 0.1448387726752553\n",
            "batch: 1746 loss: 0.14490846425876952\n",
            "batch: 1747 loss: 0.14499430549726822\n",
            "batch: 1748 loss: 0.14501177674927748\n",
            "batch: 1749 loss: 0.14506747362040914\n",
            "batch: 1750 loss: 0.14518836342566646\n",
            "batch: 1751 loss: 0.14550357117527166\n",
            "batch: 1752 loss: 0.14553515194379724\n",
            "batch: 1753 loss: 0.14558942277007736\n",
            "batch: 1754 loss: 0.14559914388717152\n",
            "batch: 1755 loss: 0.14567094398499467\n",
            "batch: 1756 loss: 0.14584471587301231\n",
            "batch: 1757 loss: 0.14597434104443527\n",
            "batch: 1758 loss: 0.14598413763777354\n",
            "batch: 1759 loss: 0.14599008785025216\n",
            "batch: 1760 loss: 0.14606899466947654\n",
            "batch: 1761 loss: 0.14610094068036414\n",
            "batch: 1762 loss: 0.14616298362449742\n",
            "batch: 1763 loss: 0.1462040199248586\n",
            "batch: 1764 loss: 0.14622712668241003\n",
            "batch: 1765 loss: 0.1462291095687542\n",
            "batch: 1766 loss: 0.14627444060356357\n",
            "batch: 1767 loss: 0.14630965822399594\n",
            "batch: 1768 loss: 0.14632249277760276\n",
            "batch: 1769 loss: 0.14635118449223228\n",
            "batch: 1770 loss: 0.146409550254466\n",
            "batch: 1771 loss: 0.14649239925039\n",
            "batch: 1772 loss: 0.14656850083661266\n",
            "batch: 1773 loss: 0.14659001817856915\n",
            "batch: 1774 loss: 0.14663293943111785\n",
            "batch: 1775 loss: 0.1466683305010665\n",
            "batch: 1776 loss: 0.14667379479226655\n",
            "batch: 1777 loss: 0.14669519554194993\n",
            "batch: 1778 loss: 0.146842566997977\n",
            "batch: 1779 loss: 0.14695641415682623\n",
            "batch: 1780 loss: 0.14720738821593113\n",
            "batch: 1781 loss: 0.14724348633852788\n",
            "batch: 1782 loss: 0.14761954369512387\n",
            "batch: 1783 loss: 0.1477222612660844\n",
            "batch: 1784 loss: 0.14773458524909802\n",
            "batch: 1785 loss: 0.1477518936425913\n",
            "batch: 1786 loss: 0.14791882354323752\n",
            "batch: 1787 loss: 0.14794853140530176\n",
            "batch: 1788 loss: 0.14849099566158838\n",
            "batch: 1789 loss: 0.14855402223882266\n",
            "batch: 1790 loss: 0.1487393451940734\n",
            "batch: 1791 loss: 0.14874966363818384\n",
            "batch: 1792 loss: 0.148775642397115\n",
            "batch: 1793 loss: 0.14893923299224116\n",
            "batch: 1794 loss: 0.1490777200034354\n",
            "batch: 1795 loss: 0.14964425201923587\n",
            "batch: 1796 loss: 0.14977960732788778\n",
            "batch: 1797 loss: 0.14980181216658092\n",
            "batch: 1798 loss: 0.14991739477426744\n",
            "batch: 1799 loss: 0.1499324751936365\n",
            "batch: 1800 loss: 0.1501822897933889\n",
            "batch: 1801 loss: 0.15019943270948716\n",
            "batch: 1802 loss: 0.1503749031361658\n",
            "batch: 1803 loss: 0.1503883009359706\n",
            "batch: 1804 loss: 0.1504166843846906\n",
            "batch: 1805 loss: 0.15047546239499934\n",
            "batch: 1806 loss: 0.15049398525361904\n",
            "batch: 1807 loss: 0.15050074042822234\n",
            "batch: 1808 loss: 0.1508150068416726\n",
            "batch: 1809 loss: 0.15083431297237984\n",
            "batch: 1810 loss: 0.15098063191468827\n",
            "batch: 1811 loss: 0.15098412578809076\n",
            "batch: 1812 loss: 0.15108142750221304\n",
            "batch: 1813 loss: 0.15110388375888578\n",
            "batch: 1814 loss: 0.15147219793568364\n",
            "batch: 1815 loss: 0.15148940704832786\n",
            "batch: 1816 loss: 0.1515005550093483\n",
            "batch: 1817 loss: 0.15153007071721367\n",
            "batch: 1818 loss: 0.1516735947530251\n",
            "batch: 1819 loss: 0.15187582796323112\n",
            "batch: 1820 loss: 0.15192864388856106\n",
            "batch: 1821 loss: 0.15198546736943536\n",
            "batch: 1822 loss: 0.15207385351019911\n",
            "batch: 1823 loss: 0.15215050846594386\n",
            "batch: 1824 loss: 0.15217531535658055\n",
            "batch: 1825 loss: 0.15223865813645535\n",
            "batch: 1826 loss: 0.15224759196373633\n",
            "batch: 1827 loss: 0.15225305380369536\n",
            "batch: 1828 loss: 0.15231888105417601\n",
            "batch: 1829 loss: 0.15240251449937933\n",
            "batch: 1830 loss: 0.15242957402090543\n",
            "batch: 1831 loss: 0.15247814963082784\n",
            "batch: 1832 loss: 0.15247940709558316\n",
            "batch: 1833 loss: 0.15262029525008983\n",
            "batch: 1834 loss: 0.15272526529547759\n",
            "batch: 1835 loss: 0.1527318727544043\n",
            "batch: 1836 loss: 0.1527714846751187\n",
            "batch: 1837 loss: 0.15278728962154128\n",
            "batch: 1838 loss: 0.15288603014708496\n",
            "batch: 1839 loss: 0.15290158236050047\n",
            "batch: 1840 loss: 0.1529615385348443\n",
            "batch: 1841 loss: 0.1529769994255621\n",
            "batch: 1842 loss: 0.15298715668194926\n",
            "batch: 1843 loss: 0.15299208028917202\n",
            "batch: 1844 loss: 0.15299596446636132\n",
            "batch: 1845 loss: 0.1532632930863183\n",
            "batch: 1846 loss: 0.15335266097518616\n",
            "batch: 1847 loss: 0.15352305900189095\n",
            "batch: 1848 loss: 0.1535400216325652\n",
            "batch: 1849 loss: 0.15359569254587405\n",
            "batch: 1850 loss: 0.15360081600188277\n",
            "batch: 1851 loss: 0.15372831796645187\n",
            "batch: 1852 loss: 0.15377720311074516\n",
            "batch: 1853 loss: 0.15383815283118746\n",
            "batch: 1854 loss: 0.15392563433735632\n",
            "batch: 1855 loss: 0.15403863578825258\n",
            "batch: 1856 loss: 0.15411900087981484\n",
            "batch: 1857 loss: 0.1541718371899333\n",
            "batch: 1858 loss: 0.15418835365376435\n",
            "batch: 1859 loss: 0.15425076769641602\n",
            "batch: 1860 loss: 0.15436127467802727\n",
            "batch: 1861 loss: 0.15439784101000986\n",
            "batch: 1862 loss: 0.15475279054394922\n",
            "batch: 1863 loss: 0.1548621347656008\n",
            "batch: 1864 loss: 0.1549185090919491\n",
            "batch: 1865 loss: 0.1550726866980549\n",
            "batch: 1866 loss: 0.15518018120131455\n",
            "batch: 1867 loss: 0.15519887796766124\n",
            "batch: 1868 loss: 0.155280896022683\n",
            "batch: 1869 loss: 0.15543163920915687\n",
            "batch: 1870 loss: 0.15543651600345038\n",
            "batch: 1871 loss: 0.1554966012367513\n",
            "batch: 1872 loss: 0.15553804140328428\n",
            "batch: 1873 loss: 0.1556174429783132\n",
            "batch: 1874 loss: 0.15573848764388823\n",
            "batch: 1 loss: 4.037051647901535e-05\n",
            "batch: 2 loss: 8.637578412890434e-05\n",
            "batch: 3 loss: 0.00012077558413147927\n",
            "batch: 4 loss: 0.0001622360534965992\n",
            "batch: 5 loss: 0.000271668117493391\n",
            "batch: 6 loss: 0.0003244303651154041\n",
            "batch: 7 loss: 0.0003507441245019436\n",
            "batch: 8 loss: 0.0004132677726447582\n",
            "batch: 9 loss: 0.00042797362990677356\n",
            "batch: 10 loss: 0.0004911991450935602\n",
            "batch: 11 loss: 0.0004987214095890522\n",
            "batch: 12 loss: 0.0006152258031070232\n",
            "batch: 13 loss: 0.0006350497975945473\n",
            "batch: 14 loss: 0.0006419769446365535\n",
            "batch: 15 loss: 0.0006654965090565384\n",
            "batch: 16 loss: 0.0006815725411288441\n",
            "batch: 17 loss: 0.0007404853324405849\n",
            "batch: 18 loss: 0.0007529476420022548\n",
            "batch: 19 loss: 0.0007771377996541559\n",
            "batch: 20 loss: 0.0007879501790739596\n",
            "batch: 21 loss: 0.0008238534317351878\n",
            "batch: 22 loss: 0.0008555180602706968\n",
            "batch: 23 loss: 0.0009800413050688804\n",
            "batch: 24 loss: 0.001210976163391024\n",
            "batch: 25 loss: 0.0013903493830002844\n",
            "batch: 26 loss: 0.0014122560848481953\n",
            "batch: 27 loss: 0.0014970304225571454\n",
            "batch: 28 loss: 0.001543256350327283\n",
            "batch: 29 loss: 0.0015908275102265179\n",
            "batch: 30 loss: 0.0016079785660840572\n",
            "batch: 31 loss: 0.0016404148251749574\n",
            "batch: 32 loss: 0.0016485962863080203\n",
            "batch: 33 loss: 0.0016689543160609902\n",
            "batch: 34 loss: 0.0018020593258552254\n",
            "batch: 35 loss: 0.0018099259282462299\n",
            "batch: 36 loss: 0.0018326928704045712\n",
            "batch: 37 loss: 0.0019748919843696057\n",
            "batch: 38 loss: 0.0020410745232366024\n",
            "batch: 39 loss: 0.0020815850994549694\n",
            "batch: 40 loss: 0.002280580957885832\n",
            "batch: 41 loss: 0.002376066771801561\n",
            "batch: 42 loss: 0.0026371550834737717\n",
            "batch: 43 loss: 0.0027410833439789712\n",
            "batch: 44 loss: 0.0027556893168948593\n",
            "batch: 45 loss: 0.0028085812940262258\n",
            "batch: 46 loss: 0.0028396519436500968\n",
            "batch: 47 loss: 0.0028642623531632124\n",
            "batch: 48 loss: 0.0028863064046017826\n",
            "batch: 49 loss: 0.0029480448584072293\n",
            "batch: 50 loss: 0.0029892311203293504\n",
            "batch: 51 loss: 0.0031205059993080794\n",
            "batch: 52 loss: 0.0031949985208921134\n",
            "batch: 53 loss: 0.0032031380529515445\n",
            "batch: 54 loss: 0.003236854262184352\n",
            "batch: 55 loss: 0.0032784268590621652\n",
            "batch: 56 loss: 0.0034455746742896734\n",
            "batch: 57 loss: 0.0034817119124345482\n",
            "batch: 58 loss: 0.0034898278783075513\n",
            "batch: 59 loss: 0.003522437698673457\n",
            "batch: 60 loss: 0.0035682583074085413\n",
            "batch: 61 loss: 0.003573311545420438\n",
            "batch: 62 loss: 0.003578344903420657\n",
            "batch: 63 loss: 0.0036499229590408505\n",
            "batch: 64 loss: 0.0038113956372253597\n",
            "batch: 65 loss: 0.0038307012165896596\n",
            "batch: 66 loss: 0.003841152801644057\n",
            "batch: 67 loss: 0.003916093788575381\n",
            "batch: 68 loss: 0.003925390135962516\n",
            "batch: 69 loss: 0.004121058386284858\n",
            "batch: 70 loss: 0.0041631953534670176\n",
            "batch: 71 loss: 0.004226674493867904\n",
            "batch: 72 loss: 0.004324891824740916\n",
            "batch: 73 loss: 0.004372182328719646\n",
            "batch: 74 loss: 0.004415123619604856\n",
            "batch: 75 loss: 0.004606751122046262\n",
            "batch: 76 loss: 0.004722876437474042\n",
            "batch: 77 loss: 0.004741728412453085\n",
            "batch: 78 loss: 0.004760613963473589\n",
            "batch: 79 loss: 0.004817693293560296\n",
            "batch: 80 loss: 0.004826986263971776\n",
            "batch: 81 loss: 0.004882106460165232\n",
            "batch: 82 loss: 0.00495853030635044\n",
            "batch: 83 loss: 0.004975261248182506\n",
            "batch: 84 loss: 0.005015575911384076\n",
            "batch: 85 loss: 0.005085646587889642\n",
            "batch: 86 loss: 0.0051409316021017734\n",
            "batch: 87 loss: 0.005172026134561748\n",
            "batch: 88 loss: 0.005181727887596935\n",
            "batch: 89 loss: 0.005307282955851406\n",
            "batch: 90 loss: 0.005486312718596309\n",
            "batch: 91 loss: 0.005499919202644378\n",
            "batch: 92 loss: 0.005539619174320251\n",
            "batch: 93 loss: 0.00558229646133259\n",
            "batch: 94 loss: 0.005618250582832843\n",
            "batch: 95 loss: 0.005649880927521735\n",
            "batch: 96 loss: 0.005670381639618426\n",
            "batch: 97 loss: 0.005735410172957927\n",
            "batch: 98 loss: 0.00575632616924122\n",
            "batch: 99 loss: 0.005782401305157691\n",
            "batch: 100 loss: 0.0057897160756401715\n",
            "batch: 101 loss: 0.005837179392110556\n",
            "batch: 102 loss: 0.005886138829868287\n",
            "batch: 103 loss: 0.005899712552782148\n",
            "batch: 104 loss: 0.005945821707602591\n",
            "batch: 105 loss: 0.005958244956564158\n",
            "batch: 106 loss: 0.005970392581541091\n",
            "batch: 107 loss: 0.006006630145478994\n",
            "batch: 108 loss: 0.006053279318381101\n",
            "batch: 109 loss: 0.0061825469364412125\n",
            "batch: 110 loss: 0.0062168974955566225\n",
            "batch: 111 loss: 0.006230347555596381\n",
            "batch: 112 loss: 0.006420021441299468\n",
            "batch: 113 loss: 0.0064259035023860635\n",
            "batch: 114 loss: 0.006538073475938291\n",
            "batch: 115 loss: 0.006586922093760222\n",
            "batch: 116 loss: 0.006597512799780816\n",
            "batch: 117 loss: 0.006624861809890717\n",
            "batch: 118 loss: 0.006634249033872038\n",
            "batch: 119 loss: 0.006671781765762716\n",
            "batch: 120 loss: 0.006750748003367334\n",
            "batch: 121 loss: 0.006757559169549495\n",
            "batch: 122 loss: 0.006797974855173379\n",
            "batch: 123 loss: 0.006802054112777114\n",
            "batch: 124 loss: 0.006820507612079382\n",
            "batch: 125 loss: 0.00683969796821475\n",
            "batch: 126 loss: 0.006846970795188099\n",
            "batch: 127 loss: 0.007029740615282208\n",
            "batch: 128 loss: 0.007130964791867882\n",
            "batch: 129 loss: 0.007137153937015682\n",
            "batch: 130 loss: 0.00715087222168222\n",
            "batch: 131 loss: 0.007168976523447782\n",
            "batch: 132 loss: 0.00729271972225979\n",
            "batch: 133 loss: 0.007301710563246161\n",
            "batch: 134 loss: 0.007308879810851068\n",
            "batch: 135 loss: 0.00744629544345662\n",
            "batch: 136 loss: 0.007460690131876618\n",
            "batch: 137 loss: 0.0074971051053144035\n",
            "batch: 138 loss: 0.007528321728575975\n",
            "batch: 139 loss: 0.007654273152817041\n",
            "batch: 140 loss: 0.0076802961979992685\n",
            "batch: 141 loss: 0.007762035087216646\n",
            "batch: 142 loss: 0.007779546605888754\n",
            "batch: 143 loss: 0.007794707848224789\n",
            "batch: 144 loss: 0.007813043067697435\n",
            "batch: 145 loss: 0.007818391578737646\n",
            "batch: 146 loss: 0.007856209652964026\n",
            "batch: 147 loss: 0.00795783335948363\n",
            "batch: 148 loss: 0.00804098421568051\n",
            "batch: 149 loss: 0.008094356494490057\n",
            "batch: 150 loss: 0.008114059245679527\n",
            "batch: 151 loss: 0.00815998104447499\n",
            "batch: 152 loss: 0.00818393991002813\n",
            "batch: 153 loss: 0.008317723488900811\n",
            "batch: 154 loss: 0.008654852634761482\n",
            "batch: 155 loss: 0.008727777859661728\n",
            "batch: 156 loss: 0.008754158705938608\n",
            "batch: 157 loss: 0.008796507936436684\n",
            "batch: 158 loss: 0.008814210100565106\n",
            "batch: 159 loss: 0.008851447931025177\n",
            "batch: 160 loss: 0.008974150738213211\n",
            "batch: 161 loss: 0.009076573430094869\n",
            "batch: 162 loss: 0.009182344375643879\n",
            "batch: 163 loss: 0.009235441046301276\n",
            "batch: 164 loss: 0.00932447131210938\n",
            "batch: 165 loss: 0.009472373115364462\n",
            "batch: 166 loss: 0.009505984643939883\n",
            "batch: 167 loss: 0.009517479074653237\n",
            "batch: 168 loss: 0.009590040822979063\n",
            "batch: 169 loss: 0.009665528816636652\n",
            "batch: 170 loss: 0.0097035766816698\n",
            "batch: 171 loss: 0.009721455724444241\n",
            "batch: 172 loss: 0.009739693134557456\n",
            "batch: 173 loss: 0.009755483261775225\n",
            "batch: 174 loss: 0.009773652664851397\n",
            "batch: 175 loss: 0.009781660115811974\n",
            "batch: 176 loss: 0.009828818409238011\n",
            "batch: 177 loss: 0.009864825355354696\n",
            "batch: 178 loss: 0.010078188362065702\n",
            "batch: 179 loss: 0.01008899982040748\n",
            "batch: 180 loss: 0.010116768832784145\n",
            "batch: 181 loss: 0.010147683955263347\n",
            "batch: 182 loss: 0.01017890078900382\n",
            "batch: 183 loss: 0.01023892943514511\n",
            "batch: 184 loss: 0.010243908282369376\n",
            "batch: 185 loss: 0.010255172812379896\n",
            "batch: 186 loss: 0.010378516444005071\n",
            "batch: 187 loss: 0.010404513173736632\n",
            "batch: 188 loss: 0.010638565936125815\n",
            "batch: 189 loss: 0.010655132551677524\n",
            "batch: 190 loss: 0.010664571613073348\n",
            "batch: 191 loss: 0.010700219046324492\n",
            "batch: 192 loss: 0.010710640265606343\n",
            "batch: 193 loss: 0.010712583556538448\n",
            "batch: 194 loss: 0.0108510047046002\n",
            "batch: 195 loss: 0.010858129048487172\n",
            "batch: 196 loss: 0.010978204818209634\n",
            "batch: 197 loss: 0.011106324197491631\n",
            "batch: 198 loss: 0.01118145446642302\n",
            "batch: 199 loss: 0.011183649360435083\n",
            "batch: 200 loss: 0.011207682560430839\n",
            "batch: 201 loss: 0.011248874089913442\n",
            "batch: 202 loss: 0.0113106330067385\n",
            "batch: 203 loss: 0.01133665422652848\n",
            "batch: 204 loss: 0.011384782708482817\n",
            "batch: 205 loss: 0.011455774567322805\n",
            "batch: 206 loss: 0.01147227066126652\n",
            "batch: 207 loss: 0.01148360932734795\n",
            "batch: 208 loss: 0.011561238178284838\n",
            "batch: 209 loss: 0.011689584174426273\n",
            "batch: 210 loss: 0.011719890005188062\n",
            "batch: 211 loss: 0.011798961012857035\n",
            "batch: 212 loss: 0.011880054115550593\n",
            "batch: 213 loss: 0.012079590915935114\n",
            "batch: 214 loss: 0.01209467534092255\n",
            "batch: 215 loss: 0.012113222589017824\n",
            "batch: 216 loss: 0.012121288104215637\n",
            "batch: 217 loss: 0.012185427977005019\n",
            "batch: 218 loss: 0.012207391953328624\n",
            "batch: 219 loss: 0.012289406394818798\n",
            "batch: 220 loss: 0.012303982366109268\n",
            "batch: 221 loss: 0.012330136060947553\n",
            "batch: 222 loss: 0.012381306018913164\n",
            "batch: 223 loss: 0.012405322544509545\n",
            "batch: 224 loss: 0.012412347664358094\n",
            "batch: 225 loss: 0.0124671249773819\n",
            "batch: 226 loss: 0.01249539069388993\n",
            "batch: 227 loss: 0.012502876498969272\n",
            "batch: 228 loss: 0.012521314162062482\n",
            "batch: 229 loss: 0.012529024246847258\n",
            "batch: 230 loss: 0.012544157480588182\n",
            "batch: 231 loss: 0.012599739828845486\n",
            "batch: 232 loss: 0.012651085385819896\n",
            "batch: 233 loss: 0.012710447082063182\n",
            "batch: 234 loss: 0.012788962015649304\n",
            "batch: 235 loss: 0.01282282723276876\n",
            "batch: 236 loss: 0.012827029138570652\n",
            "batch: 237 loss: 0.012845317551633343\n",
            "batch: 238 loss: 0.012938600489636883\n",
            "batch: 239 loss: 0.012942421618616208\n",
            "batch: 240 loss: 0.012949775949819014\n",
            "batch: 241 loss: 0.013006846603704617\n",
            "batch: 242 loss: 0.013086488452507183\n",
            "batch: 243 loss: 0.013095934469019995\n",
            "batch: 244 loss: 0.013153300642734393\n",
            "batch: 245 loss: 0.013186727385735139\n",
            "batch: 246 loss: 0.013209808066254481\n",
            "batch: 247 loss: 0.013274012230103835\n",
            "batch: 248 loss: 0.013282208383781835\n",
            "batch: 249 loss: 0.013449784532887862\n",
            "batch: 250 loss: 0.013459416233701631\n",
            "batch: 251 loss: 0.013513052330119535\n",
            "batch: 252 loss: 0.01357821919838898\n",
            "batch: 253 loss: 0.013649688520235941\n",
            "batch: 254 loss: 0.013651819941820577\n",
            "batch: 255 loss: 0.013851053160848096\n",
            "batch: 256 loss: 0.013865956662455573\n",
            "batch: 257 loss: 0.013871763755800202\n",
            "batch: 258 loss: 0.013924638335825875\n",
            "batch: 259 loss: 0.013933085372904316\n",
            "batch: 260 loss: 0.014022502979496494\n",
            "batch: 261 loss: 0.014118805451551452\n",
            "batch: 262 loss: 0.0142278158350382\n",
            "batch: 263 loss: 0.014473372726002708\n",
            "batch: 264 loss: 0.014475710763363167\n",
            "batch: 265 loss: 0.014478663888527081\n",
            "batch: 266 loss: 0.014487178933573886\n",
            "batch: 267 loss: 0.01451363769802265\n",
            "batch: 268 loss: 0.014529014092637226\n",
            "batch: 269 loss: 0.014555244468851015\n",
            "batch: 270 loss: 0.014569792632712051\n",
            "batch: 271 loss: 0.01465806879545562\n",
            "batch: 272 loss: 0.01472723748232238\n",
            "batch: 273 loss: 0.0150168017342221\n",
            "batch: 274 loss: 0.015132745687616989\n",
            "batch: 275 loss: 0.015364337091101334\n",
            "batch: 276 loss: 0.015368669694988056\n",
            "batch: 277 loss: 0.015396011492935941\n",
            "batch: 278 loss: 0.015432671057758853\n",
            "batch: 279 loss: 0.015468534032581374\n",
            "batch: 280 loss: 0.015523106570122763\n",
            "batch: 281 loss: 0.015531636190367862\n",
            "batch: 282 loss: 0.015577020154101773\n",
            "batch: 283 loss: 0.015612743128789588\n",
            "batch: 284 loss: 0.015721647989703342\n",
            "batch: 285 loss: 0.015819703441811727\n",
            "batch: 286 loss: 0.016039508861256765\n",
            "batch: 287 loss: 0.016207320031477138\n",
            "batch: 288 loss: 0.0163036534904968\n",
            "batch: 289 loss: 0.016375286643160507\n",
            "batch: 290 loss: 0.016505098406923935\n",
            "batch: 291 loss: 0.016549369756830856\n",
            "batch: 292 loss: 0.016614142668200656\n",
            "batch: 293 loss: 0.016641505601583048\n",
            "batch: 294 loss: 0.016750368813751266\n",
            "batch: 295 loss: 0.017035383979557082\n",
            "batch: 296 loss: 0.017245733345625923\n",
            "batch: 297 loss: 0.017257435095263646\n",
            "batch: 298 loss: 0.01726121616642922\n",
            "batch: 299 loss: 0.01738750760536641\n",
            "batch: 300 loss: 0.017514522346667945\n",
            "batch: 301 loss: 0.017519872230477632\n",
            "batch: 302 loss: 0.017530180941335856\n",
            "batch: 303 loss: 0.01755222508404404\n",
            "batch: 304 loss: 0.017680344955064355\n",
            "batch: 305 loss: 0.017690289547666906\n",
            "batch: 306 loss: 0.017796422800049186\n",
            "batch: 307 loss: 0.017862302316352725\n",
            "batch: 308 loss: 0.017891633078455926\n",
            "batch: 309 loss: 0.017938120722770692\n",
            "batch: 310 loss: 0.01812155282497406\n",
            "batch: 311 loss: 0.01814748573116958\n",
            "batch: 312 loss: 0.0181843931209296\n",
            "batch: 313 loss: 0.01819706732779741\n",
            "batch: 314 loss: 0.018250438284128905\n",
            "batch: 315 loss: 0.018318534906953572\n",
            "batch: 316 loss: 0.018342873653396964\n",
            "batch: 317 loss: 0.018390534607693552\n",
            "batch: 318 loss: 0.018403194434009493\n",
            "batch: 319 loss: 0.018517670101486146\n",
            "batch: 320 loss: 0.018594151250086725\n",
            "batch: 321 loss: 0.01861949766147882\n",
            "batch: 322 loss: 0.018628139005973935\n",
            "batch: 323 loss: 0.018632985518313945\n",
            "batch: 324 loss: 0.018634011406218634\n",
            "batch: 325 loss: 0.018661049149697646\n",
            "batch: 326 loss: 0.01866910959291272\n",
            "batch: 327 loss: 0.0186884698967915\n",
            "batch: 328 loss: 0.018806363495765255\n",
            "batch: 329 loss: 0.018827014217851684\n",
            "batch: 330 loss: 0.018883660326479004\n",
            "batch: 331 loss: 0.01892844634014182\n",
            "batch: 332 loss: 0.01895112998294644\n",
            "batch: 333 loss: 0.019003921421943234\n",
            "batch: 334 loss: 0.019206442820606753\n",
            "batch: 335 loss: 0.019336949082789944\n",
            "batch: 336 loss: 0.01949840989965014\n",
            "batch: 337 loss: 0.01950741036213003\n",
            "batch: 338 loss: 0.0196522882131394\n",
            "batch: 339 loss: 0.019676635063951835\n",
            "batch: 340 loss: 0.01976314090169035\n",
            "batch: 341 loss: 0.019876139886444436\n",
            "batch: 342 loss: 0.019899756045779215\n",
            "batch: 343 loss: 0.019922525016358123\n",
            "batch: 344 loss: 0.01992957934900187\n",
            "batch: 345 loss: 0.019936063408618792\n",
            "batch: 346 loss: 0.02000595138198696\n",
            "batch: 347 loss: 0.020020825182786212\n",
            "batch: 348 loss: 0.02015206824778579\n",
            "batch: 349 loss: 0.020235320387175307\n",
            "batch: 350 loss: 0.020275306021561846\n",
            "batch: 351 loss: 0.020359330234816297\n",
            "batch: 352 loss: 0.020407223330577835\n",
            "batch: 353 loss: 0.02050297718658112\n",
            "batch: 354 loss: 0.020527814237168058\n",
            "batch: 355 loss: 0.02053298654849641\n",
            "batch: 356 loss: 0.020620487090898677\n",
            "batch: 357 loss: 0.020667608310235664\n",
            "batch: 358 loss: 0.020686698850942774\n",
            "batch: 359 loss: 0.020725640387041493\n",
            "batch: 360 loss: 0.02077405594731681\n",
            "batch: 361 loss: 0.020806967411888762\n",
            "batch: 362 loss: 0.020820495475782082\n",
            "batch: 363 loss: 0.020849168085260317\n",
            "batch: 364 loss: 0.020898186520440502\n",
            "batch: 365 loss: 0.020976952248020098\n",
            "batch: 366 loss: 0.02098496098141186\n",
            "batch: 367 loss: 0.02102745131845586\n",
            "batch: 368 loss: 0.021049752068473027\n",
            "batch: 369 loss: 0.02107476832601242\n",
            "batch: 370 loss: 0.021082683401880787\n",
            "batch: 371 loss: 0.021091824715724215\n",
            "batch: 372 loss: 0.021112766047706826\n",
            "batch: 373 loss: 0.021123082244535907\n",
            "batch: 374 loss: 0.021140125637641175\n",
            "batch: 375 loss: 0.021155136613873766\n",
            "batch: 376 loss: 0.0211881966504734\n",
            "batch: 377 loss: 0.021215209408430382\n",
            "batch: 378 loss: 0.021226814565015958\n",
            "batch: 379 loss: 0.021242204044712706\n",
            "batch: 380 loss: 0.021256769410101697\n",
            "batch: 381 loss: 0.02138109417888336\n",
            "batch: 382 loss: 0.021426834809361025\n",
            "batch: 383 loss: 0.021431137836771086\n",
            "batch: 384 loss: 0.021460341467754915\n",
            "batch: 385 loss: 0.021468606854090466\n",
            "batch: 386 loss: 0.021504910895833746\n",
            "batch: 387 loss: 0.02151056344038807\n",
            "batch: 388 loss: 0.02160705981380306\n",
            "batch: 389 loss: 0.021616551162442193\n",
            "batch: 390 loss: 0.021631840832298622\n",
            "batch: 391 loss: 0.021644870240008458\n",
            "batch: 392 loss: 0.021799350175773724\n",
            "batch: 393 loss: 0.02190406272164546\n",
            "batch: 394 loss: 0.02193174859858118\n",
            "batch: 395 loss: 0.02197536366409622\n",
            "batch: 396 loss: 0.021981298661557958\n",
            "batch: 397 loss: 0.022079795307246967\n",
            "batch: 398 loss: 0.022099382295040413\n",
            "batch: 399 loss: 0.022106354326708242\n",
            "batch: 400 loss: 0.0221800443388056\n",
            "batch: 401 loss: 0.02219451152603142\n",
            "batch: 402 loss: 0.022207421542843803\n",
            "batch: 403 loss: 0.02240276193781756\n",
            "batch: 404 loss: 0.022419386286055668\n",
            "batch: 405 loss: 0.022626568723237143\n",
            "batch: 406 loss: 0.022634542466839776\n",
            "batch: 407 loss: 0.02286867949529551\n",
            "batch: 408 loss: 0.02297318852110766\n",
            "batch: 409 loss: 0.02301484409510158\n",
            "batch: 410 loss: 0.02304947798489593\n",
            "batch: 411 loss: 0.023081317325821145\n",
            "batch: 412 loss: 0.02316714004962705\n",
            "batch: 413 loss: 0.023258171839406715\n",
            "batch: 414 loss: 0.023551716787507757\n",
            "batch: 415 loss: 0.02357748776092194\n",
            "batch: 416 loss: 0.023781159350415693\n",
            "batch: 417 loss: 0.023943203771254046\n",
            "batch: 418 loss: 0.023995389925083144\n",
            "batch: 419 loss: 0.02411334422393702\n",
            "batch: 420 loss: 0.02415272797434591\n",
            "batch: 421 loss: 0.02416747562470846\n",
            "batch: 422 loss: 0.024222538611618803\n",
            "batch: 423 loss: 0.024256961940554902\n",
            "batch: 424 loss: 0.024277112944750115\n",
            "batch: 425 loss: 0.024343576452462004\n",
            "batch: 426 loss: 0.024359766139416025\n",
            "batch: 427 loss: 0.02441830978426151\n",
            "batch: 428 loss: 0.02444278361531906\n",
            "batch: 429 loss: 0.024448020139476286\n",
            "batch: 430 loss: 0.024548337990185246\n",
            "batch: 431 loss: 0.024560998763656243\n",
            "batch: 432 loss: 0.024636125724529848\n",
            "batch: 433 loss: 0.02489115498564206\n",
            "batch: 434 loss: 0.024895458640763535\n",
            "batch: 435 loss: 0.024953826321521773\n",
            "batch: 436 loss: 0.02496565291681327\n",
            "batch: 437 loss: 0.024988596726441756\n",
            "batch: 438 loss: 0.025003281818935647\n",
            "batch: 439 loss: 0.025180335747310892\n",
            "batch: 440 loss: 0.02521219247789122\n",
            "batch: 441 loss: 0.02529059441597201\n",
            "batch: 442 loss: 0.025370598966488616\n",
            "batch: 443 loss: 0.025389333084458485\n",
            "batch: 444 loss: 0.025397701842943207\n",
            "batch: 445 loss: 0.02552815858856775\n",
            "batch: 446 loss: 0.025533942193025724\n",
            "batch: 447 loss: 0.02559535772749223\n",
            "batch: 448 loss: 0.025602540938416497\n",
            "batch: 449 loss: 0.025635733837494627\n",
            "batch: 450 loss: 0.025650541157694533\n",
            "batch: 451 loss: 0.02566611085203476\n",
            "batch: 452 loss: 0.025696004803525282\n",
            "batch: 453 loss: 0.02571192284603603\n",
            "batch: 454 loss: 0.025773152022855357\n",
            "batch: 455 loss: 0.02578610018105246\n",
            "batch: 456 loss: 0.02578971277992241\n",
            "batch: 457 loss: 0.025802075835643336\n",
            "batch: 458 loss: 0.025814525649650023\n",
            "batch: 459 loss: 0.025827513952506705\n",
            "batch: 460 loss: 0.025847794060362504\n",
            "batch: 461 loss: 0.025894993115914984\n",
            "batch: 462 loss: 0.026002418135059997\n",
            "batch: 463 loss: 0.026046264477772637\n",
            "batch: 464 loss: 0.026249769844813274\n",
            "batch: 465 loss: 0.026301494207931684\n",
            "batch: 466 loss: 0.02661818524892442\n",
            "batch: 467 loss: 0.026619789580116047\n",
            "batch: 468 loss: 0.026692077012965457\n",
            "batch: 469 loss: 0.026731556238839403\n",
            "batch: 470 loss: 0.026743405925342814\n",
            "batch: 471 loss: 0.026744923151447438\n",
            "batch: 472 loss: 0.026894839457585477\n",
            "batch: 473 loss: 0.026916316110058687\n",
            "batch: 474 loss: 0.026922776366001926\n",
            "batch: 475 loss: 0.02694551699643489\n",
            "batch: 476 loss: 0.027030097544542515\n",
            "batch: 477 loss: 0.027089115675888023\n",
            "batch: 478 loss: 0.027158289987943136\n",
            "batch: 479 loss: 0.027204222377738917\n",
            "batch: 480 loss: 0.02724477200245019\n",
            "batch: 481 loss: 0.02724730069551151\n",
            "batch: 482 loss: 0.02728765597555321\n",
            "batch: 483 loss: 0.027327326711150818\n",
            "batch: 484 loss: 0.027527454208466223\n",
            "batch: 485 loss: 0.02752974192413967\n",
            "batch: 486 loss: 0.027563421629252842\n",
            "batch: 487 loss: 0.027645504318061283\n",
            "batch: 488 loss: 0.02776450184721034\n",
            "batch: 489 loss: 0.027781866878154687\n",
            "batch: 490 loss: 0.02779721147182863\n",
            "batch: 491 loss: 0.02788206965837162\n",
            "batch: 492 loss: 0.027889342585927807\n",
            "batch: 493 loss: 0.027900668433285317\n",
            "batch: 494 loss: 0.02792713818734046\n",
            "batch: 495 loss: 0.027944341482943856\n",
            "batch: 496 loss: 0.02799650088918861\n",
            "batch: 497 loss: 0.028004318653023802\n",
            "batch: 498 loss: 0.028032308195135556\n",
            "batch: 499 loss: 0.028186011899611913\n",
            "batch: 500 loss: 0.0283738477419829\n",
            "batch: 501 loss: 0.028425701201311313\n",
            "batch: 502 loss: 0.028433274149312637\n",
            "batch: 503 loss: 0.028444677994935774\n",
            "batch: 504 loss: 0.028499773928313515\n",
            "batch: 505 loss: 0.028504671309492552\n",
            "batch: 506 loss: 0.02852900710736867\n",
            "batch: 507 loss: 0.028556716781458817\n",
            "batch: 508 loss: 0.028852958392701113\n",
            "batch: 509 loss: 0.02896344836463686\n",
            "batch: 510 loss: 0.029156836901209317\n",
            "batch: 511 loss: 0.029255891461274587\n",
            "batch: 512 loss: 0.02930825417896267\n",
            "batch: 513 loss: 0.02936754779925104\n",
            "batch: 514 loss: 0.029395751992589793\n",
            "batch: 515 loss: 0.02947546372783836\n",
            "batch: 516 loss: 0.029526646109647118\n",
            "batch: 517 loss: 0.029754365431494078\n",
            "batch: 518 loss: 0.029886291923350655\n",
            "batch: 519 loss: 0.029913239812827667\n",
            "batch: 520 loss: 0.029977959497249684\n",
            "batch: 521 loss: 0.03004839323309716\n",
            "batch: 522 loss: 0.030138073964393698\n",
            "batch: 523 loss: 0.030221432512975297\n",
            "batch: 524 loss: 0.03022460697835777\n",
            "batch: 525 loss: 0.030321398961008526\n",
            "batch: 526 loss: 0.030373289699316956\n",
            "batch: 527 loss: 0.030459864149452186\n",
            "batch: 528 loss: 0.030494053701520897\n",
            "batch: 529 loss: 0.03050465992896352\n",
            "batch: 530 loss: 0.030797167339012957\n",
            "batch: 531 loss: 0.031086056449101306\n",
            "batch: 532 loss: 0.03113809553592\n",
            "batch: 533 loss: 0.031151309918262995\n",
            "batch: 534 loss: 0.031170213004224935\n",
            "batch: 535 loss: 0.031195707466104068\n",
            "batch: 536 loss: 0.031234272893168963\n",
            "batch: 537 loss: 0.03149915590474848\n",
            "batch: 538 loss: 0.031645563047030006\n",
            "batch: 539 loss: 0.03167680644022766\n",
            "batch: 540 loss: 0.03169982056284789\n",
            "batch: 541 loss: 0.03176631890947465\n",
            "batch: 542 loss: 0.031787470947601836\n",
            "batch: 543 loss: 0.03196513941476587\n",
            "batch: 544 loss: 0.03211860495398287\n",
            "batch: 545 loss: 0.03216861502046231\n",
            "batch: 546 loss: 0.03218745205143932\n",
            "batch: 547 loss: 0.03240929653088097\n",
            "batch: 548 loss: 0.032522605109610594\n",
            "batch: 549 loss: 0.032585257004597225\n",
            "batch: 550 loss: 0.03286360798368696\n",
            "batch: 551 loss: 0.03286574185884092\n",
            "batch: 552 loss: 0.03290538048243616\n",
            "batch: 553 loss: 0.03292207979655359\n",
            "batch: 554 loss: 0.032924941729637794\n",
            "batch: 555 loss: 0.03296479747060221\n",
            "batch: 556 loss: 0.03297254204179626\n",
            "batch: 557 loss: 0.033096953319269234\n",
            "batch: 558 loss: 0.03320027216698509\n",
            "batch: 559 loss: 0.033358543539303356\n",
            "batch: 560 loss: 0.03354172057833057\n",
            "batch: 561 loss: 0.03354886169394013\n",
            "batch: 562 loss: 0.03367519777675625\n",
            "batch: 563 loss: 0.03367721314250957\n",
            "batch: 564 loss: 0.03368836175173055\n",
            "batch: 565 loss: 0.03369215220480692\n",
            "batch: 566 loss: 0.03373369739099871\n",
            "batch: 567 loss: 0.03376117896556389\n",
            "batch: 568 loss: 0.03376977367408108\n",
            "batch: 569 loss: 0.03385065115697216\n",
            "batch: 570 loss: 0.0338739556305809\n",
            "batch: 571 loss: 0.03395995979837608\n",
            "batch: 572 loss: 0.0339731670942856\n",
            "batch: 573 loss: 0.03402817012264859\n",
            "batch: 574 loss: 0.0340395686206175\n",
            "batch: 575 loss: 0.03410506019263994\n",
            "batch: 576 loss: 0.034126126657123675\n",
            "batch: 577 loss: 0.03413988619565498\n",
            "batch: 578 loss: 0.034165114366333\n",
            "batch: 579 loss: 0.03432622756890487\n",
            "batch: 580 loss: 0.034339176342706196\n",
            "batch: 581 loss: 0.034358546164701693\n",
            "batch: 582 loss: 0.034419036527047864\n",
            "batch: 583 loss: 0.0344571995184524\n",
            "batch: 584 loss: 0.03451840559102129\n",
            "batch: 585 loss: 0.034526587261701935\n",
            "batch: 586 loss: 0.03455698155879509\n",
            "batch: 587 loss: 0.0346195673000766\n",
            "batch: 588 loss: 0.03464553996070754\n",
            "batch: 589 loss: 0.03466259638301562\n",
            "batch: 590 loss: 0.034684790865401736\n",
            "batch: 591 loss: 0.03470597150258254\n",
            "batch: 592 loss: 0.03473706612631213\n",
            "batch: 593 loss: 0.034808137110318056\n",
            "batch: 594 loss: 0.034901565058971754\n",
            "batch: 595 loss: 0.035072730853105895\n",
            "batch: 596 loss: 0.03509714415192138\n",
            "batch: 597 loss: 0.035133301320369355\n",
            "batch: 598 loss: 0.035161188975791444\n",
            "batch: 599 loss: 0.03519888901792001\n",
            "batch: 600 loss: 0.035210817049141044\n",
            "batch: 601 loss: 0.03522541141405236\n",
            "batch: 602 loss: 0.035253555080736985\n",
            "batch: 603 loss: 0.03526397587440442\n",
            "batch: 604 loss: 0.03527481004304718\n",
            "batch: 605 loss: 0.035326078348676675\n",
            "batch: 606 loss: 0.03550154789618682\n",
            "batch: 607 loss: 0.0355538908772869\n",
            "batch: 608 loss: 0.03560915472439956\n",
            "batch: 609 loss: 0.03571468150697183\n",
            "batch: 610 loss: 0.03577340336970519\n",
            "batch: 611 loss: 0.03579421584762167\n",
            "batch: 612 loss: 0.03581477208144497\n",
            "batch: 613 loss: 0.03587276867113542\n",
            "batch: 614 loss: 0.03590358868322801\n",
            "batch: 615 loss: 0.035933625594596376\n",
            "batch: 616 loss: 0.035948940573143774\n",
            "batch: 617 loss: 0.03604911634128075\n",
            "batch: 618 loss: 0.036059574874001556\n",
            "batch: 619 loss: 0.036094742650049735\n",
            "batch: 620 loss: 0.03612465097743552\n",
            "batch: 621 loss: 0.03628549452859443\n",
            "batch: 622 loss: 0.036340013351175\n",
            "batch: 623 loss: 0.03640055004123133\n",
            "batch: 624 loss: 0.03650481643143576\n",
            "batch: 625 loss: 0.03666619560483377\n",
            "batch: 626 loss: 0.03674342961970251\n",
            "batch: 627 loss: 0.03676857661630493\n",
            "batch: 628 loss: 0.03680192038591486\n",
            "batch: 629 loss: 0.036808638857561166\n",
            "batch: 630 loss: 0.03683140920836013\n",
            "batch: 631 loss: 0.03684812514844816\n",
            "batch: 632 loss: 0.03697677058342379\n",
            "batch: 633 loss: 0.03701450986030977\n",
            "batch: 634 loss: 0.037016686856397425\n",
            "batch: 635 loss: 0.037164987131603995\n",
            "batch: 636 loss: 0.03722100792790298\n",
            "batch: 637 loss: 0.03722959831322078\n",
            "batch: 638 loss: 0.037270285408594644\n",
            "batch: 639 loss: 0.03728666127438191\n",
            "batch: 640 loss: 0.03733245519886259\n",
            "batch: 641 loss: 0.03735280085692648\n",
            "batch: 642 loss: 0.03736771891138051\n",
            "batch: 643 loss: 0.03739129962644074\n",
            "batch: 644 loss: 0.03748807454726193\n",
            "batch: 645 loss: 0.03749641395418439\n",
            "batch: 646 loss: 0.0375129800910363\n",
            "batch: 647 loss: 0.03765279443806503\n",
            "batch: 648 loss: 0.037724552492261865\n",
            "batch: 649 loss: 0.0377902652794728\n",
            "batch: 650 loss: 0.03780286990909371\n",
            "batch: 651 loss: 0.0378776159590343\n",
            "batch: 652 loss: 0.03789895282371435\n",
            "batch: 653 loss: 0.037908379747183064\n",
            "batch: 654 loss: 0.03811289168766234\n",
            "batch: 655 loss: 0.03828238449862693\n",
            "batch: 656 loss: 0.03829844951315317\n",
            "batch: 657 loss: 0.038375293326214886\n",
            "batch: 658 loss: 0.03846769454760943\n",
            "batch: 659 loss: 0.03847436407452915\n",
            "batch: 660 loss: 0.03860518326109741\n",
            "batch: 661 loss: 0.038658101713866924\n",
            "batch: 662 loss: 0.03872561505308841\n",
            "batch: 663 loss: 0.03893318790069315\n",
            "batch: 664 loss: 0.03896973956248257\n",
            "batch: 665 loss: 0.03898102610709611\n",
            "batch: 666 loss: 0.03899051370716188\n",
            "batch: 667 loss: 0.03899743824184407\n",
            "batch: 668 loss: 0.03913748214126099\n",
            "batch: 669 loss: 0.039265786250238306\n",
            "batch: 670 loss: 0.039273405544576236\n",
            "batch: 671 loss: 0.03929294691432733\n",
            "batch: 672 loss: 0.03948479836632032\n",
            "batch: 673 loss: 0.039489705457468514\n",
            "batch: 674 loss: 0.039505716479499825\n",
            "batch: 675 loss: 0.039513178774272094\n",
            "batch: 676 loss: 0.03954964854673017\n",
            "batch: 677 loss: 0.03959602727100719\n",
            "batch: 678 loss: 0.03960124502016697\n",
            "batch: 679 loss: 0.03969194354547653\n",
            "batch: 680 loss: 0.03976085485203657\n",
            "batch: 681 loss: 0.03996679173095617\n",
            "batch: 682 loss: 0.04019841095490847\n",
            "batch: 683 loss: 0.04047007625980768\n",
            "batch: 684 loss: 0.040492246805340984\n",
            "batch: 685 loss: 0.040527352063567376\n",
            "batch: 686 loss: 0.04053086038131733\n",
            "batch: 687 loss: 0.040602649750304406\n",
            "batch: 688 loss: 0.0406260545385303\n",
            "batch: 689 loss: 0.040657752448809335\n",
            "batch: 690 loss: 0.04066119610762689\n",
            "batch: 691 loss: 0.04067643356008921\n",
            "batch: 692 loss: 0.040682557229534726\n",
            "batch: 693 loss: 0.04072105071379337\n",
            "batch: 694 loss: 0.04072617196070496\n",
            "batch: 695 loss: 0.040843777333968316\n",
            "batch: 696 loss: 0.0408664010145003\n",
            "batch: 697 loss: 0.040873937520314936\n",
            "batch: 698 loss: 0.04087742430635262\n",
            "batch: 699 loss: 0.04103595057793427\n",
            "batch: 700 loss: 0.041057376301963815\n",
            "batch: 701 loss: 0.04116612603433896\n",
            "batch: 702 loss: 0.04127724363573361\n",
            "batch: 703 loss: 0.041318984001060016\n",
            "batch: 704 loss: 0.041324837736436165\n",
            "batch: 705 loss: 0.04145719677919987\n",
            "batch: 706 loss: 0.04157548762077931\n",
            "batch: 707 loss: 0.04165235983545426\n",
            "batch: 708 loss: 0.04167173685843591\n",
            "batch: 709 loss: 0.04171815587545279\n",
            "batch: 710 loss: 0.041751023262389934\n",
            "batch: 711 loss: 0.0420328846272314\n",
            "batch: 712 loss: 0.04213917339558247\n",
            "batch: 713 loss: 0.04214583858952392\n",
            "batch: 714 loss: 0.04228024271235336\n",
            "batch: 715 loss: 0.04231095916323829\n",
            "batch: 716 loss: 0.0423376536621945\n",
            "batch: 717 loss: 0.04235814298235346\n",
            "batch: 718 loss: 0.04236977823183406\n",
            "batch: 719 loss: 0.04237272972764913\n",
            "batch: 720 loss: 0.04237649325642269\n",
            "batch: 721 loss: 0.042580758225056345\n",
            "batch: 722 loss: 0.042643629442784006\n",
            "batch: 723 loss: 0.042662934530409986\n",
            "batch: 724 loss: 0.04272414791572374\n",
            "batch: 725 loss: 0.042837644994142464\n",
            "batch: 726 loss: 0.042841763023170644\n",
            "batch: 727 loss: 0.04295461406174581\n",
            "batch: 728 loss: 0.04298117963585537\n",
            "batch: 729 loss: 0.04308084394398611\n",
            "batch: 730 loss: 0.04318833034101408\n",
            "batch: 731 loss: 0.04321030949603301\n",
            "batch: 732 loss: 0.0432157515612198\n",
            "batch: 733 loss: 0.04342235568433534\n",
            "batch: 734 loss: 0.04342466738203075\n",
            "batch: 735 loss: 0.04351604171225335\n",
            "batch: 736 loss: 0.043699734629481096\n",
            "batch: 737 loss: 0.04376101889589336\n",
            "batch: 738 loss: 0.0439326732394984\n",
            "batch: 739 loss: 0.04393734430556651\n",
            "batch: 740 loss: 0.043952637359849174\n",
            "batch: 741 loss: 0.04395446871209424\n",
            "batch: 742 loss: 0.044025595463695937\n",
            "batch: 743 loss: 0.044043538313242606\n",
            "batch: 744 loss: 0.04404592643736396\n",
            "batch: 745 loss: 0.044195325837121345\n",
            "batch: 746 loss: 0.04421548583975527\n",
            "batch: 747 loss: 0.04424456793128047\n",
            "batch: 748 loss: 0.044308021680102685\n",
            "batch: 749 loss: 0.04448621147929225\n",
            "batch: 750 loss: 0.04455972074030433\n",
            "batch: 751 loss: 0.044588196930126285\n",
            "batch: 752 loss: 0.04461315510852728\n",
            "batch: 753 loss: 0.04466660704149399\n",
            "batch: 754 loss: 0.04468028460314963\n",
            "batch: 755 loss: 0.04482768271735404\n",
            "batch: 756 loss: 0.04510912774375174\n",
            "batch: 757 loss: 0.045115914902300575\n",
            "batch: 758 loss: 0.045141900316462855\n",
            "batch: 759 loss: 0.04514696267165709\n",
            "batch: 760 loss: 0.04523866917111445\n",
            "batch: 761 loss: 0.045266332791303286\n",
            "batch: 762 loss: 0.045298590102349406\n",
            "batch: 763 loss: 0.045304042826523075\n",
            "batch: 764 loss: 0.04535920471989084\n",
            "batch: 765 loss: 0.04543030827783514\n",
            "batch: 766 loss: 0.0454414797622012\n",
            "batch: 767 loss: 0.045533443880383856\n",
            "batch: 768 loss: 0.04556860220164526\n",
            "batch: 769 loss: 0.045776172069017775\n",
            "batch: 770 loss: 0.046041799512808214\n",
            "batch: 771 loss: 0.0460967286239611\n",
            "batch: 772 loss: 0.04619834476069082\n",
            "batch: 773 loss: 0.04624703176796902\n",
            "batch: 774 loss: 0.04627152782783378\n",
            "batch: 775 loss: 0.046276148554985415\n",
            "batch: 776 loss: 0.046290125169907693\n",
            "batch: 777 loss: 0.04647669331089128\n",
            "batch: 778 loss: 0.04648697385948617\n",
            "batch: 779 loss: 0.04656684090208728\n",
            "batch: 780 loss: 0.04661088687193114\n",
            "batch: 781 loss: 0.046634262982872314\n",
            "batch: 782 loss: 0.046656199755263514\n",
            "batch: 783 loss: 0.04668092308950145\n",
            "batch: 784 loss: 0.046878030657884665\n",
            "batch: 785 loss: 0.046900533817824906\n",
            "batch: 786 loss: 0.04697443627577741\n",
            "batch: 787 loss: 0.047060309678432534\n",
            "batch: 788 loss: 0.047110418614116495\n",
            "batch: 789 loss: 0.04711453877540771\n",
            "batch: 790 loss: 0.04715564467536751\n",
            "batch: 791 loss: 0.04718413409742061\n",
            "batch: 792 loss: 0.047215540455305016\n",
            "batch: 793 loss: 0.04722135060152505\n",
            "batch: 794 loss: 0.04735738091787789\n",
            "batch: 795 loss: 0.047416854961425996\n",
            "batch: 796 loss: 0.04742446646944154\n",
            "batch: 797 loss: 0.0475116485740291\n",
            "batch: 798 loss: 0.047632836693082936\n",
            "batch: 799 loss: 0.04768003448203672\n",
            "batch: 800 loss: 0.047686837981571445\n",
            "batch: 801 loss: 0.04788882897340227\n",
            "batch: 802 loss: 0.04802164971374441\n",
            "batch: 803 loss: 0.04808183206163812\n",
            "batch: 804 loss: 0.048090060315211305\n",
            "batch: 805 loss: 0.04809522252168972\n",
            "batch: 806 loss: 0.04816675831016619\n",
            "batch: 807 loss: 0.04821154050540645\n",
            "batch: 808 loss: 0.04822424339607824\n",
            "batch: 809 loss: 0.048232613307540306\n",
            "batch: 810 loss: 0.048304357853834516\n",
            "batch: 811 loss: 0.04831702911213506\n",
            "batch: 812 loss: 0.04832357592426706\n",
            "batch: 813 loss: 0.04832521736598574\n",
            "batch: 814 loss: 0.04849418424046598\n",
            "batch: 815 loss: 0.04857859432674013\n",
            "batch: 816 loss: 0.04860642809583805\n",
            "batch: 817 loss: 0.04863336837827228\n",
            "batch: 818 loss: 0.04875545906065963\n",
            "batch: 819 loss: 0.04877168216346763\n",
            "batch: 820 loss: 0.04910040821670555\n",
            "batch: 821 loss: 0.04917839477001689\n",
            "batch: 822 loss: 0.0493999936634209\n",
            "batch: 823 loss: 0.049425242621218786\n",
            "batch: 824 loss: 0.049450734544312584\n",
            "batch: 825 loss: 0.04950927150598727\n",
            "batch: 826 loss: 0.04959868943295442\n",
            "batch: 827 loss: 0.049696627039229495\n",
            "batch: 828 loss: 0.04969980300217867\n",
            "batch: 829 loss: 0.04973136749118567\n",
            "batch: 830 loss: 0.049738075714558364\n",
            "batch: 831 loss: 0.04975600873306393\n",
            "batch: 832 loss: 0.04976642913557589\n",
            "batch: 833 loss: 0.049961659917607905\n",
            "batch: 834 loss: 0.049978372577577826\n",
            "batch: 835 loss: 0.04998318738257512\n",
            "batch: 836 loss: 0.05002354272222147\n",
            "batch: 837 loss: 0.05024231546139345\n",
            "batch: 838 loss: 0.05027780082216486\n",
            "batch: 839 loss: 0.05033236648282036\n",
            "batch: 840 loss: 0.0505010978593491\n",
            "batch: 841 loss: 0.05050403633550741\n",
            "batch: 842 loss: 0.050646945474902165\n",
            "batch: 843 loss: 0.05075793601409532\n",
            "batch: 844 loss: 0.05079675724194385\n",
            "batch: 845 loss: 0.050922774916747585\n",
            "batch: 846 loss: 0.0509640770687256\n",
            "batch: 847 loss: 0.05106316630379297\n",
            "batch: 848 loss: 0.05106868028896861\n",
            "batch: 849 loss: 0.05109928266587667\n",
            "batch: 850 loss: 0.0512341872442048\n",
            "batch: 851 loss: 0.05123711639875546\n",
            "batch: 852 loss: 0.051321139591280374\n",
            "batch: 853 loss: 0.05133267505420372\n",
            "batch: 854 loss: 0.05138610663963482\n",
            "batch: 855 loss: 0.05142081545246765\n",
            "batch: 856 loss: 0.051469361289869994\n",
            "batch: 857 loss: 0.05148775882041082\n",
            "batch: 858 loss: 0.05151834161719307\n",
            "batch: 859 loss: 0.05153090778505429\n",
            "batch: 860 loss: 0.05157230064412579\n",
            "batch: 861 loss: 0.05157582309935242\n",
            "batch: 862 loss: 0.051697900087572635\n",
            "batch: 863 loss: 0.051727569916285576\n",
            "batch: 864 loss: 0.05175396103318781\n",
            "batch: 865 loss: 0.05191399785038084\n",
            "batch: 866 loss: 0.051931700003333386\n",
            "batch: 867 loss: 0.05196511140558869\n",
            "batch: 868 loss: 0.05228236329648644\n",
            "batch: 869 loss: 0.052322454140521585\n",
            "batch: 870 loss: 0.05233228124212474\n",
            "batch: 871 loss: 0.05233880695607513\n",
            "batch: 872 loss: 0.05253175607230514\n",
            "batch: 873 loss: 0.05258648769464344\n",
            "batch: 874 loss: 0.0526036939388141\n",
            "batch: 875 loss: 0.05262025742512196\n",
            "batch: 876 loss: 0.05263545023556799\n",
            "batch: 877 loss: 0.0527283237343654\n",
            "batch: 878 loss: 0.05275132969301194\n",
            "batch: 879 loss: 0.05283416769187897\n",
            "batch: 880 loss: 0.05290703825931996\n",
            "batch: 881 loss: 0.05293569757137448\n",
            "batch: 882 loss: 0.05303300214651972\n",
            "batch: 883 loss: 0.05306596476677805\n",
            "batch: 884 loss: 0.05310071310494095\n",
            "batch: 885 loss: 0.05313010847289115\n",
            "batch: 886 loss: 0.05313402750715614\n",
            "batch: 887 loss: 0.05314204301312566\n",
            "batch: 888 loss: 0.053192429352551696\n",
            "batch: 889 loss: 0.05320633061882109\n",
            "batch: 890 loss: 0.05322587980981916\n",
            "batch: 891 loss: 0.053239344161935154\n",
            "batch: 892 loss: 0.053320507225580516\n",
            "batch: 893 loss: 0.053354349088855085\n",
            "batch: 894 loss: 0.05338024827931076\n",
            "batch: 895 loss: 0.05343192650470883\n",
            "batch: 896 loss: 0.05343984836898744\n",
            "batch: 897 loss: 0.053471167525276544\n",
            "batch: 898 loss: 0.05347472990048118\n",
            "batch: 899 loss: 0.053511035260977224\n",
            "batch: 900 loss: 0.05352319933963008\n",
            "batch: 901 loss: 0.05352986801997758\n",
            "batch: 902 loss: 0.05354688825481571\n",
            "batch: 903 loss: 0.05356823407509364\n",
            "batch: 904 loss: 0.053720362324500455\n",
            "batch: 905 loss: 0.05373617040761747\n",
            "batch: 906 loss: 0.05373929592850618\n",
            "batch: 907 loss: 0.053770635260967536\n",
            "batch: 908 loss: 0.05382294025900774\n",
            "batch: 909 loss: 0.05389454294624738\n",
            "batch: 910 loss: 0.053915021455613894\n",
            "batch: 911 loss: 0.05408465243014507\n",
            "batch: 912 loss: 0.054102610043017196\n",
            "batch: 913 loss: 0.05412738936278038\n",
            "batch: 914 loss: 0.05421470557781868\n",
            "batch: 915 loss: 0.05422534883930348\n",
            "batch: 916 loss: 0.05438082433654927\n",
            "batch: 917 loss: 0.05439146745274775\n",
            "batch: 918 loss: 0.05448949748347513\n",
            "batch: 919 loss: 0.05449482521950267\n",
            "batch: 920 loss: 0.05452358157164417\n",
            "batch: 921 loss: 0.054713362224167214\n",
            "batch: 922 loss: 0.054730487575521694\n",
            "batch: 923 loss: 0.054767417354276406\n",
            "batch: 924 loss: 0.05477063113451004\n",
            "batch: 925 loss: 0.05486770562827587\n",
            "batch: 926 loss: 0.054988308615982535\n",
            "batch: 927 loss: 0.05500189441442489\n",
            "batch: 928 loss: 0.05503458261489868\n",
            "batch: 929 loss: 0.05507753351330757\n",
            "batch: 930 loss: 0.0550844343197532\n",
            "batch: 931 loss: 0.05512478189589456\n",
            "batch: 932 loss: 0.05514071334572509\n",
            "batch: 933 loss: 0.055234077532310036\n",
            "batch: 934 loss: 0.0554412423861213\n",
            "batch: 935 loss: 0.05544706341251731\n",
            "batch: 936 loss: 0.05547242052108049\n",
            "batch: 937 loss: 0.055533388510346414\n",
            "batch: 938 loss: 0.05557834732159972\n",
            "batch: 939 loss: 0.05559892816469073\n",
            "batch: 940 loss: 0.05563606286421418\n",
            "batch: 941 loss: 0.0557511502020061\n",
            "batch: 942 loss: 0.055763982200995085\n",
            "batch: 943 loss: 0.055793170304968956\n",
            "batch: 944 loss: 0.05580335469264537\n",
            "batch: 945 loss: 0.05582252006512135\n",
            "batch: 946 loss: 0.05583219746407121\n",
            "batch: 947 loss: 0.056002787268720565\n",
            "batch: 948 loss: 0.05601140643004328\n",
            "batch: 949 loss: 0.05603408883791417\n",
            "batch: 950 loss: 0.05617259307485074\n",
            "batch: 951 loss: 0.05626618325244635\n",
            "batch: 952 loss: 0.05627958130463958\n",
            "batch: 953 loss: 0.05628129741747398\n",
            "batch: 954 loss: 0.056302601887029596\n",
            "batch: 955 loss: 0.05632775462430436\n",
            "batch: 956 loss: 0.05633329952054191\n",
            "batch: 957 loss: 0.05635868702561129\n",
            "batch: 958 loss: 0.056359778348938565\n",
            "batch: 959 loss: 0.056363449510768986\n",
            "batch: 960 loss: 0.05651246845407877\n",
            "batch: 961 loss: 0.056624814238981344\n",
            "batch: 962 loss: 0.05667123305855785\n",
            "batch: 963 loss: 0.05686396801529918\n",
            "batch: 964 loss: 0.05697600720881019\n",
            "batch: 965 loss: 0.05698830387333874\n",
            "batch: 966 loss: 0.05699842612317298\n",
            "batch: 967 loss: 0.057005637095426206\n",
            "batch: 968 loss: 0.05703701348335016\n",
            "batch: 969 loss: 0.05711316542059649\n",
            "batch: 970 loss: 0.05713366555899847\n",
            "batch: 971 loss: 0.05714240844000597\n",
            "batch: 972 loss: 0.057225507402908986\n",
            "batch: 973 loss: 0.057241493292269297\n",
            "batch: 974 loss: 0.05727294235315639\n",
            "batch: 975 loss: 0.05735368119564373\n",
            "batch: 976 loss: 0.05735564683901612\n",
            "batch: 977 loss: 0.05737239751184825\n",
            "batch: 978 loss: 0.05742336200515274\n",
            "batch: 979 loss: 0.057486270356574096\n",
            "batch: 980 loss: 0.05754838079179171\n",
            "batch: 981 loss: 0.057580160189070737\n",
            "batch: 982 loss: 0.057610193259664814\n",
            "batch: 983 loss: 0.05762088563165162\n",
            "batch: 984 loss: 0.05782268869003747\n",
            "batch: 985 loss: 0.05783110264095012\n",
            "batch: 986 loss: 0.057933941052877344\n",
            "batch: 987 loss: 0.05794488727359567\n",
            "batch: 988 loss: 0.05811599316506181\n",
            "batch: 989 loss: 0.058124616940156554\n",
            "batch: 990 loss: 0.05813824935781304\n",
            "batch: 991 loss: 0.05822896094399039\n",
            "batch: 992 loss: 0.058235014084377326\n",
            "batch: 993 loss: 0.05830997115711216\n",
            "batch: 994 loss: 0.058317370693781415\n",
            "batch: 995 loss: 0.058364030886092225\n",
            "batch: 996 loss: 0.05838414745929185\n",
            "batch: 997 loss: 0.05840126236306969\n",
            "batch: 998 loss: 0.05854330952989403\n",
            "batch: 1000 loss: 0.05869310077803675\n",
            "batch: 1001 loss: 0.05884685984032694\n",
            "batch: 1002 loss: 0.0589921821631724\n",
            "batch: 1003 loss: 0.05900724763574544\n",
            "batch: 1004 loss: 0.0591458723336691\n",
            "batch: 1005 loss: 0.05923378973605577\n",
            "batch: 1006 loss: 0.059381956064724364\n",
            "batch: 1007 loss: 0.05940506041573826\n",
            "batch: 1008 loss: 0.059548487549298444\n",
            "batch: 1009 loss: 0.05965681668894831\n",
            "batch: 1010 loss: 0.05969515529053751\n",
            "batch: 1011 loss: 0.059704573486582375\n",
            "batch: 1012 loss: 0.05972242203785572\n",
            "batch: 1013 loss: 0.05975486824347172\n",
            "batch: 1014 loss: 0.05986387294961605\n",
            "batch: 1015 loss: 0.05987992255075369\n",
            "batch: 1016 loss: 0.05993288271559868\n",
            "batch: 1017 loss: 0.060045046788291076\n",
            "batch: 1018 loss: 0.06010598976595793\n",
            "batch: 1019 loss: 0.06022686908824835\n",
            "batch: 1020 loss: 0.06024367905652616\n",
            "batch: 1021 loss: 0.06046501200890634\n",
            "batch: 1022 loss: 0.06053588799631689\n",
            "batch: 1023 loss: 0.06056709765701089\n",
            "batch: 1024 loss: 0.06058154501079116\n",
            "batch: 1025 loss: 0.06066233306436334\n",
            "batch: 1026 loss: 0.06093258791475091\n",
            "batch: 1027 loss: 0.061117227279231884\n",
            "batch: 1028 loss: 0.06125316081254278\n",
            "batch: 1029 loss: 0.06133386294601951\n",
            "batch: 1030 loss: 0.06134020962717477\n",
            "batch: 1031 loss: 0.06140978329034988\n",
            "batch: 1032 loss: 0.06142844850907568\n",
            "batch: 1033 loss: 0.0614912523884559\n",
            "batch: 1034 loss: 0.06164938839862589\n",
            "batch: 1035 loss: 0.06165433532663155\n",
            "batch: 1036 loss: 0.06166858538344968\n",
            "batch: 1037 loss: 0.06175454387173522\n",
            "batch: 1038 loss: 0.06177847195335198\n",
            "batch: 1039 loss: 0.06201333507068921\n",
            "batch: 1040 loss: 0.062025580425863154\n",
            "batch: 1041 loss: 0.06209281313151587\n",
            "batch: 1042 loss: 0.06222033534676302\n",
            "batch: 1043 loss: 0.062392291364376434\n",
            "batch: 1044 loss: 0.06247056208283175\n",
            "batch: 1045 loss: 0.06247792206436861\n",
            "batch: 1046 loss: 0.06248133231850807\n",
            "batch: 1047 loss: 0.062497605194919745\n",
            "batch: 1048 loss: 0.062514266233542\n",
            "batch: 1049 loss: 0.06251949606800918\n",
            "batch: 1050 loss: 0.06258860737050417\n",
            "batch: 1051 loss: 0.06261269077623728\n",
            "batch: 1052 loss: 0.06275720652902965\n",
            "batch: 1053 loss: 0.06289975592459086\n",
            "batch: 1054 loss: 0.06364384177292232\n",
            "batch: 1055 loss: 0.06365343351813499\n",
            "batch: 1056 loss: 0.06371694760920946\n",
            "batch: 1057 loss: 0.06372794736607466\n",
            "batch: 1058 loss: 0.06376305484084878\n",
            "batch: 1059 loss: 0.06389415255992208\n",
            "batch: 1060 loss: 0.06393752507923636\n",
            "batch: 1061 loss: 0.06408999404369388\n",
            "batch: 1062 loss: 0.06409746820677538\n",
            "batch: 1063 loss: 0.06414759550441522\n",
            "batch: 1064 loss: 0.06423658643860836\n",
            "batch: 1065 loss: 0.06435665743995923\n",
            "batch: 1066 loss: 0.06437749033991713\n",
            "batch: 1067 loss: 0.06437977082876023\n",
            "batch: 1068 loss: 0.06442147248832043\n",
            "batch: 1069 loss: 0.06442341397388372\n",
            "batch: 1070 loss: 0.06443953437788878\n",
            "batch: 1071 loss: 0.06445237155503128\n",
            "batch: 1072 loss: 0.06447606920695398\n",
            "batch: 1073 loss: 0.0645237939717481\n",
            "batch: 1074 loss: 0.06459733515849803\n",
            "batch: 1075 loss: 0.06463768662011717\n",
            "batch: 1076 loss: 0.06465265893156175\n",
            "batch: 1077 loss: 0.06475595636630896\n",
            "batch: 1078 loss: 0.06490108926559333\n",
            "batch: 1079 loss: 0.06491034367179964\n",
            "batch: 1080 loss: 0.06496145665517543\n",
            "batch: 1081 loss: 0.0649900688311318\n",
            "batch: 1082 loss: 0.06501852911582683\n",
            "batch: 1083 loss: 0.06502883163897787\n",
            "batch: 1084 loss: 0.06509493862895761\n",
            "batch: 1085 loss: 0.06510738834238146\n",
            "batch: 1086 loss: 0.06554702087736222\n",
            "batch: 1087 loss: 0.06566860828048084\n",
            "batch: 1088 loss: 0.06569212808331941\n",
            "batch: 1089 loss: 0.06572548542416189\n",
            "batch: 1090 loss: 0.06573091939475853\n",
            "batch: 1091 loss: 0.0657791478933068\n",
            "batch: 1092 loss: 0.06584612235438544\n",
            "batch: 1093 loss: 0.06587707633164246\n",
            "batch: 1094 loss: 0.06597939448442776\n",
            "batch: 1095 loss: 0.0659838192408206\n",
            "batch: 1096 loss: 0.06610259507794398\n",
            "batch: 1097 loss: 0.06617750702996272\n",
            "batch: 1098 loss: 0.06621853850607294\n",
            "batch: 1099 loss: 0.06622663233533967\n",
            "batch: 1100 loss: 0.06625191285752226\n",
            "batch: 1101 loss: 0.06626433508575429\n",
            "batch: 1102 loss: 0.0662796643312322\n",
            "batch: 1103 loss: 0.06631083796278107\n",
            "batch: 1104 loss: 0.0664056840549456\n",
            "batch: 1105 loss: 0.06643322946422267\n",
            "batch: 1106 loss: 0.0664764262988465\n",
            "batch: 1107 loss: 0.0664807956191944\n",
            "batch: 1108 loss: 0.06649456963327248\n",
            "batch: 1109 loss: 0.06662339103606064\n",
            "batch: 1110 loss: 0.06669748191174585\n",
            "batch: 1111 loss: 0.0667547835559817\n",
            "batch: 1112 loss: 0.06686516714107711\n",
            "batch: 1113 loss: 0.06687053249182645\n",
            "batch: 1114 loss: 0.06706443568470422\n",
            "batch: 1115 loss: 0.06710531117545906\n",
            "batch: 1116 loss: 0.06711158498900477\n",
            "batch: 1117 loss: 0.06716406448709313\n",
            "batch: 1118 loss: 0.06716942135582213\n",
            "batch: 1119 loss: 0.06718131139653269\n",
            "batch: 1120 loss: 0.06721381050872151\n",
            "batch: 1121 loss: 0.06722715252137278\n",
            "batch: 1122 loss: 0.06727121154090855\n",
            "batch: 1123 loss: 0.06735031051805708\n",
            "batch: 1124 loss: 0.0673549335898133\n",
            "batch: 1125 loss: 0.06747255028795916\n",
            "batch: 1126 loss: 0.06756124033790548\n",
            "batch: 1127 loss: 0.06764631851774175\n",
            "batch: 1128 loss: 0.0677955405638786\n",
            "batch: 1129 loss: 0.06781158850726206\n",
            "batch: 1130 loss: 0.06782583065528888\n",
            "batch: 1131 loss: 0.06783784089807887\n",
            "batch: 1132 loss: 0.0678412157642888\n",
            "batch: 1133 loss: 0.0678513452411862\n",
            "batch: 1134 loss: 0.06786347426485737\n",
            "batch: 1135 loss: 0.06787085683515762\n",
            "batch: 1136 loss: 0.06791753567999695\n",
            "batch: 1137 loss: 0.06793480239866767\n",
            "batch: 1138 loss: 0.06798562257050071\n",
            "batch: 1139 loss: 0.06806315832643305\n",
            "batch: 1140 loss: 0.06811578180699143\n",
            "batch: 1141 loss: 0.06824717029242311\n",
            "batch: 1142 loss: 0.06840081306605134\n",
            "batch: 1143 loss: 0.06842432166135404\n",
            "batch: 1144 loss: 0.06854674601054285\n",
            "batch: 1145 loss: 0.06861278105026576\n",
            "batch: 1146 loss: 0.06861775698571\n",
            "batch: 1147 loss: 0.06862225817341823\n",
            "batch: 1148 loss: 0.06863440693367738\n",
            "batch: 1149 loss: 0.06866119195532519\n",
            "batch: 1150 loss: 0.06866785862168763\n",
            "batch: 1151 loss: 0.06875368532410357\n",
            "batch: 1152 loss: 0.06880148994422051\n",
            "batch: 1153 loss: 0.06882841182372067\n",
            "batch: 1154 loss: 0.06897516169270966\n",
            "batch: 1155 loss: 0.06914366195222829\n",
            "batch: 1156 loss: 0.0691537352638552\n",
            "batch: 1157 loss: 0.06917443019768689\n",
            "batch: 1158 loss: 0.06924640669545624\n",
            "batch: 1159 loss: 0.06953061436733697\n",
            "batch: 1160 loss: 0.06978813143691513\n",
            "batch: 1161 loss: 0.06993674335500691\n",
            "batch: 1162 loss: 0.06996232202521059\n",
            "batch: 1163 loss: 0.06999053475877735\n",
            "batch: 1164 loss: 0.07000285887962673\n",
            "batch: 1165 loss: 0.07011417034512851\n",
            "batch: 1166 loss: 0.0701227403037483\n",
            "batch: 1167 loss: 0.07013039639929775\n",
            "batch: 1168 loss: 0.07015187683480326\n",
            "batch: 1169 loss: 0.070191208457225\n",
            "batch: 1170 loss: 0.07025853397476022\n",
            "batch: 1171 loss: 0.07025961530790664\n",
            "batch: 1172 loss: 0.0703100542484317\n",
            "batch: 1173 loss: 0.0704363678751979\n",
            "batch: 1174 loss: 0.0705982708542142\n",
            "batch: 1175 loss: 0.07067580994800665\n",
            "batch: 1176 loss: 0.07069095314876177\n",
            "batch: 1177 loss: 0.07082475004927255\n",
            "batch: 1178 loss: 0.07083365962584504\n",
            "batch: 1179 loss: 0.07096822563488968\n",
            "batch: 1180 loss: 0.07097092279721982\n",
            "batch: 1181 loss: 0.07099092906271108\n",
            "batch: 1182 loss: 0.07099662124388852\n",
            "batch: 1183 loss: 0.07108568199002184\n",
            "batch: 1184 loss: 0.07109286280092783\n",
            "batch: 1185 loss: 0.07113267715391702\n",
            "batch: 1186 loss: 0.07118458019313402\n",
            "batch: 1187 loss: 0.07126187549647875\n",
            "batch: 1188 loss: 0.07133096561697312\n",
            "batch: 1189 loss: 0.07141370009747333\n",
            "batch: 1190 loss: 0.07147577141341753\n",
            "batch: 1191 loss: 0.07147856238950044\n",
            "batch: 1192 loss: 0.07150632261205464\n",
            "batch: 1193 loss: 0.07156133808661252\n",
            "batch: 1194 loss: 0.0716292329626158\n",
            "batch: 1195 loss: 0.07163275811565109\n",
            "batch: 1196 loss: 0.07165649318438955\n",
            "batch: 1197 loss: 0.07172250846517272\n",
            "batch: 1198 loss: 0.07175096824136562\n",
            "batch: 1199 loss: 0.07183450207230635\n",
            "batch: 1200 loss: 0.07191547804442235\n",
            "batch: 1201 loss: 0.07193494149413891\n",
            "batch: 1202 loss: 0.07216289495793171\n",
            "batch: 1203 loss: 0.07219875904289075\n",
            "batch: 1204 loss: 0.07222700511780568\n",
            "batch: 1205 loss: 0.07223343233275227\n",
            "batch: 1206 loss: 0.07226253225351684\n",
            "batch: 1207 loss: 0.07227641300181858\n",
            "batch: 1208 loss: 0.07242707108776085\n",
            "batch: 1209 loss: 0.07250735613773576\n",
            "batch: 1210 loss: 0.0725244630749803\n",
            "batch: 1211 loss: 0.07253089892561547\n",
            "batch: 1212 loss: 0.0725505718390923\n",
            "batch: 1213 loss: 0.07261414031195454\n",
            "batch: 1214 loss: 0.07262198627437465\n",
            "batch: 1215 loss: 0.07271590008283965\n",
            "batch: 1216 loss: 0.072958446939243\n",
            "batch: 1217 loss: 0.07296372407651507\n",
            "batch: 1218 loss: 0.07298523005074821\n",
            "batch: 1219 loss: 0.0729925145979505\n",
            "batch: 1220 loss: 0.07301314130867831\n",
            "batch: 1221 loss: 0.0730172554703895\n",
            "batch: 1222 loss: 0.07302969353110529\n",
            "batch: 1223 loss: 0.073095130169997\n",
            "batch: 1224 loss: 0.0731722407436464\n",
            "batch: 1225 loss: 0.07320786739722826\n",
            "batch: 1226 loss: 0.07321840136987157\n",
            "batch: 1227 loss: 0.07350095948320813\n",
            "batch: 1228 loss: 0.07352042196621188\n",
            "batch: 1229 loss: 0.07353109533735551\n",
            "batch: 1230 loss: 0.0735499955213163\n",
            "batch: 1231 loss: 0.07355588221712969\n",
            "batch: 1232 loss: 0.07355735760345124\n",
            "batch: 1233 loss: 0.07359571571811102\n",
            "batch: 1234 loss: 0.07366551406099461\n",
            "batch: 1235 loss: 0.07367519627860747\n",
            "batch: 1236 loss: 0.07374704128107987\n",
            "batch: 1237 loss: 0.0738244601150509\n",
            "batch: 1238 loss: 0.07383317835791968\n",
            "batch: 1239 loss: 0.07397212092741393\n",
            "batch: 1240 loss: 0.07403900012536906\n",
            "batch: 1241 loss: 0.07405833743489347\n",
            "batch: 1242 loss: 0.07409196413657627\n",
            "batch: 1243 loss: 0.07419758729240856\n",
            "batch: 1244 loss: 0.07427880721143447\n",
            "batch: 1245 loss: 0.0744179864411708\n",
            "batch: 1246 loss: 0.07444577353424392\n",
            "batch: 1247 loss: 0.07446191666810774\n",
            "batch: 1248 loss: 0.07456847418635153\n",
            "batch: 1249 loss: 0.07473485860018991\n",
            "batch: 1250 loss: 0.07474432976427488\n",
            "batch: 1251 loss: 0.07475806633359752\n",
            "batch: 1252 loss: 0.07496390777057968\n",
            "batch: 1253 loss: 0.07499066031514667\n",
            "batch: 1254 loss: 0.07499246029986534\n",
            "batch: 1255 loss: 0.0750790976403514\n",
            "batch: 1256 loss: 0.07508865903748665\n",
            "batch: 1257 loss: 0.0751048005433986\n",
            "batch: 1258 loss: 0.07510791279061232\n",
            "batch: 1259 loss: 0.0753470526455203\n",
            "batch: 1260 loss: 0.07535759619495366\n",
            "batch: 1261 loss: 0.07542406603565906\n",
            "batch: 1262 loss: 0.07543405131681356\n",
            "batch: 1263 loss: 0.07557721313519869\n",
            "batch: 1264 loss: 0.07565725352300796\n",
            "batch: 1265 loss: 0.07568292929290328\n",
            "batch: 1266 loss: 0.07568947753414977\n",
            "batch: 1267 loss: 0.07569094847224186\n",
            "batch: 1268 loss: 0.07601509793184232\n",
            "batch: 1269 loss: 0.07608733567676973\n",
            "batch: 1270 loss: 0.07625985302112531\n",
            "batch: 1271 loss: 0.0763482499428792\n",
            "batch: 1272 loss: 0.07637324989296031\n",
            "batch: 1273 loss: 0.07645104466832708\n",
            "batch: 1274 loss: 0.07657073709077668\n",
            "batch: 1275 loss: 0.07657626773498487\n",
            "batch: 1276 loss: 0.07658855862251948\n",
            "batch: 1277 loss: 0.07671536923281383\n",
            "batch: 1278 loss: 0.07689173289469908\n",
            "batch: 1279 loss: 0.07691086363315117\n",
            "batch: 1280 loss: 0.0769548782807542\n",
            "batch: 1281 loss: 0.07697409061423968\n",
            "batch: 1282 loss: 0.07697619777580257\n",
            "batch: 1283 loss: 0.07702650940825698\n",
            "batch: 1284 loss: 0.07705254468170461\n",
            "batch: 1285 loss: 0.07721303422597703\n",
            "batch: 1286 loss: 0.07729147861746606\n",
            "batch: 1287 loss: 0.07730225111392793\n",
            "batch: 1288 loss: 0.0776483997538453\n",
            "batch: 1289 loss: 0.07773487001506146\n",
            "batch: 1290 loss: 0.07773813067853916\n",
            "batch: 1291 loss: 0.07782886904210318\n",
            "batch: 1292 loss: 0.07807904314727057\n",
            "batch: 1293 loss: 0.07814713166386354\n",
            "batch: 1294 loss: 0.07836850450665224\n",
            "batch: 1295 loss: 0.07849391327530611\n",
            "batch: 1296 loss: 0.07849753603816498\n",
            "batch: 1297 loss: 0.0785536972853588\n",
            "batch: 1298 loss: 0.07859751360223163\n",
            "batch: 1299 loss: 0.07860773536667694\n",
            "batch: 1300 loss: 0.07867271284863818\n",
            "batch: 1301 loss: 0.07868804237816948\n",
            "batch: 1302 loss: 0.0787226427627029\n",
            "batch: 1303 loss: 0.07873732644424308\n",
            "batch: 1304 loss: 0.07874583525501658\n",
            "batch: 1305 loss: 0.07887849016033578\n",
            "batch: 1306 loss: 0.07889927471347619\n",
            "batch: 1307 loss: 0.0789378554924624\n",
            "batch: 1308 loss: 0.07909041295491624\n",
            "batch: 1309 loss: 0.07909456747921649\n",
            "batch: 1310 loss: 0.07942050877364817\n",
            "batch: 1311 loss: 0.07943055084126535\n",
            "batch: 1312 loss: 0.07948141184228007\n",
            "batch: 1313 loss: 0.07952044446172658\n",
            "batch: 1314 loss: 0.07954341152461711\n",
            "batch: 1315 loss: 0.07968874862941448\n",
            "batch: 1316 loss: 0.07969320832157974\n",
            "batch: 1317 loss: 0.07981866170431022\n",
            "batch: 1318 loss: 0.07993058025056962\n",
            "batch: 1319 loss: 0.07994929738307838\n",
            "batch: 1320 loss: 0.07996416822040919\n",
            "batch: 1321 loss: 0.07997440619266126\n",
            "batch: 1322 loss: 0.08011038696265314\n",
            "batch: 1323 loss: 0.0801482414851198\n",
            "batch: 1324 loss: 0.08016730225889478\n",
            "batch: 1325 loss: 0.08018436539231334\n",
            "batch: 1326 loss: 0.0802586612260202\n",
            "batch: 1327 loss: 0.08043934586702381\n",
            "batch: 1328 loss: 0.08045426334871444\n",
            "batch: 1329 loss: 0.08053795215918216\n",
            "batch: 1330 loss: 0.08058304935006891\n",
            "batch: 1331 loss: 0.08060338599479291\n",
            "batch: 1332 loss: 0.0807501443872461\n",
            "batch: 1333 loss: 0.08075680031080265\n",
            "batch: 1334 loss: 0.08087814060796518\n",
            "batch: 1335 loss: 0.08090723614592571\n",
            "batch: 1336 loss: 0.08093799317080994\n",
            "batch: 1337 loss: 0.08100288442720194\n",
            "batch: 1338 loss: 0.08103068102907855\n",
            "batch: 1339 loss: 0.0811673598290654\n",
            "batch: 1340 loss: 0.08117384306306485\n",
            "batch: 1341 loss: 0.0812456397783244\n",
            "batch: 1342 loss: 0.08128873736376409\n",
            "batch: 1343 loss: 0.08132437433267478\n",
            "batch: 1344 loss: 0.0813883584436262\n",
            "batch: 1345 loss: 0.08141563120076899\n",
            "batch: 1346 loss: 0.08146572359243874\n",
            "batch: 1347 loss: 0.08153468806634191\n",
            "batch: 1348 loss: 0.0815668588053668\n",
            "batch: 1349 loss: 0.08199624896759633\n",
            "batch: 1350 loss: 0.08200983042980078\n",
            "batch: 1351 loss: 0.08206257954577449\n",
            "batch: 1352 loss: 0.08215638513455634\n",
            "batch: 1353 loss: 0.08223115833441261\n",
            "batch: 1354 loss: 0.0823112539757276\n",
            "batch: 1355 loss: 0.08232176617125515\n",
            "batch: 1356 loss: 0.08232904479524586\n",
            "batch: 1357 loss: 0.0824033429386327\n",
            "batch: 1358 loss: 0.08245377760997508\n",
            "batch: 1359 loss: 0.08246579135453794\n",
            "batch: 1360 loss: 0.08258920955157373\n",
            "batch: 1361 loss: 0.08278359546756837\n",
            "batch: 1362 loss: 0.08279218606336508\n",
            "batch: 1363 loss: 0.08279882132133935\n",
            "batch: 1364 loss: 0.08299994311353658\n",
            "batch: 1365 loss: 0.08316838679334615\n",
            "batch: 1366 loss: 0.08332467976829502\n",
            "batch: 1367 loss: 0.08333486643771175\n",
            "batch: 1368 loss: 0.08340371953288558\n",
            "batch: 1369 loss: 0.08356598052720074\n",
            "batch: 1370 loss: 0.08360937472770456\n",
            "batch: 1371 loss: 0.08362170106323902\n",
            "batch: 1372 loss: 0.08368354553880636\n",
            "batch: 1373 loss: 0.08369989636505488\n",
            "batch: 1374 loss: 0.08373453580925706\n",
            "batch: 1375 loss: 0.0837727635015035\n",
            "batch: 1376 loss: 0.08385907148162369\n",
            "batch: 1377 loss: 0.0838821762498701\n",
            "batch: 1378 loss: 0.08407644380594138\n",
            "batch: 1379 loss: 0.08415297046268824\n",
            "batch: 1380 loss: 0.0842124626111472\n",
            "batch: 1381 loss: 0.08423322250472848\n",
            "batch: 1382 loss: 0.0844874729119474\n",
            "batch: 1383 loss: 0.08449270129634533\n",
            "batch: 1384 loss: 0.08457105939520988\n",
            "batch: 1385 loss: 0.08461463163478766\n",
            "batch: 1386 loss: 0.08462470245233271\n",
            "batch: 1387 loss: 0.08469409455230925\n",
            "batch: 1388 loss: 0.0847579592751572\n",
            "batch: 1389 loss: 0.08484091271331999\n",
            "batch: 1390 loss: 0.0851428835230181\n",
            "batch: 1391 loss: 0.0851791458191583\n",
            "batch: 1392 loss: 0.08547124511620495\n",
            "batch: 1393 loss: 0.08561226982495282\n",
            "batch: 1394 loss: 0.08577465318760369\n",
            "batch: 1395 loss: 0.08580421025550458\n",
            "batch: 1396 loss: 0.08583820319420192\n",
            "batch: 1397 loss: 0.08584489716228563\n",
            "batch: 1398 loss: 0.08585655894514639\n",
            "batch: 1399 loss: 0.08587339667987544\n",
            "batch: 1400 loss: 0.08598463337135036\n",
            "batch: 1401 loss: 0.0860427074880572\n",
            "batch: 1402 loss: 0.08610662343364675\n",
            "batch: 1403 loss: 0.08612735978898127\n",
            "batch: 1404 loss: 0.08617397890996653\n",
            "batch: 1405 loss: 0.08618203711148817\n",
            "batch: 1406 loss: 0.08618474697077182\n",
            "batch: 1407 loss: 0.08619183597841766\n",
            "batch: 1408 loss: 0.08625209304818418\n",
            "batch: 1409 loss: 0.08630224480235484\n",
            "batch: 1410 loss: 0.0864102092658868\n",
            "batch: 1411 loss: 0.08651516207063105\n",
            "batch: 1412 loss: 0.08658736394846346\n",
            "batch: 1413 loss: 0.08661374572420028\n",
            "batch: 1414 loss: 0.08664454778411891\n",
            "batch: 1415 loss: 0.08667797252663877\n",
            "batch: 1416 loss: 0.08685732217261102\n",
            "batch: 1417 loss: 0.08686122114944737\n",
            "batch: 1418 loss: 0.08690101499098819\n",
            "batch: 1419 loss: 0.08690894723671955\n",
            "batch: 1420 loss: 0.08692057960282545\n",
            "batch: 1421 loss: 0.08692545937455724\n",
            "batch: 1422 loss: 0.08701515761471819\n",
            "batch: 1423 loss: 0.08710659880645108\n",
            "batch: 1424 loss: 0.08719169640250038\n",
            "batch: 1425 loss: 0.08720116332906765\n",
            "batch: 1426 loss: 0.08720775582303758\n",
            "batch: 1427 loss: 0.08723056194034871\n",
            "batch: 1428 loss: 0.08728195085225161\n",
            "batch: 1429 loss: 0.08728724280779715\n",
            "batch: 1430 loss: 0.08745443532650825\n",
            "batch: 1431 loss: 0.08746585565095302\n",
            "batch: 1432 loss: 0.08751658432220574\n",
            "batch: 1433 loss: 0.0876677098426735\n",
            "batch: 1434 loss: 0.0876864875111496\n",
            "batch: 1435 loss: 0.08770582563464996\n",
            "batch: 1436 loss: 0.08773116580804344\n",
            "batch: 1437 loss: 0.08784795269777533\n",
            "batch: 1438 loss: 0.0878542257574154\n",
            "batch: 1439 loss: 0.08786805622547399\n",
            "batch: 1440 loss: 0.08801779194443952\n",
            "batch: 1441 loss: 0.08813181566714774\n",
            "batch: 1442 loss: 0.08820088791369926\n",
            "batch: 1443 loss: 0.0882105965501396\n",
            "batch: 1444 loss: 0.08823198220680933\n",
            "batch: 1445 loss: 0.08823781672900077\n",
            "batch: 1446 loss: 0.08825760149245616\n",
            "batch: 1447 loss: 0.08836438157444354\n",
            "batch: 1448 loss: 0.08836690772033762\n",
            "batch: 1449 loss: 0.08856823945499491\n",
            "batch: 1450 loss: 0.08864197958714794\n",
            "batch: 1451 loss: 0.08866564508609008\n",
            "batch: 1452 loss: 0.08867137732391711\n",
            "batch: 1453 loss: 0.0886868524387246\n",
            "batch: 1454 loss: 0.08871265355346258\n",
            "batch: 1455 loss: 0.08871507207665127\n",
            "batch: 1456 loss: 0.08876415202382486\n",
            "batch: 1457 loss: 0.08878598776075523\n",
            "batch: 1458 loss: 0.08882247021782677\n",
            "batch: 1459 loss: 0.08883016522263643\n",
            "batch: 1460 loss: 0.08884836553817149\n",
            "batch: 1461 loss: 0.08886862902750726\n",
            "batch: 1462 loss: 0.08895013067533727\n",
            "batch: 1463 loss: 0.0890453693162417\n",
            "batch: 1464 loss: 0.08905506820732262\n",
            "batch: 1465 loss: 0.08920780174189713\n",
            "batch: 1466 loss: 0.08932314696663525\n",
            "batch: 1467 loss: 0.08939034507179167\n",
            "batch: 1468 loss: 0.08939952539035585\n",
            "batch: 1469 loss: 0.08941184254863765\n",
            "batch: 1470 loss: 0.08946891677507665\n",
            "batch: 1471 loss: 0.08952611846232321\n",
            "batch: 1472 loss: 0.08952937889832538\n",
            "batch: 1473 loss: 0.089561370644602\n",
            "batch: 1474 loss: 0.0896921898907749\n",
            "batch: 1475 loss: 0.08969493427861017\n",
            "batch: 1476 loss: 0.08972089878830593\n",
            "batch: 1477 loss: 0.08975471518922132\n",
            "batch: 1478 loss: 0.09004123179602902\n",
            "batch: 1479 loss: 0.09004290253703948\n",
            "batch: 1480 loss: 0.09005542520561721\n",
            "batch: 1481 loss: 0.09008033543953206\n",
            "batch: 1482 loss: 0.09008703658625018\n",
            "batch: 1483 loss: 0.0901132283405168\n",
            "batch: 1484 loss: 0.09024701405025554\n",
            "batch: 1485 loss: 0.09024980732414406\n",
            "batch: 1486 loss: 0.09026963993150275\n",
            "batch: 1487 loss: 0.09032987938064616\n",
            "batch: 1488 loss: 0.0903748723565368\n",
            "batch: 1489 loss: 0.09042964750516694\n",
            "batch: 1490 loss: 0.09044139848824125\n",
            "batch: 1491 loss: 0.09053063575353008\n",
            "batch: 1492 loss: 0.09061166157748085\n",
            "batch: 1493 loss: 0.09062098156649154\n",
            "batch: 1494 loss: 0.09063332075893413\n",
            "batch: 1495 loss: 0.0907189222824527\n",
            "batch: 1496 loss: 0.09085921945690643\n",
            "batch: 1497 loss: 0.09085984520317288\n",
            "batch: 1498 loss: 0.09113618613482685\n",
            "batch: 1499 loss: 0.09117171776742908\n",
            "batch: 1500 loss: 0.09118233943619998\n",
            "batch: 1501 loss: 0.091193157567468\n",
            "batch: 1502 loss: 0.09136237351485761\n",
            "batch: 1503 loss: 0.09137674122379394\n",
            "batch: 1504 loss: 0.09139374559820862\n",
            "batch: 1505 loss: 0.0914307191267726\n",
            "batch: 1506 loss: 0.09150350159109803\n",
            "batch: 1507 loss: 0.09159147502930136\n",
            "batch: 1508 loss: 0.09168503143341514\n",
            "batch: 1509 loss: 0.09168710679683136\n",
            "batch: 1510 loss: 0.0916939917349373\n",
            "batch: 1511 loss: 0.09173892333667027\n",
            "batch: 1512 loss: 0.09179348469089019\n",
            "batch: 1513 loss: 0.09186812679778086\n",
            "batch: 1514 loss: 0.09190750752697932\n",
            "batch: 1515 loss: 0.09198204502026783\n",
            "batch: 1516 loss: 0.09201912085275399\n",
            "batch: 1517 loss: 0.09203177625249373\n",
            "batch: 1518 loss: 0.09204931024025427\n",
            "batch: 1519 loss: 0.09206787162768887\n",
            "batch: 1520 loss: 0.09217106381553458\n",
            "batch: 1521 loss: 0.09224230759340571\n",
            "batch: 1522 loss: 0.09229428205388832\n",
            "batch: 1523 loss: 0.09230506071756826\n",
            "batch: 1524 loss: 0.0923610350669478\n",
            "batch: 1525 loss: 0.09237643252249109\n",
            "batch: 1526 loss: 0.09239001162472414\n",
            "batch: 1527 loss: 0.0924017210493912\n",
            "batch: 1528 loss: 0.09247129532351392\n",
            "batch: 1529 loss: 0.09249304679624037\n",
            "batch: 1530 loss: 0.09252919252804713\n",
            "batch: 1531 loss: 0.09261186160735088\n",
            "batch: 1532 loss: 0.09273753287486033\n",
            "batch: 1533 loss: 0.09273999292851659\n",
            "batch: 1534 loss: 0.09275732697249622\n",
            "batch: 1535 loss: 0.09278640601114603\n",
            "batch: 1536 loss: 0.09281692972854944\n",
            "batch: 1537 loss: 0.09292836026923032\n",
            "batch: 1538 loss: 0.09294377641641768\n",
            "batch: 1539 loss: 0.09295894284622046\n",
            "batch: 1540 loss: 0.09315033601300092\n",
            "batch: 1541 loss: 0.09320495007635327\n",
            "batch: 1542 loss: 0.09323168337607057\n",
            "batch: 1543 loss: 0.09332669142895611\n",
            "batch: 1544 loss: 0.09333735825010808\n",
            "batch: 1545 loss: 0.09338869803288254\n",
            "batch: 1546 loss: 0.09339267977309645\n",
            "batch: 1547 loss: 0.09370224567485275\n",
            "batch: 1548 loss: 0.09370730239182012\n",
            "batch: 1549 loss: 0.0937193797978689\n",
            "batch: 1550 loss: 0.0938070103827049\n",
            "batch: 1551 loss: 0.09401286771922605\n",
            "batch: 1552 loss: 0.09402251472912031\n",
            "batch: 1553 loss: 0.09402462245785864\n",
            "batch: 1554 loss: 0.0940537116441992\n",
            "batch: 1555 loss: 0.09426890552678378\n",
            "batch: 1556 loss: 0.09433498879411491\n",
            "batch: 1557 loss: 0.09440679194667609\n",
            "batch: 1558 loss: 0.09454588641860755\n",
            "batch: 1559 loss: 0.0945574929889408\n",
            "batch: 1560 loss: 0.09456257289584027\n",
            "batch: 1561 loss: 0.0946582246714388\n",
            "batch: 1562 loss: 0.0947009274319862\n",
            "batch: 1563 loss: 0.09470465646247613\n",
            "batch: 1564 loss: 0.09480598090897548\n",
            "batch: 1565 loss: 0.09482721321965801\n",
            "batch: 1566 loss: 0.0949900487580453\n",
            "batch: 1567 loss: 0.09508002614910947\n",
            "batch: 1568 loss: 0.09509757272835122\n",
            "batch: 1569 loss: 0.09511084600101458\n",
            "batch: 1570 loss: 0.09516022079001414\n",
            "batch: 1571 loss: 0.09522867048840271\n",
            "batch: 1572 loss: 0.09524692879553186\n",
            "batch: 1573 loss: 0.09526929217885481\n",
            "batch: 1574 loss: 0.09527992916229414\n",
            "batch: 1575 loss: 0.09530869237083243\n",
            "batch: 1576 loss: 0.0953518425275688\n",
            "batch: 1577 loss: 0.09543682671833086\n",
            "batch: 1578 loss: 0.09545508481870638\n",
            "batch: 1579 loss: 0.09550925421650755\n",
            "batch: 1580 loss: 0.09551969538565026\n",
            "batch: 1581 loss: 0.09555073476332472\n",
            "batch: 1582 loss: 0.09563383706408786\n",
            "batch: 1583 loss: 0.09569018797698664\n",
            "batch: 1584 loss: 0.09583275967958615\n",
            "batch: 1585 loss: 0.09586794503900456\n",
            "batch: 1586 loss: 0.09587630806240487\n",
            "batch: 1587 loss: 0.09590837352845119\n",
            "batch: 1588 loss: 0.09595660587522434\n",
            "batch: 1589 loss: 0.09606599246087717\n",
            "batch: 1590 loss: 0.09612575002509402\n",
            "batch: 1591 loss: 0.09617013956728625\n",
            "batch: 1592 loss: 0.09618268806330162\n",
            "batch: 1593 loss: 0.09624599026731448\n",
            "batch: 1594 loss: 0.096273213358887\n",
            "batch: 1595 loss: 0.09628658881812589\n",
            "batch: 1596 loss: 0.09629226535587804\n",
            "batch: 1597 loss: 0.09630239292077021\n",
            "batch: 1598 loss: 0.09633339192933636\n",
            "batch: 1599 loss: 0.09634568888443755\n",
            "batch: 1600 loss: 0.09641533140587853\n",
            "batch: 1601 loss: 0.09646140357974219\n",
            "batch: 1602 loss: 0.09663089165213751\n",
            "batch: 1603 loss: 0.09675183634582209\n",
            "batch: 1604 loss: 0.09679168468463467\n",
            "batch: 1605 loss: 0.09680600441090065\n",
            "batch: 1606 loss: 0.09682102971366839\n",
            "batch: 1607 loss: 0.09683942141971784\n",
            "batch: 1608 loss: 0.09685325242235558\n",
            "batch: 1609 loss: 0.09695979620172875\n",
            "batch: 1610 loss: 0.09696672448638129\n",
            "batch: 1611 loss: 0.0969815852412139\n",
            "batch: 1612 loss: 0.09699219159997301\n",
            "batch: 1613 loss: 0.09708349801815348\n",
            "batch: 1614 loss: 0.09720994569576578\n",
            "batch: 1615 loss: 0.09725403134367662\n",
            "batch: 1616 loss: 0.09735295414022403\n",
            "batch: 1617 loss: 0.09736388247675495\n",
            "batch: 1618 loss: 0.09737687577895121\n",
            "batch: 1619 loss: 0.09741927812836365\n",
            "batch: 1620 loss: 0.09758908878109651\n",
            "batch: 1621 loss: 0.09759680685430067\n",
            "batch: 1622 loss: 0.0977007945778896\n",
            "batch: 1623 loss: 0.09780829367070691\n",
            "batch: 1624 loss: 0.09783189318730728\n",
            "batch: 1625 loss: 0.09784348170395242\n",
            "batch: 1626 loss: 0.09784478399291402\n",
            "batch: 1627 loss: 0.09785250346030808\n",
            "batch: 1628 loss: 0.09785373995063128\n",
            "batch: 1629 loss: 0.09794263469037832\n",
            "batch: 1630 loss: 0.0979476751133916\n",
            "batch: 1631 loss: 0.09804262988717528\n",
            "batch: 1632 loss: 0.09805386225768598\n",
            "batch: 1633 loss: 0.09806631313153776\n",
            "batch: 1634 loss: 0.0981111369978753\n",
            "batch: 1635 loss: 0.09820208376162919\n",
            "batch: 1636 loss: 0.09828094852232606\n",
            "batch: 1637 loss: 0.09837002415471943\n",
            "batch: 1638 loss: 0.09849153795355232\n",
            "batch: 1639 loss: 0.09851257348508807\n",
            "batch: 1640 loss: 0.09852166128606768\n",
            "batch: 1641 loss: 0.0986853121414897\n",
            "batch: 1642 loss: 0.09874603319988819\n",
            "batch: 1643 loss: 0.09875843884685309\n",
            "batch: 1644 loss: 0.09896462466457161\n",
            "batch: 1645 loss: 0.09898102446162374\n",
            "batch: 1646 loss: 0.0990258003275958\n",
            "batch: 1647 loss: 0.0991984290581313\n",
            "batch: 1648 loss: 0.09932274320983561\n",
            "batch: 1649 loss: 0.09947776238882215\n",
            "batch: 1650 loss: 0.09948376225336687\n",
            "batch: 1651 loss: 0.09956900278135436\n",
            "batch: 1652 loss: 0.09970299542351858\n",
            "batch: 1653 loss: 0.09971128189685988\n",
            "batch: 1654 loss: 0.09977481203648494\n",
            "batch: 1655 loss: 0.0998730448273127\n",
            "batch: 1656 loss: 0.09987726040679262\n",
            "batch: 1657 loss: 0.09997100756067084\n",
            "batch: 1658 loss: 0.09997768606926548\n",
            "batch: 1659 loss: 0.10031031965400325\n",
            "batch: 1660 loss: 0.10048810187663185\n",
            "batch: 1661 loss: 0.10058225115324604\n",
            "batch: 1662 loss: 0.10060220013308571\n",
            "batch: 1663 loss: 0.1006286274169688\n",
            "batch: 1664 loss: 0.10073573133099126\n",
            "batch: 1665 loss: 0.10079940998303936\n",
            "batch: 1666 loss: 0.10082285235758172\n",
            "batch: 1667 loss: 0.10083343180204975\n",
            "batch: 1668 loss: 0.10087288765172707\n",
            "batch: 1669 loss: 0.10092434428195701\n",
            "batch: 1670 loss: 0.10099330904643285\n",
            "batch: 1671 loss: 0.10102064494724618\n",
            "batch: 1672 loss: 0.10109049646492349\n",
            "batch: 1673 loss: 0.1010987129251589\n",
            "batch: 1674 loss: 0.10110427212790819\n",
            "batch: 1675 loss: 0.10111705100984546\n",
            "batch: 1676 loss: 0.1011408084713039\n",
            "batch: 1677 loss: 0.10116450610087487\n",
            "batch: 1678 loss: 0.10128607084677788\n",
            "batch: 1679 loss: 0.10157578509376618\n",
            "batch: 1680 loss: 0.10168274685071083\n",
            "batch: 1681 loss: 0.10186217118130299\n",
            "batch: 1682 loss: 0.10187983494141371\n",
            "batch: 1683 loss: 0.10199098288902314\n",
            "batch: 1684 loss: 0.10199822217255132\n",
            "batch: 1685 loss: 0.10200177493767114\n",
            "batch: 1686 loss: 0.10204812790156575\n",
            "batch: 1687 loss: 0.10211629870982142\n",
            "batch: 1688 loss: 0.10213309437112185\n",
            "batch: 1689 loss: 0.10214707978611114\n",
            "batch: 1690 loss: 0.10218466852401616\n",
            "batch: 1691 loss: 0.10219031756540062\n",
            "batch: 1692 loss: 0.10219515101687285\n",
            "batch: 1693 loss: 0.10230004647449822\n",
            "batch: 1694 loss: 0.10230560845305445\n",
            "batch: 1695 loss: 0.1023211414188263\n",
            "batch: 1696 loss: 0.10234441506006987\n",
            "batch: 1697 loss: 0.10242614684888394\n",
            "batch: 1698 loss: 0.10248903553077253\n",
            "batch: 1699 loss: 0.10250430212059292\n",
            "batch: 1700 loss: 0.10254214480408701\n",
            "batch: 1701 loss: 0.10274148173519643\n",
            "batch: 1702 loss: 0.10279254861810477\n",
            "batch: 1703 loss: 0.10280492953007342\n",
            "batch: 1704 loss: 0.10315975502674701\n",
            "batch: 1705 loss: 0.10321852861513617\n",
            "batch: 1706 loss: 0.10326439767872216\n",
            "batch: 1707 loss: 0.10327676484157564\n",
            "batch: 1708 loss: 0.10335016478021862\n",
            "batch: 1709 loss: 0.10366870231350185\n",
            "batch: 1710 loss: 0.10368240254727425\n",
            "batch: 1711 loss: 0.10372191788238706\n",
            "batch: 1712 loss: 0.10372777870559366\n",
            "batch: 1713 loss: 0.10374251676892163\n",
            "batch: 1714 loss: 0.10376857181248487\n",
            "batch: 1715 loss: 0.10381735909340205\n",
            "batch: 1716 loss: 0.1039318270793301\n",
            "batch: 1717 loss: 0.10397322377172531\n",
            "batch: 1718 loss: 0.1041802208533627\n",
            "batch: 1719 loss: 0.10434391271678033\n",
            "batch: 1720 loss: 0.10435542069916846\n",
            "batch: 1721 loss: 0.10439230942894938\n",
            "batch: 1722 loss: 0.10444498709012986\n",
            "batch: 1723 loss: 0.10447724158858182\n",
            "batch: 1724 loss: 0.10456257835571887\n",
            "batch: 1725 loss: 0.10456576219416457\n",
            "batch: 1726 loss: 0.10458872543304461\n",
            "batch: 1727 loss: 0.10466907581716077\n",
            "batch: 1728 loss: 0.10467116239509779\n",
            "batch: 1729 loss: 0.10476128567598061\n",
            "batch: 1730 loss: 0.1047669961534557\n",
            "batch: 1731 loss: 0.10476983875298174\n",
            "batch: 1732 loss: 0.10478051963058534\n",
            "batch: 1733 loss: 0.10507636800018372\n",
            "batch: 1734 loss: 0.10509440954384627\n",
            "batch: 1735 loss: 0.10517229948547901\n",
            "batch: 1736 loss: 0.10519787910935702\n",
            "batch: 1737 loss: 0.10523252910358133\n",
            "batch: 1738 loss: 0.10526171620917739\n",
            "batch: 1739 loss: 0.10527622330730083\n",
            "batch: 1740 loss: 0.10532837523316266\n",
            "batch: 1741 loss: 0.10534544606303098\n",
            "batch: 1742 loss: 0.10536695062537911\n",
            "batch: 1743 loss: 0.10538229168095858\n",
            "batch: 1744 loss: 0.10551331277826102\n",
            "batch: 1745 loss: 0.10551935844059335\n",
            "batch: 1746 loss: 0.10557884486700642\n",
            "batch: 1747 loss: 0.10563862036104547\n",
            "batch: 1748 loss: 0.10572685055370676\n",
            "batch: 1749 loss: 0.10577724111016142\n",
            "batch: 1750 loss: 0.10592513267631876\n",
            "batch: 1751 loss: 0.10603233702416764\n",
            "batch: 1752 loss: 0.10618469804461347\n",
            "batch: 1753 loss: 0.10624651219631778\n",
            "batch: 1754 loss: 0.10626850495237158\n",
            "batch: 1755 loss: 0.10631584364670561\n",
            "batch: 1756 loss: 0.10644323672848986\n",
            "batch: 1757 loss: 0.10647069884586381\n",
            "batch: 1758 loss: 0.10648246803070652\n",
            "batch: 1759 loss: 0.10666968729282962\n",
            "batch: 1760 loss: 0.1066915325851296\n",
            "batch: 1761 loss: 0.10685635057400214\n",
            "batch: 1762 loss: 0.10690057569305646\n",
            "batch: 1763 loss: 0.10698464065353619\n",
            "batch: 1764 loss: 0.1071533537612413\n",
            "batch: 1765 loss: 0.10719213606725679\n",
            "batch: 1766 loss: 0.10722821089188801\n",
            "batch: 1767 loss: 0.10743292507092701\n",
            "batch: 1768 loss: 0.10749145226489054\n",
            "batch: 1769 loss: 0.10777587931166636\n",
            "batch: 1770 loss: 0.1077896995258634\n",
            "batch: 1771 loss: 0.1077983861475368\n",
            "batch: 1772 loss: 0.10782027870445746\n",
            "batch: 1773 loss: 0.1078811154740979\n",
            "batch: 1774 loss: 0.10793429464503425\n",
            "batch: 1775 loss: 0.10794755556463496\n",
            "batch: 1776 loss: 0.10814380616723793\n",
            "batch: 1777 loss: 0.10816093682899372\n",
            "batch: 1778 loss: 0.10816196358535672\n",
            "batch: 1779 loss: 0.108210006922076\n",
            "batch: 1780 loss: 0.10828332246054197\n",
            "batch: 1781 loss: 0.1083339016433456\n",
            "batch: 1782 loss: 0.10835460504476215\n",
            "batch: 1783 loss: 0.10837236412015044\n",
            "batch: 1784 loss: 0.10838508023746544\n",
            "batch: 1785 loss: 0.10844085186399752\n",
            "batch: 1786 loss: 0.1085043273610645\n",
            "batch: 1787 loss: 0.10860280029900606\n",
            "batch: 1788 loss: 0.10882418373652035\n",
            "batch: 1789 loss: 0.10889951537229353\n",
            "batch: 1790 loss: 0.10911407747544581\n",
            "batch: 1791 loss: 0.10912815434351797\n",
            "batch: 1792 loss: 0.10915032506227726\n",
            "batch: 1793 loss: 0.10925402469426626\n",
            "batch: 1794 loss: 0.10925686346116709\n",
            "batch: 1795 loss: 0.10941434407356428\n",
            "batch: 1796 loss: 0.10942266839492368\n",
            "batch: 1797 loss: 0.10944041046622442\n",
            "batch: 1798 loss: 0.1094550799013232\n",
            "batch: 1799 loss: 0.1095192578912829\n",
            "batch: 1800 loss: 0.10958027930866228\n",
            "batch: 1801 loss: 0.10966389280121075\n",
            "batch: 1802 loss: 0.10969841687689769\n",
            "batch: 1803 loss: 0.1097738153890823\n",
            "batch: 1804 loss: 0.10978589392203139\n",
            "batch: 1805 loss: 0.10995441286760615\n",
            "batch: 1806 loss: 0.10996271573688136\n",
            "batch: 1807 loss: 0.11009911663021194\n",
            "batch: 1808 loss: 0.11047880247916328\n",
            "batch: 1809 loss: 0.11049572924460517\n",
            "batch: 1810 loss: 0.11050440523709404\n",
            "batch: 1811 loss: 0.11054380087862956\n",
            "batch: 1812 loss: 0.11067211340676295\n",
            "batch: 1813 loss: 0.11071641299437034\n",
            "batch: 1814 loss: 0.11073368237103569\n",
            "batch: 1815 loss: 0.11077244504477131\n",
            "batch: 1816 loss: 0.11082036481733666\n",
            "batch: 1817 loss: 0.11089062561030733\n",
            "batch: 1818 loss: 0.11089835289336042\n",
            "batch: 1819 loss: 0.11101132548815804\n",
            "batch: 1820 loss: 0.11103364979318577\n",
            "batch: 1821 loss: 0.11104623477748828\n",
            "batch: 1822 loss: 0.11105053051403957\n",
            "batch: 1823 loss: 0.1110995405188878\n",
            "batch: 1824 loss: 0.11112992359540658\n",
            "batch: 1825 loss: 0.11115968728467124\n",
            "batch: 1826 loss: 0.11116454215237172\n",
            "batch: 1827 loss: 0.11119257071131142\n",
            "batch: 1828 loss: 0.11120335328747752\n",
            "batch: 1829 loss: 0.1115517917292309\n",
            "batch: 1830 loss: 0.11155916619003983\n",
            "batch: 1831 loss: 0.11156944570114137\n",
            "batch: 1832 loss: 0.11157997744885506\n",
            "batch: 1833 loss: 0.11169758122024359\n",
            "batch: 1834 loss: 0.11170449398207712\n",
            "batch: 1835 loss: 0.1117347716105287\n",
            "batch: 1836 loss: 0.11180338094505714\n",
            "batch: 1837 loss: 0.11181575111794519\n",
            "batch: 1838 loss: 0.111864283294708\n",
            "batch: 1839 loss: 0.11196961324039148\n",
            "batch: 1840 loss: 0.11199195553484606\n",
            "batch: 1841 loss: 0.11212705516937421\n",
            "batch: 1842 loss: 0.11226004064205336\n",
            "batch: 1843 loss: 0.11226298710919218\n",
            "batch: 1844 loss: 0.1124002136758645\n",
            "batch: 1845 loss: 0.11240279075555736\n",
            "batch: 1846 loss: 0.11247945307247574\n",
            "batch: 1847 loss: 0.11251611635513836\n",
            "batch: 1848 loss: 0.11272619960136944\n",
            "batch: 1849 loss: 0.11274943884514504\n",
            "batch: 1850 loss: 0.11279324303619796\n",
            "batch: 1851 loss: 0.11282091027736897\n",
            "batch: 1852 loss: 0.11288291171431775\n",
            "batch: 1853 loss: 0.11307496558368439\n",
            "batch: 1854 loss: 0.1131034164899611\n",
            "batch: 1855 loss: 0.11312355369940633\n",
            "batch: 1856 loss: 0.11313530294277006\n",
            "batch: 1857 loss: 0.1131513565783971\n",
            "batch: 1858 loss: 0.11315506455028662\n",
            "batch: 1859 loss: 0.11318692942807684\n",
            "batch: 1860 loss: 0.11325224964419613\n",
            "batch: 1861 loss: 0.11326515790919074\n",
            "batch: 1862 loss: 0.11333130069175967\n",
            "batch: 1863 loss: 0.11339548222819576\n",
            "batch: 1864 loss: 0.1134895227039815\n",
            "batch: 1865 loss: 0.11371228853712091\n",
            "batch: 1866 loss: 0.1137272132440121\n",
            "batch: 1867 loss: 0.11380140883015702\n",
            "batch: 1868 loss: 0.11382986755209276\n",
            "batch: 1869 loss: 0.11386688260274241\n",
            "batch: 1870 loss: 0.11388505509408424\n",
            "batch: 1871 loss: 0.11394362331466983\n",
            "batch: 1872 loss: 0.11397620962472865\n",
            "batch: 1873 loss: 0.11402109695883701\n",
            "batch: 1874 loss: 0.11406296775402734\n",
            "Training is completed.\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCH):\n",
        "  running_loss = 0\n",
        "  loss_per_batch = 0\n",
        "\n",
        "  model.train(True)\n",
        "\n",
        "  for i, data in enumerate(training_loader):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs.to(device = device))\n",
        "\n",
        "    loss = loss_fn(output, labels.to(device = device))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if i % 999:\n",
        "      loss_per_batch = running_loss / 1000\n",
        "      print(f\"batch: {i} loss: {loss_per_batch}\")\n",
        "\n",
        "  running_vloss = 0.0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, vdata in enumerate(test_loader):\n",
        "      vinputs, vlabels = vdata\n",
        "      voutputs = model(vinputs.to(device))\n",
        "      vloss = loss_fn(voutputs, vlabels.to(device))\n",
        "      running_loss += vloss\n",
        "\n",
        "  avg_vloss = running_loss / (i + 1)\n",
        "\n",
        "  if avg_vloss < best_vloss :\n",
        "    best_vloss = avg_vloss\n",
        "    model_path = f\"model_{epoch}\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "  epoch_number += 1\n",
        "\n",
        "print(\"Training is completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYaQ-7AOZH4C",
        "outputId": "3b6e54d1-884c-4f16-b5ac-4d9d8c5923ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_loaded = NN()\n",
        "model_loaded.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUHTW3Vfbugb",
        "outputId": "380e8fdc-152a-46d6-a67f-dd802f544114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = test_dataset[27][0]\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "YTBPBKsgb-GL",
        "outputId": "f511aace-7adb-47e8-ff2f-42187fb51501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x23d00318e10>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(img.reshape(28,28), cmap=\"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWU-e7xhcT_a",
        "outputId": "899df3f8-e845-43a9-eb7e-20418354f887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-11.5730,  -8.8167,  -6.3451,  -8.0897,  13.2075,  -7.3282, -12.5549,\n",
              "          -2.6806,  -7.6420,   1.6140]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model_loaded(img)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dLNzyBlocqGz"
      },
      "outputs": [],
      "source": [
        "predict = torch.max(outputs, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8xZYko8c6ve",
        "outputId": "87c83a5c-52eb-4cf5-daac-0076c3a427a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([13.2075], grad_fn=<MaxBackward0>),\n",
              "indices=tensor([4]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lITl1zF4z-MG",
        "outputId": "fdd7b64d-ab9d-4717-a1c8-2a62d8b93eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model is 97.61\n"
          ]
        }
      ],
      "source": [
        "model_loaded.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device = device), labels.to(device = device)\n",
        "\n",
        "    outputs = model_loaded(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"Accuracy of the model is {accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
